{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15x8txVO1V9SusjtURzEeanVxIPwfAlxY",
      "authorship_tag": "ABX9TyNR6s7zg6aoBzfClWFjogyH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibsen-Gomes/Deep_learning_Colab/blob/main/Deep_learning_breast_cancer_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries:"
      ],
      "metadata": {
        "id": "M9dJck8L-CXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "4WgHe92r-Ax6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch package import:"
      ],
      "metadata": {
        "id": "NEvz3onB-JRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "csxD8avJxcF5",
        "outputId": "aadb0bb0-4b5e-4e76-ed12-b2024bdee592"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "ZdRl6WxXxoua"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "6lGVDwFJy86B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CssdCo9pxsaL",
        "outputId": "f6310356-3cc9-4179-eb2e-909178f5523c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78dedd98ca90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = pd.read_csv('/content/drive/MyDrive/Deep_learning/entradas_breast.csv')\n",
        "classe = pd.read_csv('/content/drive/MyDrive/Deep_learning/saidas_breast.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "7Ffz0JXdzEqr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj_lwatI7Ase",
        "outputId": "5aa71681-815c-4810-f994-2cf65ed23278"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "7hgIKjvU7LFP",
        "outputId": "aba83034-d4ea-42f8-f269-93f4a6233eef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
              "0         17.99          10.38           122.80      1001.0           0.11840   \n",
              "1         20.57          17.77           132.90      1326.0           0.08474   \n",
              "2         19.69          21.25           130.00      1203.0           0.10960   \n",
              "3         11.42          20.38            77.58       386.1           0.14250   \n",
              "4         20.29          14.34           135.10      1297.0           0.10030   \n",
              "\n",
              "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
              "0            0.27760           0.3001              0.14710          0.2419   \n",
              "1            0.07864           0.0869              0.07017          0.1812   \n",
              "2            0.15990           0.1974              0.12790          0.2069   \n",
              "3            0.28390           0.2414              0.10520          0.2597   \n",
              "4            0.13280         198.0000              0.10430          0.1809   \n",
              "\n",
              "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
              "0                  0.07871  ...          25.38           17.33   \n",
              "1                  0.05667  ...          24.99           23.41   \n",
              "2                  0.05999  ...          23.57           25.53   \n",
              "3                  0.09744  ...          14.91           26.50   \n",
              "4                  0.05883  ...          22.54           16.67   \n",
              "\n",
              "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
              "0            184.60       2019.0             0.1622              0.6656   \n",
              "1            158.80       1956.0             0.1238              0.1866   \n",
              "2            152.50       1709.0             0.1444              0.4245   \n",
              "3             98.87        567.7             0.2098              0.8663   \n",
              "4            152.20       1575.0             0.1374            205.0000   \n",
              "\n",
              "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
              "0            0.7119                 0.2654           0.4601   \n",
              "1            0.2416               186.0000         275.0000   \n",
              "2            0.4504               243.0000           0.3613   \n",
              "3            0.6869                 0.2575           0.6638   \n",
              "4            0.4000                 0.1625           0.2364   \n",
              "\n",
              "    fractal_dimension_worst  \n",
              "0                   0.11890  \n",
              "1                   0.08902  \n",
              "2                   0.08758  \n",
              "3                 173.00000  \n",
              "4                   0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3884957b-462f-4b4c-be87-2b6941125430\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3884957b-462f-4b4c-be87-2b6941125430')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-211c951d-83b6-4c19-95bf-2d8e7e1baca5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-211c951d-83b6-4c19-95bf-2d8e7e1baca5')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-211c951d-83b6-4c19-95bf-2d8e7e1baca5 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3884957b-462f-4b4c-be87-2b6941125430 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3884957b-462f-4b4c-be87-2b6941125430');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "55FTNTiL7ONY",
        "outputId": "40ba8338-09bd-405c-c44b-79024e1ef107"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-d8dc4915-1e87-409d-bbe6-05e04e7bf134\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8dc4915-1e87-409d-bbe6-05e04e7bf134')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4a96488c-40bc-413b-add0-2cfaa7abce81\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a96488c-40bc-413b-add0-2cfaa7abce81')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4a96488c-40bc-413b-add0-2cfaa7abce81 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8dc4915-1e87-409d-bbe6-05e04e7bf134 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8dc4915-1e87-409d-bbe6-05e04e7bf134');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(classe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhg_bRLq7XNU",
        "outputId": "10f3a001-7ca5-4816-f0c1-69817c8dbcfc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample count for each label:"
      ],
      "metadata": {
        "id": "u7DQfWgy-jHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=classe['0'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "A8nJH17w7dEP",
        "outputId": "fa8eee6f-cefd-4b73-c8fd-e1c4cf48c10b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='0', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkM0lEQVR4nO3de2xUdd7H8U9b6ECBmaZAZ9qlxQsKVMslBctEH8JCpVxkJVbXC0JXCUS2sIFxEWsQBC9VdBe8VFg366IJXVldwYgKYpHipYAWWRCEACEphk6Lsu1AXaa0neePDSc7CyhOL2f64/1KJum5zJnvMcG+c+bMNCYUCoUEAABgqFi7BwAAAGhLxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjNbJ7gGiQXNzs44fP64ePXooJibG7nEAAMAlCIVCOnXqlFJTUxUbe/HrN8SOpOPHjystLc3uMQAAQASOHTumPn36XHQ7sSOpR48ekv7zH8vpdNo8DQAAuBSBQEBpaWnW7/GLIXYk660rp9NJ7AAA0MH81C0o3KAMAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoneweAAA6usqlmXaPAESl9EV77R5BEld2AACA4YgdAABgNFtjZ+XKlRo0aJCcTqecTqe8Xq8++OADa/uoUaMUExMT9njggQfCjlFZWamJEycqISFBycnJmj9/vhobG9v7VAAAQJSy9Z6dPn366Omnn9Y111yjUCik1157Tbfeequ++uorXXfddZKkGTNmaOnSpdZzEhISrJ+bmpo0ceJEeTweff7556qqqtK0adPUuXNnPfXUU+1+PgAAIPrYGjuTJk0KW37yySe1cuVKbd++3YqdhIQEeTyeCz7/ww8/1P79+/XRRx/J7XZryJAhevzxx7VgwQI99thjio+Pb/NzAAAA0S1q7tlpamrSG2+8ofr6enm9Xmv9mjVr1KtXL11//fUqLCzUDz/8YG0rLy9XZmam3G63tS43N1eBQED79u276GsFg0EFAoGwBwAAMJPtHz3fu3evvF6vzpw5o+7du2vdunXKyMiQJN1zzz3q27evUlNTtWfPHi1YsEAHDx7U22+/LUny+/1hoSPJWvb7/Rd9zaKiIi1ZsqSNzggAAEQT22Onf//+2r17t+rq6vTWW28pPz9fZWVlysjI0MyZM639MjMzlZKSojFjxujIkSO6+uqrI37NwsJC+Xw+azkQCCgtLa1F5wEAAKKT7W9jxcfHq1+/fsrKylJRUZEGDx6s559//oL7ZmdnS5IOHz4sSfJ4PKqurg7b59zyxe7zkSSHw2F9AuzcAwAAmMn22Plfzc3NCgaDF9y2e/duSVJKSookyev1au/evaqpqbH22bx5s5xOp/VWGAAAuLzZ+jZWYWGhxo8fr/T0dJ06dUolJSXaunWrNm3apCNHjqikpEQTJkxQz549tWfPHs2bN08jR47UoEGDJEljx45VRkaGpk6dqmXLlsnv92vhwoUqKCiQw+Gw89QAAECUsDV2ampqNG3aNFVVVcnlcmnQoEHatGmTbr75Zh07dkwfffSRVqxYofr6eqWlpSkvL08LFy60nh8XF6cNGzZo1qxZ8nq96tatm/Lz88O+lwcAAFzeYkKhUMjuIewWCATkcrlUV1fH/TsAfjb+EChwYW39h0Av9fd31N2zAwAA0JqIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRbY2flypUaNGiQnE6nnE6nvF6vPvjgA2v7mTNnVFBQoJ49e6p79+7Ky8tTdXV12DEqKys1ceJEJSQkKDk5WfPnz1djY2N7nwoAAIhStsZOnz599PTTT6uiokJffvmlRo8erVtvvVX79u2TJM2bN0/vvvuu3nzzTZWVlen48eO67bbbrOc3NTVp4sSJamho0Oeff67XXntNq1ev1qJFi+w6JQAAEGViQqFQyO4h/ltSUpKeffZZ3X777erdu7dKSkp0++23S5IOHDiggQMHqry8XCNGjNAHH3ygW265RcePH5fb7ZYkrVq1SgsWLNCJEycUHx9/Sa8ZCATkcrlUV1cnp9PZZucGwEyVSzPtHgGISumL9rbp8S/193fU3LPT1NSkN954Q/X19fJ6vaqoqNDZs2eVk5Nj7TNgwAClp6ervLxcklReXq7MzEwrdCQpNzdXgUDAujp0IcFgUIFAIOwBAADMZHvs7N27V927d5fD4dADDzygdevWKSMjQ36/X/Hx8UpMTAzb3+12y+/3S5L8fn9Y6Jzbfm7bxRQVFcnlclmPtLS01j0pAAAQNWyPnf79+2v37t3asWOHZs2apfz8fO3fv79NX7OwsFB1dXXW49ixY236egAAwD6d7B4gPj5e/fr1kyRlZWXpiy++0PPPP68777xTDQ0Nqq2tDbu6U11dLY/HI0nyeDzauXNn2PHOfVrr3D4X4nA45HA4WvlMAABANLL9ys7/am5uVjAYVFZWljp37qzS0lJr28GDB1VZWSmv1ytJ8nq92rt3r2pqaqx9Nm/eLKfTqYyMjHafHQAARB9br+wUFhZq/PjxSk9P16lTp1RSUqKtW7dq06ZNcrlcmj59unw+n5KSkuR0OjVnzhx5vV6NGDFCkjR27FhlZGRo6tSpWrZsmfx+vxYuXKiCggKu3AAAAEk2x05NTY2mTZumqqoquVwuDRo0SJs2bdLNN98sSVq+fLliY2OVl5enYDCo3Nxcvfzyy9bz4+LitGHDBs2aNUter1fdunVTfn6+li5datcpAQCAKBN137NjB75nB0BL8D07wIXxPTsAAADtgNgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRbI2doqIiDR8+XD169FBycrImT56sgwcPhu0zatQoxcTEhD0eeOCBsH0qKys1ceJEJSQkKDk5WfPnz1djY2N7ngoAAIhSnex88bKyMhUUFGj48OFqbGzUI488orFjx2r//v3q1q2btd+MGTO0dOlSazkhIcH6uampSRMnTpTH49Hnn3+uqqoqTZs2TZ07d9ZTTz3VrucDAACij62xs3HjxrDl1atXKzk5WRUVFRo5cqS1PiEhQR6P54LH+PDDD7V//3599NFHcrvdGjJkiB5//HEtWLBAjz32mOLj4897TjAYVDAYtJYDgUArnREAAIg2UXXPTl1dnSQpKSkpbP2aNWvUq1cvXX/99SosLNQPP/xgbSsvL1dmZqbcbre1Ljc3V4FAQPv27bvg6xQVFcnlclmPtLS0NjgbAAAQDWy9svPfmpubNXfuXN144426/vrrrfX33HOP+vbtq9TUVO3Zs0cLFizQwYMH9fbbb0uS/H5/WOhIspb9fv8FX6uwsFA+n89aDgQCBA8AAIaKmtgpKCjQ119/rU8//TRs/cyZM62fMzMzlZKSojFjxujIkSO6+uqrI3oth8Mhh8PRonkBAEDHEBVvY82ePVsbNmzQxx9/rD59+vzovtnZ2ZKkw4cPS5I8Ho+qq6vD9jm3fLH7fAAAwOXD1tgJhUKaPXu21q1bpy1btujKK6/8yefs3r1bkpSSkiJJ8nq92rt3r2pqaqx9Nm/eLKfTqYyMjDaZGwAAdBy2vo1VUFCgkpISvfPOO+rRo4d1j43L5VLXrl115MgRlZSUaMKECerZs6f27NmjefPmaeTIkRo0aJAkaezYscrIyNDUqVO1bNky+f1+LVy4UAUFBbxVBQAA7L2ys3LlStXV1WnUqFFKSUmxHmvXrpUkxcfH66OPPtLYsWM1YMAAPfjgg8rLy9O7775rHSMuLk4bNmxQXFycvF6v7r33Xk2bNi3se3kAAMDly9YrO6FQ6Ee3p6Wlqays7CeP07dvX73//vutNRYAADBIVNygDAAA0FaIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgtE52D3C5yJr/ut0jAFGp4tlpdo8AwHBc2QEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0SKKndGjR6u2tva89YFAQKNHj27pTAAAAK0motjZunWrGhoazlt/5swZffLJJ5d8nKKiIg0fPlw9evRQcnKyJk+erIMHD553zIKCAvXs2VPdu3dXXl6eqqurw/aprKzUxIkTlZCQoOTkZM2fP1+NjY2RnBoAADDMz/pSwT179lg/79+/X36/31puamrSxo0b9Ytf/OKSj1dWVqaCggINHz5cjY2NeuSRRzR27Fjt379f3bp1kyTNmzdP7733nt588025XC7Nnj1bt912mz777DPrdSdOnCiPx6PPP/9cVVVVmjZtmjp37qynnnrq55weAAAwUEwoFApd6s6xsbGKiYmRJF3oaV27dtWLL76o+++/P6JhTpw4oeTkZJWVlWnkyJGqq6tT7969VVJSottvv12SdODAAQ0cOFDl5eUaMWKEPvjgA91yyy06fvy43G63JGnVqlVasGCBTpw4ofj4+J983UAgIJfLpbq6Ojmdzohm/yl8gzJwYSZ8g3Ll0ky7RwCiUvqivW16/Ev9/f2zruwcPXpUoVBIV111lXbu3KnevXtb2+Lj45WcnKy4uLiIh66rq5MkJSUlSZIqKip09uxZ5eTkWPsMGDBA6enpVuyUl5crMzPTCh1Jys3N1axZs7Rv3z4NHTr0vNcJBoMKBoPWciAQiHhmAAAQ3X5W7PTt21eS1Nzc3OqDNDc3a+7cubrxxht1/fXXS5L8fr/i4+OVmJgYtq/b7bbeQvP7/WGhc277uW0XUlRUpCVLlrTyGQAAgGgU8R8CPXTokD7++GPV1NScFz+LFi362ccrKCjQ119/rU8//TTSkS5ZYWGhfD6ftRwIBJSWltbmrwsAANpfRLHz5z//WbNmzVKvXr3k8Xis+3gkKSYm5mfHzuzZs7VhwwZt27ZNffr0sdZ7PB41NDSotrY27OpOdXW1PB6Ptc/OnTvDjnfu01rn9vlfDodDDofjZ80IAAA6pog+ev7EE0/oySeflN/v1+7du/XVV19Zj127dl3ycUKhkGbPnq1169Zpy5YtuvLKK8O2Z2VlqXPnziotLbXWHTx4UJWVlfJ6vZIkr9ervXv3qqamxtpn8+bNcjqdysjIiOT0AACAQSK6svOvf/1Ld9xxR4tfvKCgQCUlJXrnnXfUo0cP6x4bl8ulrl27yuVyafr06fL5fEpKSpLT6dScOXPk9Xo1YsQISdLYsWOVkZGhqVOnatmyZfL7/Vq4cKEKCgq4egMAACK7snPHHXfoww8/bPGLr1y5UnV1dRo1apRSUlKsx9q1a619li9frltuuUV5eXkaOXKkPB6P3n77bWt7XFycNmzYoLi4OHm9Xt17772aNm2ali5d2uL5AABAxxfRlZ1+/frp0Ucf1fbt25WZmanOnTuHbf/d7353Sce5lK/46dKli4qLi1VcXHzRffr27av333//kl4TAABcXiKKnVdeeUXdu3dXWVmZysrKwrbFxMRccuwAAAC0tYhi5+jRo609BwAAQJuI6J4dAACAjiKiKzs/9bevXn311YiGAQAAaG0Rf/T8v509e1Zff/21amtrNXr06FYZDAAAoDVEFDvr1q07b11zc7NmzZqlq6++usVDAQAAtJZWu2cnNjZWPp9Py5cvb61DAgAAtFir3qB85MgRNTY2tuYhAQAAWiSit7H++y+GS//5csCqqiq99957ys/Pb5XBAAAAWkNEsfPVV1+FLcfGxqp37976wx/+8JOf1AIAAGhPEcXOxx9/3NpzAAAAtImIYuecEydO6ODBg5Kk/v37q3fv3q0yFAAAQGuJ6Abl+vp63X///UpJSdHIkSM1cuRIpaamavr06frhhx9ae0YAAICIRRQ7Pp9PZWVlevfdd1VbW6va2lq98847Kisr04MPPtjaMwIAAEQsorex/vGPf+itt97SqFGjrHUTJkxQ165d9etf/1orV65srfkAAABaJKIrOz/88IPcbvd565OTk3kbCwAARJWIYsfr9Wrx4sU6c+aMte7f//63lixZIq/X22rDAQAAtFREb2OtWLFC48aNU58+fTR48GBJ0j//+U85HA59+OGHrTogAABAS0QUO5mZmTp06JDWrFmjAwcOSJLuvvtuTZkyRV27dm3VAQEAAFoiotgpKiqS2+3WjBkzwta/+uqrOnHihBYsWNAqwwEAALRURPfs/OlPf9KAAQPOW3/ddddp1apVLR4KAACgtUQUO36/XykpKeet7927t6qqqlo8FAAAQGuJKHbS0tL02Wefnbf+s88+U2pqaouHAgAAaC0R3bMzY8YMzZ07V2fPntXo0aMlSaWlpXrooYf4BmUAABBVIoqd+fPn6/vvv9dvf/tbNTQ0SJK6dOmiBQsWqLCwsFUHBAAAaImIYicmJkbPPPOMHn30UX3zzTfq2rWrrrnmGjkcjtaeDwAAoEUiip1zunfvruHDh7fWLAAAAK0uohuUAQAAOgpiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEazNXa2bdumSZMmKTU1VTExMVq/fn3Y9t/85jeKiYkJe4wbNy5sn5MnT2rKlClyOp1KTEzU9OnTdfr06XY8CwAAEM1sjZ36+noNHjxYxcXFF91n3Lhxqqqqsh5/+9vfwrZPmTJF+/bt0+bNm7VhwwZt27ZNM2fObOvRAQBAB9Giv3reUuPHj9f48eN/dB+HwyGPx3PBbd988402btyoL774QsOGDZMkvfjii5owYYKee+45paamtvrMAACgY4n6e3a2bt2q5ORk9e/fX7NmzdL3339vbSsvL1diYqIVOpKUk5Oj2NhY7dix46LHDAaDCgQCYQ8AAGCmqI6dcePG6fXXX1dpaameeeYZlZWVafz48WpqapIk+f1+JScnhz2nU6dOSkpKkt/vv+hxi4qK5HK5rEdaWlqbngcAALCPrW9j/ZS77rrL+jkzM1ODBg3S1Vdfra1bt2rMmDERH7ewsFA+n89aDgQCBA8AAIaK6is7/+uqq65Sr169dPjwYUmSx+NRTU1N2D6NjY06efLkRe/zkf5zH5DT6Qx7AAAAM3Wo2Pn222/1/fffKyUlRZLk9XpVW1uriooKa58tW7aoublZ2dnZdo0JAACiiK1vY50+fdq6SiNJR48e1e7du5WUlKSkpCQtWbJEeXl58ng8OnLkiB566CH169dPubm5kqSBAwdq3LhxmjFjhlatWqWzZ89q9uzZuuuuu/gkFgAAkGTzlZ0vv/xSQ4cO1dChQyVJPp9PQ4cO1aJFixQXF6c9e/boV7/6la699lpNnz5dWVlZ+uSTT+RwOKxjrFmzRgMGDNCYMWM0YcIE3XTTTXrllVfsOiUAABBlbL2yM2rUKIVCoYtu37Rp008eIykpSSUlJa05FgAAMEiHumcHAADg5yJ2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNFtjZ9u2bZo0aZJSU1MVExOj9evXh20PhUJatGiRUlJS1LVrV+Xk5OjQoUNh+5w8eVJTpkyR0+lUYmKipk+frtOnT7fjWQAAgGhma+zU19dr8ODBKi4uvuD2ZcuW6YUXXtCqVau0Y8cOdevWTbm5uTpz5oy1z5QpU7Rv3z5t3rxZGzZs0LZt2zRz5sz2OgUAABDlOtn54uPHj9f48eMvuC0UCmnFihVauHChbr31VknS66+/LrfbrfXr1+uuu+7SN998o40bN+qLL77QsGHDJEkvvviiJkyYoOeee06pqakXPHYwGFQwGLSWA4FAK58ZAACIFlF7z87Ro0fl9/uVk5NjrXO5XMrOzlZ5ebkkqby8XImJiVboSFJOTo5iY2O1Y8eOix67qKhILpfLeqSlpbXdiQAAAFtFbez4/X5JktvtDlvvdrutbX6/X8nJyWHbO3XqpKSkJGufCyksLFRdXZ31OHbsWCtPDwAAooWtb2PZxeFwyOFw2D0GAABoB1F7Zcfj8UiSqqurw9ZXV1db2zwej2pqasK2NzY26uTJk9Y+AADg8ha1sXPllVfK4/GotLTUWhcIBLRjxw55vV5JktfrVW1trSoqKqx9tmzZoubmZmVnZ7f7zAAAIPrY+jbW6dOndfjwYWv56NGj2r17t5KSkpSenq65c+fqiSee0DXXXKMrr7xSjz76qFJTUzV58mRJ0sCBAzVu3DjNmDFDq1at0tmzZzV79mzdddddF/0kFgAAuLzYGjtffvmlfvnLX1rLPp9PkpSfn6/Vq1froYceUn19vWbOnKna2lrddNNN2rhxo7p06WI9Z82aNZo9e7bGjBmj2NhY5eXl6YUXXmj3cwEAANEpJhQKhewewm6BQEAul0t1dXVyOp1t8hpZ819vk+MCHV3Fs9PsHqHFKpdm2j0CEJXSF+1t0+Nf6u/vqL1nBwAAoDUQOwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGhRHTuPPfaYYmJiwh4DBgywtp85c0YFBQXq2bOnunfvrry8PFVXV9s4MQAAiDZRHTuSdN1116mqqsp6fPrpp9a2efPm6d1339Wbb76psrIyHT9+XLfddpuN0wIAgGjTye4BfkqnTp3k8XjOW19XV6e//OUvKikp0ejRoyVJf/3rXzVw4EBt375dI0aMuOgxg8GggsGgtRwIBFp/cAAAEBWi/srOoUOHlJqaqquuukpTpkxRZWWlJKmiokJnz55VTk6Ote+AAQOUnp6u8vLyHz1mUVGRXC6X9UhLS2vTcwAAAPaJ6tjJzs7W6tWrtXHjRq1cuVJHjx7V//3f/+nUqVPy+/2Kj49XYmJi2HPcbrf8fv+PHrewsFB1dXXW49ixY214FgAAwE5R/TbW+PHjrZ8HDRqk7Oxs9e3bV3//+9/VtWvXiI/rcDjkcDhaY0QAABDlovrKzv9KTEzUtddeq8OHD8vj8aihoUG1tbVh+1RXV1/wHh8AAHB56lCxc/r0aR05ckQpKSnKyspS586dVVpaam0/ePCgKisr5fV6bZwSAABEk6h+G+v3v/+9Jk2apL59++r48eNavHix4uLidPfdd8vlcmn69Ony+XxKSkqS0+nUnDlz5PV6f/STWAAA4PIS1bHz7bff6u6779b333+v3r1766abbtL27dvVu3dvSdLy5csVGxurvLw8BYNB5ebm6uWXX7Z5agAAEE2iOnbeeOONH93epUsXFRcXq7i4uJ0mAgAAHU2HumcHAADg5yJ2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YyJneLiYl1xxRXq0qWLsrOztXPnTrtHAgAAUcCI2Fm7dq18Pp8WL16sXbt2afDgwcrNzVVNTY3dowEAAJsZETt//OMfNWPGDN13333KyMjQqlWrlJCQoFdffdXu0QAAgM062T1ASzU0NKiiokKFhYXWutjYWOXk5Ki8vPyCzwkGgwoGg9ZyXV2dJCkQCLTZnE3Bf7fZsYGOrC3/3bWXU2ea7B4BiEpt/e/73PFDodCP7tfhY+e7775TU1OT3G532Hq3260DBw5c8DlFRUVasmTJeevT0tLaZEYAF+d68QG7RwDQVopc7fIyp06dkst18dfq8LETicLCQvl8Pmu5ublZJ0+eVM+ePRUTE2PjZGgPgUBAaWlpOnbsmJxOp93jAGhF/Pu+vIRCIZ06dUqpqak/ul+Hj51evXopLi5O1dXVYeurq6vl8Xgu+ByHwyGHwxG2LjExsa1GRJRyOp38zxAwFP++Lx8/dkXnnA5/g3J8fLyysrJUWlpqrWtublZpaam8Xq+NkwEAgGjQ4a/sSJLP51N+fr6GDRumG264QStWrFB9fb3uu+8+u0cDAAA2MyJ27rzzTp04cUKLFi2S3+/XkCFDtHHjxvNuWgak/7yNuXjx4vPeygTQ8fHvGxcSE/qpz2sBAAB0YB3+nh0AAIAfQ+wAAACjETsAAMBoxA4AADAasYPLSnFxsa644gp16dJF2dnZ2rlzp90jAWgF27Zt06RJk5SamqqYmBitX7/e7pEQRYgdXDbWrl0rn8+nxYsXa9euXRo8eLByc3NVU1Nj92gAWqi+vl6DBw9WcXGx3aMgCvHRc1w2srOzNXz4cL300kuS/vNN22lpaZozZ44efvhhm6cD0FpiYmK0bt06TZ482e5RECW4soPLQkNDgyoqKpSTk2Oti42NVU5OjsrLy22cDADQ1ogdXBa+++47NTU1nfet2m63W36/36apAADtgdgBAABGI3ZwWejVq5fi4uJUXV0dtr66uloej8emqQAA7YHYwWUhPj5eWVlZKi0ttdY1NzertLRUXq/XxskAAG3NiL96DlwKn8+n/Px8DRs2TDfccINWrFih+vp63XfffXaPBqCFTp8+rcOHD1vLR48e1e7du5WUlKT09HQbJ0M04KPnuKy89NJLevbZZ+X3+zVkyBC98MILys7OtnssAC20detW/fKXvzxvfX5+vlavXt3+AyGqEDsAAMBo3LMDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsADBWcXGxrrjiCnXp0kXZ2dnauXOn3SMBsAGxA8BIa9eulc/n0+LFi7Vr1y4NHjxYubm5qqmpsXs0AO2Mv40FwEjZ2dkaPny4XnrpJUlSc3Oz0tLSNGfOHD388MM2TwegPXFlB4BxGhoaVFFRoZycHGtdbGyscnJyVF5ebuNkAOxA7AAwznfffaempia53e6w9W63W36/36apANiF2AEAAEYjdgAYp1evXoqLi1N1dXXY+urqank8HpumAmAXYgeAceLj45WVlaXS0lJrXXNzs0pLS+X1em2cDIAdOtk9AAC0BZ/Pp/z8fA0bNkw33HCDVqxYofr6et133312jwagnRE7AIx055136sSJE1q0aJH8fr+GDBmijRs3nnfTMgDz8T07AADAaNyzAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGj/D07cPTCA+cw2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and testing:"
      ],
      "metadata": {
        "id": "qSgbLMaS-sqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previsores_train, previsores_test, classe_train, classe_test = train_test_split(previsores,\n",
        "                                                                               classe,\n",
        "                                                                               test_size = 0.25)"
      ],
      "metadata": {
        "id": "gld6l0R87haV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(previsores_train.shape, classe_train.shape, previsores_test.shape, classe_test.shape) # check the shapes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f57P4p8g_Tvj",
        "outputId": "82641a52-6595-4ee0-b545-0ead7280cda5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(426, 30) (426, 1) (143, 30) (143, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vS5ng2Uv-INV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformation into Tensors:\n",
        "\n",
        "##### Essential for processing on GPUs"
      ],
      "metadata": {
        "id": "iMjDJRI5-Qk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(previsores_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71ii63IR-TLU",
        "outputId": "90b08ba5-b702-44f0-89cd-530d54148665"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(np.array(previsores_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4_33HEb-XNQ",
        "outputId": "83132cd6-e69b-45f6-dee6-a73f7033a7bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores_train = torch.tensor(np.array(previsores_train), dtype = torch.float)\n",
        "classe_train = torch.tensor(np.array(classe_train), dtype = torch.float)"
      ],
      "metadata": {
        "id": "QjG2y_q7-gxZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(previsores_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg53Wqw2_Gci",
        "outputId": "0d876969-8905-40b7-880a-7a9a539a7cec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(classe_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLOVRRFr_eaX",
        "outputId": "813f0627-e207-4f5f-9675-2e713d63ead8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creation of a dataset with the union of predictors and classes:"
      ],
      "metadata": {
        "id": "wNCCss9tACcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.utils.data.TensorDataset(previsores_train, classe_train)"
      ],
      "metadata": {
        "id": "tYalOFt__g2-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn-Wkaa1AQvm",
        "outputId": "17c6e09e-668a-4496-bddc-ef74a106c1a9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.TensorDataset"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "h8yf2Y7MAU-K"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4sRCcHICBLuv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model building:"
      ],
      "metadata": {
        "id": "qBI-F7_DBMbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 30 neurÃ´nios no input = 30 atributos previsores\n",
        "# 16 neurÃ´nios 1Â° camada oculta\n",
        "# 16 neurÃ´nios 2Â° camada oculta\n",
        "# pq 16 neurÃ´nios nas redes ocultas? -> (entradas + saÃ­das) / 2 = (30+1)/2 = 16\n",
        "# 1 neurÃ´nio na camada de saÃ­da (probabilidade de uma classe 0 ou 1)\n",
        "\n",
        "classificador = nn.Sequential( # sequencia de camada\n",
        "\n",
        "    nn.Linear(in_features=30, out_features=16,), # Linear = todas as camadas de entrada ligado a todos de saÃ­da\n",
        "    nn.ReLU(), # funÃ§Ã£o de ativaÃ§Ã£o aplicado no 1Â° camdada de 16 neurÃ´nios\n",
        "\n",
        "    nn.Linear(16, 16), # Linear = todas as 16 camadas ligadas aos prÃ³ximos 16 neurÃ´nios\n",
        "    nn.ReLU(), # funÃ§Ã£o de ativaÃ§Ã£o aplicado no 2Â° camada de 16 neurÃ´nios\n",
        "\n",
        "    nn.Linear(16, 1), # Linear = todas as 16 camadas ligadas ao neurÃ´nio de saÃ­da\n",
        "    nn.Sigmoid(), # funÃ§Ã£o de ativaÃ§Ã£o na camada com 1 neurÃ´nio\n",
        ")\n"
      ],
      "metadata": {
        "id": "hdzyUVFuBOgG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# observar a estrutura da rede neural:\n",
        "\n",
        "classificador.parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBdDGExFEZP2",
        "outputId": "fc49e1c8-8dcf-4ccf-b563-4e69b6e94c45"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Sequential(\n",
              "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o de erro:\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "# Binary cross entropy (comparaÃ§Ã£o entre previsÃ£o e gabarito)"
      ],
      "metadata": {
        "id": "unaZfXUTE6PO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Otimizador\n",
        "\n",
        "optimizer = torch.optim.Adam(classificador.parameters(),\n",
        "                             lr = 0.001, # taxa de aprendizado\n",
        "                             weight_decay = 0.0001) # decaimento dos pesos\n",
        "                             # diminui lr com o passar das epocas"
      ],
      "metadata": {
        "id": "8OPpzysMFD4B"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NecessÃ¡rio um For para treinamento (diferente do TensorFLow ou Sklearn que tem um fit)\n",
        "for epoch in range(200): # Em 1 epoca passando por 426 registros de 10 em 10 (batch) registros\n",
        "  running_loss = 0. # Inicializar o acumulador do erro\n",
        "\n",
        "  for data in train_loader: # train_loader = dados dividido em 10 em 10 registros\n",
        "\n",
        "    inputs, labels = data # inputs=previsores e labels=classes\n",
        "    optimizer.zero_grad() # zerar, pq em cada ajuste de peso Ã© necessario calcular o gradiente separadamente\n",
        "\n",
        "    outputs = classificador(inputs) #passando os inputs no modelo e gerando os outputs -> processo forward na rede (esqeurda p/ direita)\n",
        "    # outputs-> classificador.forward(inputs)\n",
        "    loss = criterion(outputs, labels) #calculo do erro entre labels reais e preditos\n",
        "    loss.backward() #voltando e atualizando os pesos processo de backward na rede (direita p/ esquerda)\n",
        "    optimizer.step() #atualizaÃ§Ã£o dos pesos usando o \"Adam\"\n",
        "\n",
        "    running_loss += loss.item() #somatorio do erro\n",
        "  print('Ã‰poca %3d: perda %.5f' % (epoch+1, running_loss/len(train_loader)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV1iDbiCFiHm",
        "outputId": "ebb0f378-b59f-4134-e05f-c13f46b97c21"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã‰poca   1: perda 10.76845\n",
            "Ã‰poca   2: perda 2.76033\n",
            "Ã‰poca   3: perda 1.41596\n",
            "Ã‰poca   4: perda 0.70450\n",
            "Ã‰poca   5: perda 0.68355\n",
            "Ã‰poca   6: perda 0.38389\n",
            "Ã‰poca   7: perda 0.60377\n",
            "Ã‰poca   8: perda 0.28244\n",
            "Ã‰poca   9: perda 0.25952\n",
            "Ã‰poca  10: perda 0.24751\n",
            "Ã‰poca  11: perda 0.31085\n",
            "Ã‰poca  12: perda 0.23567\n",
            "Ã‰poca  13: perda 0.25210\n",
            "Ã‰poca  14: perda 0.23270\n",
            "Ã‰poca  15: perda 0.23848\n",
            "Ã‰poca  16: perda 0.20633\n",
            "Ã‰poca  17: perda 0.24387\n",
            "Ã‰poca  18: perda 0.28400\n",
            "Ã‰poca  19: perda 0.22199\n",
            "Ã‰poca  20: perda 0.22885\n",
            "Ã‰poca  21: perda 0.19840\n",
            "Ã‰poca  22: perda 0.26132\n",
            "Ã‰poca  23: perda 0.27163\n",
            "Ã‰poca  24: perda 0.22426\n",
            "Ã‰poca  25: perda 0.26579\n",
            "Ã‰poca  26: perda 0.22590\n",
            "Ã‰poca  27: perda 0.20857\n",
            "Ã‰poca  28: perda 0.20451\n",
            "Ã‰poca  29: perda 0.20278\n",
            "Ã‰poca  30: perda 0.20289\n",
            "Ã‰poca  31: perda 0.23885\n",
            "Ã‰poca  32: perda 0.19190\n",
            "Ã‰poca  33: perda 0.24389\n",
            "Ã‰poca  34: perda 0.38608\n",
            "Ã‰poca  35: perda 0.23924\n",
            "Ã‰poca  36: perda 0.26869\n",
            "Ã‰poca  37: perda 0.22983\n",
            "Ã‰poca  38: perda 0.35327\n",
            "Ã‰poca  39: perda 0.41073\n",
            "Ã‰poca  40: perda 0.23598\n",
            "Ã‰poca  41: perda 0.24683\n",
            "Ã‰poca  42: perda 0.17950\n",
            "Ã‰poca  43: perda 0.17404\n",
            "Ã‰poca  44: perda 0.20017\n",
            "Ã‰poca  45: perda 0.19187\n",
            "Ã‰poca  46: perda 0.16739\n",
            "Ã‰poca  47: perda 0.22035\n",
            "Ã‰poca  48: perda 0.20409\n",
            "Ã‰poca  49: perda 0.17189\n",
            "Ã‰poca  50: perda 0.18399\n",
            "Ã‰poca  51: perda 0.18035\n",
            "Ã‰poca  52: perda 0.18436\n",
            "Ã‰poca  53: perda 0.17365\n",
            "Ã‰poca  54: perda 0.19575\n",
            "Ã‰poca  55: perda 0.18712\n",
            "Ã‰poca  56: perda 0.18084\n",
            "Ã‰poca  57: perda 0.19334\n",
            "Ã‰poca  58: perda 0.19100\n",
            "Ã‰poca  59: perda 0.16328\n",
            "Ã‰poca  60: perda 0.19409\n",
            "Ã‰poca  61: perda 0.15603\n",
            "Ã‰poca  62: perda 0.21006\n",
            "Ã‰poca  63: perda 0.14880\n",
            "Ã‰poca  64: perda 0.17919\n",
            "Ã‰poca  65: perda 0.23830\n",
            "Ã‰poca  66: perda 0.24273\n",
            "Ã‰poca  67: perda 0.15340\n",
            "Ã‰poca  68: perda 0.16052\n",
            "Ã‰poca  69: perda 0.16396\n",
            "Ã‰poca  70: perda 0.17297\n",
            "Ã‰poca  71: perda 0.15893\n",
            "Ã‰poca  72: perda 0.15543\n",
            "Ã‰poca  73: perda 0.19978\n",
            "Ã‰poca  74: perda 0.18473\n",
            "Ã‰poca  75: perda 0.16940\n",
            "Ã‰poca  76: perda 0.13820\n",
            "Ã‰poca  77: perda 0.15342\n",
            "Ã‰poca  78: perda 0.17160\n",
            "Ã‰poca  79: perda 0.17440\n",
            "Ã‰poca  80: perda 0.19348\n",
            "Ã‰poca  81: perda 0.16987\n",
            "Ã‰poca  82: perda 0.15534\n",
            "Ã‰poca  83: perda 0.16130\n",
            "Ã‰poca  84: perda 0.15593\n",
            "Ã‰poca  85: perda 0.15051\n",
            "Ã‰poca  86: perda 0.15632\n",
            "Ã‰poca  87: perda 0.18837\n",
            "Ã‰poca  88: perda 0.16734\n",
            "Ã‰poca  89: perda 0.18310\n",
            "Ã‰poca  90: perda 0.17599\n",
            "Ã‰poca  91: perda 0.15742\n",
            "Ã‰poca  92: perda 0.16861\n",
            "Ã‰poca  93: perda 0.17069\n",
            "Ã‰poca  94: perda 0.18726\n",
            "Ã‰poca  95: perda 0.18152\n",
            "Ã‰poca  96: perda 0.16691\n",
            "Ã‰poca  97: perda 0.15681\n",
            "Ã‰poca  98: perda 0.14507\n",
            "Ã‰poca  99: perda 0.15358\n",
            "Ã‰poca 100: perda 0.15444\n",
            "Ã‰poca 101: perda 0.16903\n",
            "Ã‰poca 102: perda 0.13317\n",
            "Ã‰poca 103: perda 0.14649\n",
            "Ã‰poca 104: perda 0.12645\n",
            "Ã‰poca 105: perda 0.12825\n",
            "Ã‰poca 106: perda 0.13072\n",
            "Ã‰poca 107: perda 0.13557\n",
            "Ã‰poca 108: perda 0.13752\n",
            "Ã‰poca 109: perda 0.12574\n",
            "Ã‰poca 110: perda 0.12867\n",
            "Ã‰poca 111: perda 0.13926\n",
            "Ã‰poca 112: perda 0.17216\n",
            "Ã‰poca 113: perda 0.21998\n",
            "Ã‰poca 114: perda 0.15726\n",
            "Ã‰poca 115: perda 0.18958\n",
            "Ã‰poca 116: perda 0.10270\n",
            "Ã‰poca 117: perda 0.13913\n",
            "Ã‰poca 118: perda 0.11765\n",
            "Ã‰poca 119: perda 0.11724\n",
            "Ã‰poca 120: perda 0.11082\n",
            "Ã‰poca 121: perda 0.11524\n",
            "Ã‰poca 122: perda 0.11435\n",
            "Ã‰poca 123: perda 0.12975\n",
            "Ã‰poca 124: perda 0.18454\n",
            "Ã‰poca 125: perda 0.11940\n",
            "Ã‰poca 126: perda 0.10665\n",
            "Ã‰poca 127: perda 0.11657\n",
            "Ã‰poca 128: perda 0.12813\n",
            "Ã‰poca 129: perda 0.11541\n",
            "Ã‰poca 130: perda 0.10819\n",
            "Ã‰poca 131: perda 0.10836\n",
            "Ã‰poca 132: perda 0.11920\n",
            "Ã‰poca 133: perda 0.11772\n",
            "Ã‰poca 134: perda 0.09690\n",
            "Ã‰poca 135: perda 0.16700\n",
            "Ã‰poca 136: perda 0.14758\n",
            "Ã‰poca 137: perda 0.10124\n",
            "Ã‰poca 138: perda 0.12282\n",
            "Ã‰poca 139: perda 0.22560\n",
            "Ã‰poca 140: perda 0.18721\n",
            "Ã‰poca 141: perda 0.13104\n",
            "Ã‰poca 142: perda 0.12981\n",
            "Ã‰poca 143: perda 0.11923\n",
            "Ã‰poca 144: perda 0.10716\n",
            "Ã‰poca 145: perda 0.09304\n",
            "Ã‰poca 146: perda 0.09606\n",
            "Ã‰poca 147: perda 0.11234\n",
            "Ã‰poca 148: perda 0.12824\n",
            "Ã‰poca 149: perda 0.16136\n",
            "Ã‰poca 150: perda 0.13446\n",
            "Ã‰poca 151: perda 0.11991\n",
            "Ã‰poca 152: perda 0.16126\n",
            "Ã‰poca 153: perda 0.09770\n",
            "Ã‰poca 154: perda 0.09919\n",
            "Ã‰poca 155: perda 0.09344\n",
            "Ã‰poca 156: perda 0.08920\n",
            "Ã‰poca 157: perda 0.15663\n",
            "Ã‰poca 158: perda 0.13263\n",
            "Ã‰poca 159: perda 0.12572\n",
            "Ã‰poca 160: perda 0.11413\n",
            "Ã‰poca 161: perda 0.12353\n",
            "Ã‰poca 162: perda 0.09119\n",
            "Ã‰poca 163: perda 0.08393\n",
            "Ã‰poca 164: perda 0.08902\n",
            "Ã‰poca 165: perda 0.08175\n",
            "Ã‰poca 166: perda 0.11245\n",
            "Ã‰poca 167: perda 0.10994\n",
            "Ã‰poca 168: perda 0.09620\n",
            "Ã‰poca 169: perda 0.09483\n",
            "Ã‰poca 170: perda 0.09180\n",
            "Ã‰poca 171: perda 0.10098\n",
            "Ã‰poca 172: perda 0.10211\n",
            "Ã‰poca 173: perda 0.14015\n",
            "Ã‰poca 174: perda 0.09617\n",
            "Ã‰poca 175: perda 0.08932\n",
            "Ã‰poca 176: perda 0.08135\n",
            "Ã‰poca 177: perda 0.10858\n",
            "Ã‰poca 178: perda 0.10915\n",
            "Ã‰poca 179: perda 0.09978\n",
            "Ã‰poca 180: perda 0.10126\n",
            "Ã‰poca 181: perda 0.08059\n",
            "Ã‰poca 182: perda 0.07895\n",
            "Ã‰poca 183: perda 0.10244\n",
            "Ã‰poca 184: perda 0.08979\n",
            "Ã‰poca 185: perda 0.09937\n",
            "Ã‰poca 186: perda 0.11484\n",
            "Ã‰poca 187: perda 0.15320\n",
            "Ã‰poca 188: perda 0.10772\n",
            "Ã‰poca 189: perda 0.07588\n",
            "Ã‰poca 190: perda 0.07841\n",
            "Ã‰poca 191: perda 0.10055\n",
            "Ã‰poca 192: perda 0.08026\n",
            "Ã‰poca 193: perda 0.10969\n",
            "Ã‰poca 194: perda 0.10880\n",
            "Ã‰poca 195: perda 0.09223\n",
            "Ã‰poca 196: perda 0.10891\n",
            "Ã‰poca 197: perda 0.08487\n",
            "Ã‰poca 198: perda 0.08838\n",
            "Ã‰poca 199: perda 0.08587\n",
            "Ã‰poca 200: perda 0.09464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-GdMs6zMS3M"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization of weights:"
      ],
      "metadata": {
        "id": "VigzDj6-cglC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(classificador.parameters())\n"
      ],
      "metadata": {
        "id": "Q4c7IswAckt1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pesos0 = params[0]\n",
        "pesos0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuZaRTcPcvwm",
        "outputId": "9a5d9bfc-7fd6-4189-b80b-a956a56a8f75"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ligaÃ§Ã£o (pesos) entre todas os 30 inputs da camadas de entrada com os 16 neurÃ´nios da primeira camada oculta\n",
        "print(pesos0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi9bHgTsdH4K",
        "outputId": "1fe74b14-8b12-4d97-cf98-662ecf55cf25"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-1.9109e-01,  1.7119e-01, -3.5133e-01,  6.7053e-02, -8.2535e-02,\n",
            "          1.4880e-01, -1.0899e-01, -6.4639e-03,  3.3289e-02,  1.5473e-01,\n",
            "          1.7561e-01,  2.3933e-02,  5.5499e-02,  1.5561e-01,  1.0422e-02,\n",
            "         -3.9185e-02,  1.0401e-01, -1.9042e-02,  3.9523e-01,  1.0048e-01,\n",
            "         -4.3885e-01,  1.7833e-01, -3.0826e-01,  5.3839e-02, -3.4434e-01,\n",
            "         -1.5011e-01, -4.0621e-01, -2.5918e-01, -1.7752e-01,  8.8531e-02],\n",
            "        [ 6.0245e-02, -1.0450e-01, -1.3004e-01, -2.3399e-03,  1.2431e-01,\n",
            "          5.5083e-02,  1.0114e-01,  1.3782e-01, -6.1712e-02, -5.6312e-02,\n",
            "          1.1227e-01, -3.9852e-02,  4.2403e-02,  1.2821e-01,  2.0907e-02,\n",
            "         -1.5227e-02,  1.7265e-01, -1.2454e-01,  2.7212e-01,  1.6477e-01,\n",
            "         -4.9475e-01,  1.6507e-01, -3.2307e-01,  1.6869e-01,  1.1211e-01,\n",
            "          8.4064e-02,  4.9427e-02,  6.9157e-02,  1.5138e-01,  2.6271e-01],\n",
            "        [ 5.3393e-02, -3.6048e-01,  1.9123e-01, -6.2063e-02, -2.3654e-01,\n",
            "          2.9437e-01, -2.2583e-02, -2.6343e-01, -3.1568e-01,  3.1972e-01,\n",
            "         -1.2249e-02, -1.5986e-02,  1.0226e-01, -2.4990e-01, -2.3906e-03,\n",
            "         -9.8200e-03, -1.2362e-02,  1.0592e-02,  3.5716e-01,  8.6871e-03,\n",
            "          4.4761e-02, -4.8594e-01,  1.5956e-01, -1.4781e-01, -4.9534e-02,\n",
            "         -6.8493e-02,  1.0586e-01, -4.9942e-01, -3.1793e-01, -1.3229e-01],\n",
            "        [ 1.6202e-01, -1.0245e-01,  3.9663e-01,  1.6837e-01, -3.6291e-01,\n",
            "         -2.6007e-02,  4.2681e-03, -1.9713e-02,  7.3011e-02, -2.8490e-01,\n",
            "         -1.2632e-01,  3.8419e-02, -3.0385e-03, -2.2152e-01, -4.3782e-02,\n",
            "          8.4855e-02, -5.3845e-01,  2.4525e-01, -4.7251e-01, -3.8596e-01,\n",
            "          5.2120e-01, -2.2353e-01,  2.5074e-01, -1.6355e-01, -8.5662e-02,\n",
            "         -1.1594e-02,  4.2649e-02, -7.0178e-02, -7.1906e-02, -4.5268e-01],\n",
            "        [ 1.2740e-02, -4.3677e-02, -1.6838e-02, -1.3512e-01, -6.0313e-32,\n",
            "         -5.8427e-02, -2.7369e-02, -6.0153e-40, -1.0940e-14, -2.9099e-40,\n",
            "          8.9260e-02,  4.0706e-02, -1.2399e-01,  1.8194e-01,  6.8583e-39,\n",
            "          1.2462e-39, -1.8743e-40, -6.0793e-40,  1.9228e-39,  5.0032e-39,\n",
            "          3.8394e-02, -1.1228e-01,  1.1330e-01, -1.5684e-01, -5.4219e-19,\n",
            "          1.3362e-04,  1.1202e-01,  2.7237e-10,  3.0164e-07, -2.5747e-31],\n",
            "        [ 8.7365e-02, -5.5755e-02,  1.5032e-01, -1.1616e-01,  4.4513e-01,\n",
            "         -4.2501e-01,  4.1392e-01,  3.0201e-01,  9.3819e-02,  1.3972e-01,\n",
            "          2.2496e-01,  2.3970e-02,  3.3548e-02, -1.9573e-01, -3.2279e-04,\n",
            "         -6.7212e-02, -8.7188e-02, -8.5549e-03, -4.3734e-01, -1.1263e-01,\n",
            "          8.5493e-02, -2.5447e-01,  1.6594e-01, -1.0261e-01,  1.6214e-01,\n",
            "         -2.6627e-01, -1.2194e-01,  2.2085e-01,  3.4026e-01, -5.4476e-01],\n",
            "        [ 1.7783e-01, -4.4106e-02,  2.3066e-01, -7.8582e-02, -3.3627e-02,\n",
            "          6.3778e-02,  7.9301e-03, -1.9668e-03, -7.9845e-02,  5.8246e-01,\n",
            "         -1.0881e-01, -8.0382e-02,  5.9928e-02,  1.9096e-01, -7.9217e-03,\n",
            "         -6.4485e-02, -8.4906e-02,  4.8214e-02,  3.6833e-02, -8.8733e-02,\n",
            "          6.8076e-02, -3.8759e-01,  2.6998e-01,  3.5000e-03,  2.7508e-01,\n",
            "         -1.2780e-01, -3.1831e-02, -2.1749e-01, -2.7500e-02, -2.0906e-01],\n",
            "        [ 5.7003e-02, -6.2751e-02, -3.2490e-01, -1.3738e-01,  3.1967e-01,\n",
            "         -1.9218e-01,  2.6620e-01, -5.5588e-01, -4.7959e-01, -8.8720e-02,\n",
            "         -2.6206e-01,  1.1074e-01, -4.2252e-02, -4.8129e-02,  1.0616e-02,\n",
            "         -6.2552e-02,  1.2904e-01,  2.4702e-02,  4.6398e-01,  1.2203e-01,\n",
            "         -3.4602e-01,  1.5294e-01, -4.9680e-03,  1.5571e-01,  2.7311e-01,\n",
            "         -3.0224e-01, -4.4879e-01, -5.9367e-01, -2.6055e-01,  1.9416e-01],\n",
            "        [ 2.9444e-02, -1.4605e-02, -1.8192e-02, -8.6972e-02,  7.0128e-39,\n",
            "          1.5008e-39, -4.0711e-39, -6.0414e-39, -2.0532e-02,  2.2711e-40,\n",
            "         -2.1016e-02, -1.2387e-01, -2.7138e-02, -1.9579e-02, -2.4147e-39,\n",
            "          1.7785e-39,  7.0468e-39, -1.0210e-39,  1.2438e-39, -1.4174e-41,\n",
            "          4.1239e-03, -3.8457e-02,  5.3675e-02, -7.2494e-02,  3.5326e-40,\n",
            "          8.7971e-02, -1.7467e-39,  1.5952e-39, -2.2319e-39,  1.6784e-39],\n",
            "        [ 2.2548e-01, -1.2939e-01,  3.6435e-01,  1.8516e-01, -3.9770e-01,\n",
            "         -3.8739e-01, -6.6612e-02, -5.7266e-02,  4.0501e-02,  3.9107e-01,\n",
            "          7.8121e-02, -1.6983e-01,  1.0653e-02, -2.7053e-01, -1.5042e-02,\n",
            "         -1.8287e-01, -1.7684e-01,  1.8289e-01,  6.7462e-01, -1.8181e-02,\n",
            "          2.9171e-01, -2.2551e-01,  5.9957e-02, -1.7515e-01,  1.1489e-01,\n",
            "         -3.7054e-02,  1.0844e-02,  5.0582e-02,  1.1100e-01, -1.5913e-01],\n",
            "        [ 4.7109e-02,  4.1930e-01,  4.7875e-02, -1.5006e-01,  1.3259e-02,\n",
            "          8.4557e-02, -6.7133e-02,  1.9134e-01,  7.5042e-02, -3.3179e-01,\n",
            "          2.2486e-01,  3.1111e-02, -1.4620e-01,  9.9260e-02, -1.5633e-03,\n",
            "          3.3660e-03,  2.5398e-02,  1.1493e-01, -3.1818e-01, -2.7920e-03,\n",
            "          5.0518e-02,  4.3757e-01,  2.3328e-01,  7.1771e-02, -5.1580e-02,\n",
            "          1.9559e-01, -9.5885e-02, -1.7284e-01, -4.1491e-02, -1.8689e-02],\n",
            "        [ 1.0631e-01,  3.1562e-06, -3.1980e-02, -1.0431e-01, -6.7779e-39,\n",
            "         -9.7354e-40, -2.3028e-39,  1.5075e-39, -2.5239e-11,  5.5889e-40,\n",
            "         -8.9289e-04, -6.8156e-03, -2.1411e-02, -7.0044e-03, -2.3854e-39,\n",
            "         -6.2640e-39,  1.1607e-06, -2.8456e-39, -7.5635e-40, -5.3912e-39,\n",
            "          1.4368e-05,  4.6749e-04,  3.6092e-02,  5.7202e-02, -1.2362e-39,\n",
            "          4.8878e-08, -3.4613e-40, -1.0901e-04,  1.6526e-39, -5.0730e-39],\n",
            "        [ 1.7420e-01,  7.7155e-02,  6.7565e-03,  2.5253e-02, -4.7351e-02,\n",
            "          6.8162e-01, -5.1798e-01,  2.1403e-01,  4.5151e-02,  2.9059e-01,\n",
            "          2.9810e-01,  7.0551e-02, -9.8824e-02, -4.0845e-02, -1.7333e-03,\n",
            "         -8.2368e-02, -5.6492e-02, -3.5833e-02, -1.4639e-01, -2.8896e-01,\n",
            "          3.1379e-01, -1.5832e-01,  1.2645e-01,  1.1271e-01,  1.3234e-01,\n",
            "          1.5143e-01, -2.3298e-01, -9.0475e-02, -7.4525e-02, -3.7030e-01],\n",
            "        [-2.3428e-01, -2.0350e-01, -4.4740e-02,  1.1510e-01,  2.1487e-01,\n",
            "         -2.6051e-01, -1.3642e-01, -1.6553e-01,  1.7919e-01, -5.4929e-01,\n",
            "         -1.4165e-01,  5.0645e-02, -1.1018e-01, -3.6597e-02, -1.2504e-03,\n",
            "          5.1219e-02, -5.5681e-02, -7.6748e-03, -5.3904e-01,  9.8482e-04,\n",
            "         -2.3915e-01, -9.3650e-02,  4.3562e-02,  9.9972e-02,  2.6139e-01,\n",
            "          7.3143e-02,  2.6418e-01,  3.1898e-01,  5.6186e-02,  2.3767e-02],\n",
            "        [-2.8120e-01, -6.3165e-01, -3.5830e-01,  9.3751e-02,  3.2995e-01,\n",
            "          5.0825e-02,  8.3178e-02, -4.8795e-01, -2.2272e-01,  5.7035e-01,\n",
            "          1.5476e-01,  1.5068e-02, -8.8991e-02,  1.6400e-01,  1.4352e-03,\n",
            "         -1.2758e-01,  1.5152e-02, -2.9043e-02,  5.4106e-01,  2.2595e-03,\n",
            "         -3.3905e-01, -4.8606e-01, -2.1101e-01,  9.8931e-02, -7.8130e-02,\n",
            "         -2.7056e-01, -2.1831e-01,  1.0851e-01,  2.3163e-01,  2.6162e-01],\n",
            "        [ 5.8259e-02, -3.2516e-01,  5.9466e-02,  4.7188e-02,  1.6176e-02,\n",
            "         -8.1594e-02, -9.8772e-02,  2.5131e-01,  2.1993e-01, -1.2665e-01,\n",
            "         -6.0385e-02,  2.5328e-03,  2.1755e-02, -3.2245e-01, -2.5420e-02,\n",
            "         -3.2635e-02, -2.2874e-01, -1.2959e-02, -2.4947e-01, -1.7948e-01,\n",
            "          4.1487e-01, -2.1759e-01,  2.7082e-01, -5.3811e-02,  4.4917e-02,\n",
            "          1.1310e-01,  1.6183e-01,  3.0095e-02,  6.3122e-02, -2.7205e-01]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unidade de bias na 1Â° camada oculta\n",
        "bias0 = params[1]\n",
        "bias0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZRBS5m1ddWV",
        "outputId": "dcd5defa-81dd-4bbd-892e-952ebb102307"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ligaÃ§Ã£o (pesos) entre todas os 16 neurÃ´nios da primeira camada oculta com os 16 neurÃ´nios da segunda camada oculta.\n",
        "pesos1 = params[2]\n",
        "pesos1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p6BK-pFd_ol",
        "outputId": "ebb9ae31-6795-4de6-c82b-fe72d1406abc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unidade de bias na 2Â° camada oculta\n",
        "bias1 = params[3]\n",
        "bias1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5GZVMXZeK7r",
        "outputId": "a49b19ac-fe7f-40fd-e21a-266dc195398a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fr3wtnXae1xo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model evaluation:"
      ],
      "metadata": {
        "id": "NmUp-V8SfD31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.eval() # .eval = significa que o classificador em modo avaliaÃ§Ã£o\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfDvxf0qfFnk",
        "outputId": "3ffb59d1-ffa1-4acd-8317-8dec9fffd834"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(previsores_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQNa5mbTgyEH",
        "outputId": "23c8f4c1-6626-4d6e-8092-db60b31a9b41"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores_test = torch.tensor(np.array(previsores_test), dtype=torch.float)"
      ],
      "metadata": {
        "id": "_IogBHRgg6Zn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(previsores_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlrl_6fchGMk",
        "outputId": "0f1cfd6c-4fa3-430e-aeef-03b333e6565a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes = classificador.forward(previsores_test) # passar pela rede neural em forward"
      ],
      "metadata": {
        "id": "j5moNpFOhIZc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probabilidade entre 0 e 1\n",
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta9pu3pAhZ_2",
        "outputId": "63c8ae31-d234-4482-b050-05770dd750c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.5830e-01],\n",
              "        [1.1794e-07],\n",
              "        [2.1472e-04],\n",
              "        [9.9999e-01],\n",
              "        [9.9995e-01],\n",
              "        [2.1025e-09],\n",
              "        [5.3036e-09],\n",
              "        [5.6333e-01],\n",
              "        [9.9973e-01],\n",
              "        [9.9247e-01],\n",
              "        [9.9428e-01],\n",
              "        [3.7188e-03],\n",
              "        [9.9941e-01],\n",
              "        [3.2833e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.5526e-01],\n",
              "        [9.9908e-01],\n",
              "        [9.9870e-01],\n",
              "        [1.0000e+00],\n",
              "        [2.2425e-07],\n",
              "        [3.5586e-04],\n",
              "        [9.6723e-01],\n",
              "        [9.0230e-13],\n",
              "        [9.9974e-01],\n",
              "        [9.9261e-01],\n",
              "        [9.9957e-01],\n",
              "        [9.9910e-01],\n",
              "        [9.9999e-01],\n",
              "        [9.8977e-01],\n",
              "        [1.5022e-06],\n",
              "        [9.9992e-01],\n",
              "        [9.9919e-01],\n",
              "        [1.0000e+00],\n",
              "        [4.5617e-01],\n",
              "        [9.9948e-01],\n",
              "        [9.9989e-01],\n",
              "        [7.6538e-04],\n",
              "        [9.8525e-01],\n",
              "        [3.1276e-08],\n",
              "        [5.8282e-01],\n",
              "        [9.6287e-01],\n",
              "        [9.1047e-03],\n",
              "        [9.9858e-01],\n",
              "        [8.3760e-01],\n",
              "        [9.9999e-01],\n",
              "        [9.9981e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [9.8145e-01],\n",
              "        [9.6172e-01],\n",
              "        [1.1653e-07],\n",
              "        [1.5650e-06],\n",
              "        [9.9921e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9993e-01],\n",
              "        [8.9572e-01],\n",
              "        [9.9938e-01],\n",
              "        [1.6846e-09],\n",
              "        [1.3368e-01],\n",
              "        [9.9776e-01],\n",
              "        [8.3532e-01],\n",
              "        [1.6518e-10],\n",
              "        [3.2335e-09],\n",
              "        [9.4783e-01],\n",
              "        [9.9997e-01],\n",
              "        [9.6794e-01],\n",
              "        [3.4029e-04],\n",
              "        [2.6453e-01],\n",
              "        [9.9990e-01],\n",
              "        [9.9836e-01],\n",
              "        [9.9960e-01],\n",
              "        [7.1519e-08],\n",
              "        [9.9695e-01],\n",
              "        [7.6372e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9009e-01],\n",
              "        [9.7956e-01],\n",
              "        [3.2347e-01],\n",
              "        [9.7130e-01],\n",
              "        [9.9998e-01],\n",
              "        [5.9762e-01],\n",
              "        [9.9622e-01],\n",
              "        [9.9990e-01],\n",
              "        [2.9441e-08],\n",
              "        [2.9942e-02],\n",
              "        [1.6208e-01],\n",
              "        [3.1008e-07],\n",
              "        [2.6633e-05],\n",
              "        [1.0000e+00],\n",
              "        [9.6723e-01],\n",
              "        [9.7988e-01],\n",
              "        [8.9134e-01],\n",
              "        [5.2207e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9999e-01],\n",
              "        [1.0000e+00],\n",
              "        [4.9178e-07],\n",
              "        [1.9282e-04],\n",
              "        [9.9990e-01],\n",
              "        [1.3748e-03],\n",
              "        [7.5979e-07],\n",
              "        [1.0000e+00],\n",
              "        [1.1767e-06],\n",
              "        [2.1894e-06],\n",
              "        [9.9313e-01],\n",
              "        [9.9753e-01],\n",
              "        [9.5841e-01],\n",
              "        [2.9095e-14],\n",
              "        [5.1248e-01],\n",
              "        [9.4507e-01],\n",
              "        [1.6718e-03],\n",
              "        [9.2104e-01],\n",
              "        [9.9932e-01],\n",
              "        [3.2114e-16],\n",
              "        [1.0000e+00],\n",
              "        [1.3973e-10],\n",
              "        [1.0000e+00],\n",
              "        [9.8606e-01],\n",
              "        [9.9943e-01],\n",
              "        [7.1841e-02],\n",
              "        [6.3001e-02],\n",
              "        [9.9954e-01],\n",
              "        [9.9911e-01],\n",
              "        [5.3717e-07],\n",
              "        [9.9963e-01],\n",
              "        [3.6365e-11],\n",
              "        [4.9113e-07],\n",
              "        [1.0000e+00],\n",
              "        [9.9782e-01],\n",
              "        [6.0853e-13],\n",
              "        [4.5824e-08],\n",
              "        [1.6088e-01],\n",
              "        [7.2409e-01],\n",
              "        [9.9479e-01],\n",
              "        [8.4714e-02],\n",
              "        [9.7630e-01],\n",
              "        [9.9963e-01],\n",
              "        [9.9931e-01],\n",
              "        [9.9626e-01],\n",
              "        [5.6200e-05],\n",
              "        [9.9580e-01],\n",
              "        [1.8291e-13],\n",
              "        [9.9811e-01]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limiar de classificaÃ§Ã£o\n",
        "\n",
        "previsoes = np.array(previsoes> 0.5) # valor 0.5 de acordo com o cenÃ¡rio\n",
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F6bTn7shbtu",
        "outputId": "643ad091-f13d-4777-c5b3-e298b8427cf7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1XhZgdei5_u",
        "outputId": "6dad61d2-c233-4a7f-ad0d-0d0936b556f7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gqzQto-YilA0",
        "outputId": "ccaf5011-a834-42ba-f9ca-f5e115161e05"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0\n",
              "204  1\n",
              "70   0\n",
              "131  0\n",
              "431  1\n",
              "540  1\n",
              "..  ..\n",
              "89   1\n",
              "199  0\n",
              "411  1\n",
              "18   0\n",
              "390  1\n",
              "\n",
              "[143 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-5a3f64a2-2688-4734-9ff9-b68421778c35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a3f64a2-2688-4734-9ff9-b68421778c35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-7c06b228-0689-4117-b217-4cef4d2d57c4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c06b228-0689-4117-b217-4cef4d2d57c4')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-7c06b228-0689-4117-b217-4cef4d2d57c4 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a3f64a2-2688-4734-9ff9-b68421778c35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a3f64a2-2688-4734-9ff9-b68421778c35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taxa de acerto, comparaÃ§Ã£o entre as etiquetas 0 e 1 com as str True e False:\n",
        "\n",
        "taxa_acerto = accuracy_score(classe_test, previsoes)\n",
        "taxa_acerto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k_J_Ug8h_YX",
        "outputId": "fa02795b-91d5-4430-e368-df7e6f85c190"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9230769230769231"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix de confusÃ£o:\n",
        "\n",
        "matrix = confusion_matrix(classe_test, previsoes)\n",
        "matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsDIRHeCiPUM",
        "outputId": "51c4867d-be0c-49c7-ef5d-4723f20bcc16"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[47,  7],\n",
              "       [ 4, 85]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(matrix, annot=True);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "wMInwLwakmxe",
        "outputId": "0dd27c23-7155-4741-c3c9-0317433fba71"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGdCAYAAAAczXrvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkY0lEQVR4nO3df3QU5dn/8c8GkiUFs5gAu4kSjIANiggGDSv4C6MpRYQSUSy2UWlpbUwLW+UxfQRbS11/QxGByoMoVary/QoVvxWqsQ1yDL+iWBVBRB6iwi7FmkSCWXjYff7ot9vuEDWrs5ntzPvluc8x98zec+V48OK65p5ZVywWiwkAADhGhtUBAACAzkXyBwDAYUj+AAA4DMkfAACHIfkDAOAwJH8AAByG5A8AgMOQ/AEAcBiSPwAADtPV6gD+YXv/sVaHAKQdf3iH1SEAaan50O6Urn/04HumrZXZ61TT1jJL2iR/AADSRvSY1RGkFG1/AAAchsofAACjWNTqCFKK5A8AgFGU5A8AgKPEbF75c88fAACHofIHAMCItj8AAA5D2x8AANgJlT8AAEY2f8kPyR8AACPa/gAAwE6o/AEAMGK3PwAAzsJLfgAAgK1Q+QMAYETbHwAAh6HtDwCAw0SPmTeScOzYMc2aNUtFRUXKzs5W//799ctf/lKxWCx+TiwW0+zZs5Wfn6/s7GyVlZVp165dSV2H5A8AQJq4++67tWjRIi1YsEBvv/227r77bt1zzz168MEH4+fcc889mj9/vhYvXqxNmzape/fuKi8vV1tbW4evQ9sfAAAji9r+r7zyisaPH6+xY8dKkk455RT97ne/0+bNm/8eViymefPm6bbbbtP48eMlScuXL5fX69Xq1as1efLkDl2Hyh8AAKNo1LQRiUTU0tKSMCKRSLuXPe+881RbW6t33nlHkvT6669rw4YNGjNmjCRpz549CoVCKisri3/G4/GotLRU9fX1Hf71SP4AAKRQMBiUx+NJGMFgsN1zb731Vk2ePFnFxcXKzMzUsGHDNH36dE2ZMkWSFAqFJElerzfhc16vN36sI2j7AwBgZGLbv6amRoFAIGHO7Xa3e+7TTz+tJ554QitWrNAZZ5yhbdu2afr06SooKFBlZaVpMZH8AQAwMvE5f7fb/ZnJ3uiWW26JV/+SdOaZZ2rv3r0KBoOqrKyUz+eTJIXDYeXn58c/Fw6HNXTo0A7HRNsfAIA0cfjwYWVkJKbmLl26KPr//zJSVFQkn8+n2tra+PGWlhZt2rRJfr+/w9eh8gcAwCAWS+75fLOMGzdOv/rVr1RYWKgzzjhDr732mh544AHdcMMNkiSXy6Xp06drzpw5GjhwoIqKijRr1iwVFBRowoQJHb4OyR8AACOLHvV78MEHNWvWLP3oRz/SgQMHVFBQoB/84AeaPXt2/JyZM2eqtbVV06ZNU1NTk0aNGqW1a9eqW7duHb6OK/avrw2y0Pb+Y60OAUg7/vAOq0MA0lLzod0pXb9t23OmrdVt6OWmrWUWKn8AAIz4Yh8AABzG5l/sQ/IHAMAoyS/k+XfDo34AADgMlT8AAEa0/QEAcBibb/ij7Q8AgMNQ+QMAYETbHwAAh6HtDwAA7ITKHwAAI5tX/iR/AAAMrPpWv85C2x8AAIeh8gcAwIi2PwAADsOjfgAAOIzNK3/u+QMA4DBU/gAAGNH2BwDAYWj7AwAAO6HyBwDAiLY/AAAOQ9sfAADYCZU/AABGNq/8Sf4AABjZ/J4/bX8AAByGyh8AACPa/gAAOIzN2/4kfwAAjGxe+XPPHwAAh6HyBwDAiLY/AAAOQ9sfAADYCZU/AABGNq/8Sf4AABjFYlZHkFK0/QEASBOnnHKKXC7XcaOqqkqS1NbWpqqqKuXl5alHjx6qqKhQOBxO+jokfwAAjKJR80YStmzZov3798fHCy+8IEmaNGmSJGnGjBlas2aNVq5cqbq6Ou3bt08TJ05M+tej7Q8AgJFF9/x79+6d8PNdd92l/v3768ILL1Rzc7OWLl2qFStWaPTo0ZKkZcuWadCgQdq4caNGjBjR4etQ+QMAkEKRSEQtLS0JIxKJfOHnjhw5oscff1w33HCDXC6XGhoadPToUZWVlcXPKS4uVmFhoerr65OKieQPAIBRLGraCAaD8ng8CSMYDH5hCKtXr1ZTU5Ouu+46SVIoFFJWVpZ69uyZcJ7X61UoFErq16PtDwCAkYlt/5qaGgUCgYQ5t9v9hZ9bunSpxowZo4KCAtNi+QeSPwAARiY+6ud2uzuU7P/V3r179eKLL+qZZ56Jz/l8Ph05ckRNTU0J1X84HJbP50tqfdr+AACkmWXLlqlPnz4aO3ZsfK6kpESZmZmqra2Nz+3cuVONjY3y+/1JrU/lDwCAkYVv+ItGo1q2bJkqKyvVtes/07TH49HUqVMVCASUm5urnJwcVVdXy+/3J7XTXyL5AwBwPAuT/4svvqjGxkbdcMMNxx2bO3euMjIyVFFRoUgkovLyci1cuDDpa7hisfR4h+H2/mO/+CTAYfzhHVaHAKSl5kO7U7r+p0tvNm2t7Kn3mbaWWaj8AQAwivHFPgAAOEosmhZN8ZRhtz8AAA5D5Q8AgJGFG/46A8kfAAAjm9/zp+0PAIDDUPkDAGBk8w1/JH8AAIy45w8AgMPYPPlzzx8AAIeh8gcAwCg93nyfMiR/KO8Hk+SdeZ0+WrZa4TlLlHlSHw1cv6zdc9+/KahPnt/QyREC1vjLW3Xq1+/k4+aXPPxb3Rz4eafHg05k87Y/yd/hup05UCde8w21vf1efO7o/oPaWXptwnknTv6G8r4/UYfqtnZ2iIBlLr7wW+qS8c+7o6effpp+/9xvtXrV8xZGBXx1JH8Hc32tm06ae4v2/+xB9aq6+p8HolEdO/hxwrknXOZXyx82KHa4rZOjBKzz0cG/Jfw846c/1Hu792rDy5ssigidxuaP+rHhz8Hyf3GjDv1pi1pf2fa553UbPEDZZ/RX08o/dk5gQBrKzMzU1ZPH6/HfrrQ6FHSGWNS8kYaSrvwPHjyoRx55RPX19QqFQpIkn8+n8847T9ddd5169+5tepAwX87lF6jbGQO0Z8L0Lzy356TLFNnVqE9ffTv1gQFp6vJxl8rjydETj/9fq0MBvrKkKv8tW7botNNO0/z58+XxeHTBBRfoggsukMfj0fz581VcXKytW7/4nnAkElFLS0vCOBI79qV/CSSna34v+WZN04cz7lXsyNHPPdflzpLnigv1MVU/HO47352kF/5Yp1DogNWhoDNEY+aNNJRU5V9dXa1JkyZp8eLFcrlcCcdisZh++MMfqrq6WvX19Z+7TjAY1C9+8YuEuR/1HKCq3NOSCQdfUvbgAera60Sd+uz8+Jyraxd97dzByv3OOL09aEJ8p2vOmJHK6OZW86pai6IFrNe3b4Euunikrv32j6wOBZ0kZvPd/q5YrOMPM2ZnZ+u1115TcXFxu8d37NihYcOG6dNPP/3cdSKRiCKRSMLce0OvUparS0dDwVeQ0T1bmSf1SZgruHu6Irs/0EcP/x9F3tkbn+/3RFDHPm7RBzcFOztMSPKHd1gdAiTd+rMf6/obrtHpXx+lY8foUqaD5kO7U7p+a7DStLW61zxm2lpmSary9/l82rx582cm/82bN8vr9X7hOm63W263O2GOxN95oq2fJiR4SYoebtOxppaE+cx++frauYPVOPXnnRwhkD5cLpemXHulfvfEMyR+J0nTdr1Zkkr+N998s6ZNm6aGhgZdcskl8UQfDodVW1urJUuW6L777ktJoOh8J155qf4ndFCtL79qdSiAZS6+eKQKC0/Sb9nl7yxpukvfLEm1/SXpqaee0ty5c9XQ0BD/W3CXLl1UUlKiQCCgq6666ksFsr3/2C/1OcDOaPsD7Ut52/+OKaat1X32E6atZZakH/W7+uqrdfXVV+vo0aM6ePCgJKlXr17KzMw0PTgAAGC+L/2Gv8zMTOXn55sZCwAA6cHmu/15vS8AAEY23/DH630BAHAYKn8AAIxsvtuf5A8AgBFtfwAAYCdU/gAAGNj93f4kfwAAjGj7AwAAO6HyBwDAyOaVP8kfAAAjHvUDAMBhbF75c88fAIA08uGHH+raa69VXl6esrOzdeaZZ2rr1q3x47FYTLNnz1Z+fr6ys7NVVlamXbt2JXUNkj8AAAaxaMy0kYyPP/5YI0eOVGZmpp5//nlt375d999/v0488cT4Offcc4/mz5+vxYsXa9OmTerevbvKy8vV1tbW4evQ9gcAwMiitv/dd9+tvn37atmyZfG5oqKi+L/HYjHNmzdPt912m8aPHy9JWr58ubxer1avXq3Jkyd36DpU/gAApFAkElFLS0vCiEQi7Z777LPPavjw4Zo0aZL69OmjYcOGacmSJfHje/bsUSgUUllZWXzO4/GotLRU9fX1HY6J5A8AgFE0atoIBoPyeDwJIxgMtnvZ9957T4sWLdLAgQO1bt063Xjjjfrxj3+sxx57TJIUCoUkSV6vN+FzXq83fqwjaPsDAGBkYtu/pqZGgUAgYc7tdrd/2WhUw4cP15133ilJGjZsmN58800tXrxYlZWVpsVE5Q8AQAq53W7l5OQkjM9K/vn5+Tr99NMT5gYNGqTGxkZJks/nkySFw+GEc8LhcPxYR5D8AQAwisbMG0kYOXKkdu7cmTD3zjvvqF+/fpL+vvnP5/OptrY2frylpUWbNm2S3+/v8HVo+wMAYBCLWbPbf8aMGTrvvPN055136qqrrtLmzZv18MMP6+GHH5YkuVwuTZ8+XXPmzNHAgQNVVFSkWbNmqaCgQBMmTOjwdUj+AACkiXPOOUerVq1STU2N7rjjDhUVFWnevHmaMmVK/JyZM2eqtbVV06ZNU1NTk0aNGqW1a9eqW7duHb6OK2bVX28Mtvcfa3UIQNrxh3dYHQKQlpoP7U7p+i3fv8y0tXKW/NG0tcxC5Q8AgJHN3+1P8gcAwCDZ1/L+u2G3PwAADkPlDwCAkc0rf5I/AABGUasDSC3a/gAAOAyVPwAABnbf8EfyBwDAyObJn7Y/AAAOQ+UPAICRzTf8kfwBADCw+z1/2v4AADgMlT8AAEa0/QEAcBa7t/1J/gAAGNm88ueePwAADkPlDwCAQczmlT/JHwAAI5snf9r+AAA4DJU/AAAGtP0BAHAamyd/2v4AADgMlT8AAAa0/QEAcBiSPwAADmP35M89fwAAHIbKHwAAo5jL6ghSiuQPAIABbX8AAGArVP4AABjEorT9AQBwFNr+AADAVqj8AQAwiLHbHwAAZ6HtDwAAOsXPf/5zuVyuhFFcXBw/3tbWpqqqKuXl5alHjx6qqKhQOBxO+jokfwAADGJRl2kjWWeccYb2798fHxs2bIgfmzFjhtasWaOVK1eqrq5O+/bt08SJE5O+Bm1/AAAMYjHrrt21a1f5fL7j5pubm7V06VKtWLFCo0ePliQtW7ZMgwYN0saNGzVixIgOX4PKHwAAAzMr/0gkopaWloQRiUQ+89q7du1SQUGBTj31VE2ZMkWNjY2SpIaGBh09elRlZWXxc4uLi1VYWKj6+vqkfj+SPwAAKRQMBuXxeBJGMBhs99zS0lI9+uijWrt2rRYtWqQ9e/bo/PPP1yeffKJQKKSsrCz17Nkz4TNer1ehUCipmGj7AwBgYOYb/mpqahQIBBLm3G53u+eOGTMm/u9DhgxRaWmp+vXrp6efflrZ2dmmxUTyBwDAwMx7/m63+zOT/Rfp2bOnTjvtNL377ru69NJLdeTIETU1NSVU/+FwuN09Ap+Htj8AAGnq0KFD2r17t/Lz81VSUqLMzEzV1tbGj+/cuVONjY3y+/1JrUvlDwCAgVVf7HPzzTdr3Lhx6tevn/bt26fbb79dXbp00TXXXCOPx6OpU6cqEAgoNzdXOTk5qq6ult/vT2qnv0TyBwDgOFa93veDDz7QNddco48++ki9e/fWqFGjtHHjRvXu3VuSNHfuXGVkZKiiokKRSETl5eVauHBh0tdxxWJWPs34T9v7j7U6BCDt+MM7rA4BSEvNh3andP3dg8tNW6v/m+tMW8ssVP4AABjY/d3+JH8AAAyiNv9WP3b7AwDgMFT+AAAYWLXhr7OQ/AEAMLDqUb/OQvIHAMAgPZ6DSx3u+QMA4DBU/gAAGND2BwDAYXjUDwAA2AqVPwAABjzqBwCAw7DbHwAA2AqVPwAABnbf8EfyBwDAwO73/Gn7AwDgMFT+AAAY2H3DH8kfAAAD7vl3kiHvb7M6BCDtfLrvZatDAByJe/4AAMBW0qbyBwAgXdD2BwDAYWy+34+2PwAATkPlDwCAAW1/AAAcht3+AADAVqj8AQAwiFodQIqR/AEAMIiJtj8AALARKn8AAAyiNn/Qn+QPAIBB1OZtf5I/AAAG3PMHAAC2QuUPAIABj/oBAOAwtP0BAECnu+uuu+RyuTR9+vT4XFtbm6qqqpSXl6cePXqooqJC4XA46bVJ/gAAGERNHF/Gli1b9Jvf/EZDhgxJmJ8xY4bWrFmjlStXqq6uTvv27dPEiROTXp/kDwCAgZXJ/9ChQ5oyZYqWLFmiE088MT7f3NyspUuX6oEHHtDo0aNVUlKiZcuW6ZVXXtHGjRuTugbJHwCAFIpEImppaUkYkUjkM8+vqqrS2LFjVVZWljDf0NCgo0ePJswXFxersLBQ9fX1ScVE8gcAwCAml2kjGAzK4/EkjGAw2O51n3zySb366qvtHg+FQsrKylLPnj0T5r1er0KhUFK/H7v9AQAwiJq42b+mpkaBQCBhzu12H3fe+++/r5/85Cd64YUX1K1bN/MCaAfJHwCAFHK73e0me6OGhgYdOHBAZ599dnzu2LFjWr9+vRYsWKB169bpyJEjampqSqj+w+GwfD5fUjGR/AEAMLDi3f6XXHKJ3njjjYS566+/XsXFxfqP//gP9e3bV5mZmaqtrVVFRYUkaefOnWpsbJTf70/qWiR/AAAMrPhSvxNOOEGDBw9OmOvevbvy8vLi81OnTlUgEFBubq5ycnJUXV0tv9+vESNGJHUtkj8AAAbp+nrfuXPnKiMjQxUVFYpEIiovL9fChQuTXscVi8XS4luLu2adZHUIQNr5dN/LVocApKXMXqemdP1nfN82ba2JoRWmrWUWKn8AAAyiLnu/25/kDwCAQVq0xFOIl/wAAOAwVP4AABik64Y/s5D8AQAwMPMNf+mItj8AAA5D5Q8AgIEVb/jrTCR/AAAM2O0PAABshcofAAADu2/4I/kDAGDAo34AADgM9/wBAICtUPkDAGDAPX8AABzG7vf8afsDAOAwVP4AABjYvfIn+QMAYBCz+T1/2v4AADgMlT8AAAa0/QEAcBi7J3/a/gAAOAyVPwAABnZ/vS/JHwAAA97wBwCAw3DPHwAA2AqVPwAABnav/En+AAAY2H3DH21/AAAchsofAAADdvsDAOAwdr/nT9sfAACHofIHAMDA7hv+SP4AABhEbZ7+afsDAJAmFi1apCFDhignJ0c5OTny+/16/vnn48fb2tpUVVWlvLw89ejRQxUVFQqHw0lfh+QPAIBB1MSRjJNPPll33XWXGhoatHXrVo0ePVrjx4/XW2+9JUmaMWOG1qxZo5UrV6qurk779u3TxIkTk/79XLFYLC16G12zTrI6BCDtfLrvZatDANJSZq9TU7r+Hf2mmLbW7L1PfKXP5+bm6t5779WVV16p3r17a8WKFbryyislSTt27NCgQYNUX1+vESNGdHhNKn8AAAysqvz/1bFjx/Tkk0+qtbVVfr9fDQ0NOnr0qMrKyuLnFBcXq7CwUPX19UmtzYY/AABSKBKJKBKJJMy53W653e52z3/jjTfk9/vV1tamHj16aNWqVTr99NO1bds2ZWVlqWfPngnne71ehUKhpGKi8gcAwCDqMm8Eg0F5PJ6EEQwGP/PaX//617Vt2zZt2rRJN954oyorK7V9+3ZTfz8qfwAADMx81O8/a2oUCAQS5j6r6pekrKwsDRgwQJJUUlKiLVu26Ne//rWuvvpqHTlyRE1NTQnVfzgcls/nSyomKn8AAFLI7XbHH937x/i85G8UjUYViURUUlKizMxM1dbWxo/t3LlTjY2N8vv9ScVE5Q8AgIFVj8HV1NRozJgxKiws1CeffKIVK1boz3/+s9atWyePx6OpU6cqEAgoNzdXOTk5qq6ult/vT2qnv0TyBwDgOFZ9sc+BAwf03e9+V/v375fH49GQIUO0bt06XXrppZKkuXPnKiMjQxUVFYpEIiovL9fChQuTvg7P+QNpjOf8gfal+jn/mlO+bdpawf9eYdpaZqHyBwDAwO7v9if5AwBgYO/Uz25/AAAch8ofAAADqzb8dRaSPwAABtzzBwDAYeyd+rnnDwCA41D5AwBgwD1/AAAcJmbzxj9tfwAAHIbKHwAAA9r+AAA4jN0f9aPtDwCAw1D5AwBgYO+6n8of7Zh5S5X+58iHuv++X1gdCtCpjh07pgcfXq7yK69TycXj9Y1J12vxshX6128+/88592vwyDEJ4weB2yyMGqkQVcy0kY6o/JFgeMlZ+v73rtXrf9ludShAp1v6+Eo9tfr/6Ve3/VQDivrprR3v6LZfzVWPHt117aTx8fNGjRiuOT+bEf85MzPTinCBL43kj7ju3b+m5csX6Ic3ztTPan5sdThAp9v25tu6+PwRuvC8cyVJJ+V79YcX6vTG9p0J52VlZqpXXq4VIaKT2H23P21/xD04/049/4da1b70stWhAJYYOniQNm3dpv9u/ECStGPXe3r1L2/p/BHDE87b8tpfdMHYybp88vd0x70Pqqm5xYpwkUIxE/9JR1T+kCRdddUVGjZssEb4x1odCmCZ733nKrUePqxx356mLhkZOhaN6sfTKnV5+ej4OSNHlKjswpE6qcCr9z/cr1//5lH98Kez9MRvHlCXLl0sjB5msnvlb3ryf//993X77bfrkUce+cxzIpGIIpFIwlwsFpPL5TI7HHTAyScXaO79d+gb37zmuP8ugJOsfWm9nvvjn3T3z2dqQFE/7dj1nu7+9W/Up1euxn/zUknSN8suip9/Wv8inda/SGOuukFbXvuLRgwfZlHkQHJMb/v/7W9/02OPPfa55wSDQXk8noQRi35idijooLPPPlNeb29t2bRWbYf3qu3wXl144XmqvukGtR3eq4wM7g7BGe5/aKm+d+1V+mbZRTqtf5Gu+MYl+u7V39J//fbpz/xM35PydWLPHDV+sL8TI0Wq0fY3ePbZZz/3+HvvvfeFa9TU1CgQCCTMnZhXnGwoMMlLL23QWcNGJ8z915IHtHPnbt1730OKRu3eAAP+rq0tIldGYgcyIyND0dhn/w88dOCvamr+RL3ZAGgrdv+/XtLJf8KECXK5XAnPvRp9Ufve7XbL7XYn9RmkzqFDrXrrrcTdzIdbD+ujjz4+bh6ws4tGlmrJY08q39tHA4r66e133tXyp57Rt8ZeJkk6fPhTLXzkCV160Uj1ysvV+x/u0wMLH1HhyQUaWXq2xdEDHZd08s/Pz9fChQs1fvz4do9v27ZNJSUlXzkwAOhsP5txox5cslxz7ntIf/u4Sb175WrS+G/qxuu/LUnK6JKhd3bv0bPPv6iWQ63q0ytX5517tm76/neVlZVlcfQw0+d1e+zAFfu8Er4dV1xxhYYOHao77rij3eOvv/66hg0blnSruGvWSUmdDzjBp/t47BJoT2avU1O6/rX9Jpq21uN7nzFtLbMkXfnfcsstam1t/czjAwYM0J/+9KevFBQAAEidpJP/+eef/7nHu3fvrgsvvPBLBwQAgNXS9Z38ZuElPwAAGKTrI3pm4QFuAAAchsofAAADnvMHAMBhuOcPAIDDcM8fAADYCpU/AAAG3PMHAMBhknz57b8d2v4AAKSJYDCoc845RyeccIL69OmjCRMmaOfOxC9Ya2trU1VVlfLy8tSjRw9VVFQoHA4ndR2SPwAABlHFTBvJqKurU1VVlTZu3KgXXnhBR48e1WWXXZbwWv0ZM2ZozZo1Wrlyperq6rRv3z5NnJjcdxEk/cU+qcIX+wDH44t9gPal+ot9xhVebtpaaxqf+9Kf/etf/6o+ffqorq5OF1xwgZqbm9W7d2+tWLFCV155pSRpx44dGjRokOrr6zVixIgOrUvlDwBACkUiEbW0tCSMSCTSoc82NzdLknJzcyVJDQ0NOnr0qMrKyuLnFBcXq7CwUPX19R2OieQPAIBBzMR/gsGgPB5PwggGg18YQzQa1fTp0zVy5EgNHjxYkhQKhZSVlaWePXsmnOv1ehUKhTr8+7HbHwAAAzPf8FdTU6NAIJAw53a7v/BzVVVVevPNN7VhwwbTYvkHkj8AACnkdrs7lOz/1U033aTnnntO69ev18knnxyf9/l8OnLkiJqamhKq/3A4LJ/P1+H1afsDAGAQi8VMG8le96abbtKqVav00ksvqaioKOF4SUmJMjMzVVtbG5/buXOnGhsb5ff7O3wdKn8AAAysesNfVVWVVqxYod///vc64YQT4vfxPR6PsrOz5fF4NHXqVAUCAeXm5ionJ0fV1dXy+/0d3ukvkfwBADiOVV/ss2jRIknSRRddlDC/bNkyXXfddZKkuXPnKiMjQxUVFYpEIiovL9fChQuTug7P+QNpjOf8gfal+jn/y/p+w7S1/vj+WtPWMguVPwAABmbu9k9HJH8AAAzSpCmeMuz2BwDAYaj8AQAwoO0PAIDDWLXbv7PQ9gcAwGGo/AEAMIjafMMfyR8AAAN7p37a/gAAOA6VPwAABuz2BwDAYUj+AAA4DG/4AwAAtkLlDwCAAW1/AAAchjf8AQAAW6HyBwDAwO4b/kj+AAAY2P2eP21/AAAchsofAAAD2v4AADgMbX8AAGArVP4AABjY/Tl/kj8AAAZR7vkDAOAsdq/8uecPAIDDUPkDAGBA2x8AAIeh7Q8AAGyFyh8AAAPa/gAAOAxtfwAAYCtU/gAAGND2BwDAYWj7AwAAWyH5AwBgEItFTRvJWL9+vcaNG6eCggK5XC6tXr3aEFdMs2fPVn5+vrKzs1VWVqZdu3Yl/fuR/AEAMIgqZtpIRmtrq8466yw99NBD7R6/5557NH/+fC1evFibNm1S9+7dVV5erra2tqSuwz1/AAAMYhZt+BszZozGjBnT7rFYLKZ58+bptttu0/jx4yVJy5cvl9fr1erVqzV58uQOX4fKHwCAFIpEImppaUkYkUgk6XX27NmjUCiksrKy+JzH41Fpaanq6+uTWovkDwCAgZlt/2AwKI/HkzCCwWDSMYVCIUmS1+tNmPd6vfFjHUXbHwAAAzPb/jU1NQoEAglzbrfbtPW/DJI/AAAp5Ha7TUn2Pp9PkhQOh5Wfnx+fD4fDGjp0aFJr0fYHAMAgGouZNsxSVFQkn8+n2tra+FxLS4s2bdokv9+f1FpU/gAAGFj1hr9Dhw7p3Xffjf+8Z88ebdu2Tbm5uSosLNT06dM1Z84cDRw4UEVFRZo1a5YKCgo0YcKEpK5D8gcAIE1s3bpVF198cfznf+wVqKys1KOPPqqZM2eqtbVV06ZNU1NTk0aNGqW1a9eqW7duSV3HFbPqYUaDrlknWR0CkHY+3fey1SEAaSmz16kpXd/rKTZtrXDzDtPWMguVPwAABsm+me/fDRv+AABwGCp/AAAM0uSOeMqQ/AEAMDDzEb10RPIHAMDA7pU/9/wBAHAYKn8AAAzsvtuf5A8AgAFtfwAAYCtU/gAAGLDbHwAAh7Hqi306C21/AAAchsofAAAD2v4AADgMu/0BAICtUPkDAGBg9w1/JH8AAAzs3vYn+QMAYGD35M89fwAAHIbKHwAAA3vX/ZIrZvfeBpISiUQUDAZVU1Mjt9ttdThAWuDPBeyG5I8ELS0t8ng8am5uVk5OjtXhAGmBPxewG+75AwDgMCR/AAAchuQPAIDDkPyRwO126/bbb2dTE/Av+HMBu2HDHwAADkPlDwCAw5D8AQBwGJI/AAAOQ/IHAMBhSP6Ie+ihh3TKKaeoW7duKi0t1ebNm60OCbDU+vXrNW7cOBUUFMjlcmn16tVWhwSYguQPSdJTTz2lQCCg22+/Xa+++qrOOusslZeX68CBA1aHBlimtbVVZ511lh566CGrQwFMxaN+kCSVlpbqnHPO0YIFCyRJ0WhUffv2VXV1tW699VaLowOs53K5tGrVKk2YMMHqUICvjMofOnLkiBoaGlRWVhafy8jIUFlZmerr6y2MDACQCiR/6ODBgzp27Ji8Xm/CvNfrVSgUsigqAECqkPwBAHAYkj/Uq1cvdenSReFwOGE+HA7L5/NZFBUAIFVI/lBWVpZKSkpUW1sbn4tGo6qtrZXf77cwMgBAKnS1OgCkh0AgoMrKSg0fPlznnnuu5s2bp9bWVl1//fVWhwZY5tChQ3r33XfjP+/Zs0fbtm1Tbm6uCgsLLYwM+Gp41A9xCxYs0L333qtQKKShQ4dq/vz5Ki0ttToswDJ//vOfdfHFFx83X1lZqUcffbTzAwJMQvIHAMBhuOcPAIDDkPwBAHAYkj8AAA5D8gcAwGFI/gAAOAzJHwAAhyH5AwDgMCR/AAAchuQPAIDDkPwBAHAYkj8AAA5D8gcAwGH+F73+Mp7c5nCmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4btjJVHDktDi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2\n",
        "\n",
        "## UtilizaÃ§Ã£o da validaÃ§Ã£o cruzada e dropout"
      ],
      "metadata": {
        "id": "56CX5zpM_7PV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Validation"
      ],
      "metadata": {
        "id": "zM6vfErh5rTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhV60ljF5uL_",
        "outputId": "d2ad7018-9c73-4886-cfec-aeb788cef672"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.8.10)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.65.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetBinaryClassifier\n",
        "import torch\n",
        "from sklearn.model_selection import cross_val_score\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yv-vye5O5xjq",
        "outputId": "d1d0cd86-7aa2-4337-c3a2-e5a3b67b0209"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvwqIzSC6DJP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data..."
      ],
      "metadata": {
        "id": "WebbSo0d67BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGmjwQpd685y",
        "outputId": "f2c5ad50-ec1a-48e4-c014-06d0a02e833e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78dedd98ca90>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = pd.read_csv('/content/drive/MyDrive/Deep_learning/entradas_breast.csv')\n",
        "classe = pd.read_csv('/content/drive/MyDrive/Deep_learning/saidas_breast.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "KiIFaBleAkoY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=classe['0']);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "gI8ocA0nAktL",
        "outputId": "7ae28e2d-2832-40cb-f080-a5ab8ff3c2a7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti1EOAhrA98i",
        "outputId": "fd788225-e4eb-4963-8fd6-1319e7c8972e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = np.array(previsores, dtype='float32')\n",
        "classe = np.array(classe, dtype='float32').squeeze(1)"
      ],
      "metadata": {
        "id": "2e-Nz7kqA-kP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retirada do 1 no shape original para utilizaÃ§Ã£o do PyTorch\n",
        "classe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pMx6sODBPYN",
        "outputId": "05875df7-5a24-4447-9392-81964d8c7b6f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#type(classe)\n",
        "type(previsores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckme0Yj7BZ9k",
        "outputId": "e237970d-47ea-4586-db33-0425ce78d383"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classe para estrutura da rede neural:"
      ],
      "metadata": {
        "id": "JwhzVomC6FcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "gawppu9Z6yHP"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# O skorch exige que a rn seja passada como uma classe que herda do nn.Module:\n",
        "\n",
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Contruindo a rede: 30 -> 16 -> 16 -> 1\n",
        "\n",
        "    # 1) 30 -> 16:\n",
        "    self.dense0 = nn.Linear(30, 16)\n",
        "    torch.nn.init.uniform_(self.dense0.weight)\n",
        "    self.activation0 = nn.ReLU()\n",
        "    # 2) 16 -> 16:\n",
        "    self.dense1 = nn.Linear(16, 16)\n",
        "    torch.nn.init.uniform_(self.dense1.weight)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    # 3) 16 -> 1:\n",
        "    self.dense2 = nn.Linear(16, 1)\n",
        "    torch.nn.init.uniform_(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() ** ATUALIZAÃ‡ÃƒO (ver detalhes no texto acima) **\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) ** ATUALIZAÃ‡ÃƒO (ver detalhes no texto acima) **\n",
        "    return X"
      ],
      "metadata": {
        "id": "uffeQ-l_FXSd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnnsy9SP97ie"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando o Skorch:"
      ],
      "metadata": {
        "id": "-mt6gcGz98tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  criterion=torch.nn.BCEWithLogitsLoss,\n",
        "                                                  optimizer=torch.optim.Adam,\n",
        "                                                  lr=0.001,\n",
        "                                                  optimizer__weight_decay=0.0001,\n",
        "                                                  max_epochs=100,\n",
        "                                                  batch_size=10,\n",
        "                                                  train_split=False) #False para que o split seja feita a validaÃ§Ã£o cruzada"
      ],
      "metadata": {
        "id": "REeNlKfw-B_u"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SLwnvTb7_OK4"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Validation:"
      ],
      "metadata": {
        "id": "Z9hXvHzZ_bGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = cross_val_score(classificador_sklearn,previsores,classe,cv=10,scoring='accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEzIxMjm_dki",
        "outputId": "a6c48dd7-0bc4-4927-9ad4-e30b6fa0d314"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m91294.3561\u001b[0m  0.1484\n",
            "      2    \u001b[36m72722.7842\u001b[0m  0.1683\n",
            "      3    \u001b[36m57326.1895\u001b[0m  0.1267\n",
            "      4    \u001b[36m45113.9061\u001b[0m  0.1388\n",
            "      5    \u001b[36m35504.2660\u001b[0m  0.1984\n",
            "      6    \u001b[36m27942.9745\u001b[0m  0.2327\n",
            "      7    \u001b[36m21966.1433\u001b[0m  0.2596\n",
            "      8    \u001b[36m17219.1712\u001b[0m  0.0847\n",
            "      9    \u001b[36m13405.5771\u001b[0m  0.0720\n",
            "     10    \u001b[36m10299.5128\u001b[0m  0.0731\n",
            "     11     \u001b[36m7712.1263\u001b[0m  0.0737\n",
            "     12     \u001b[36m5558.0446\u001b[0m  0.0769\n",
            "     13     \u001b[36m3777.9468\u001b[0m  0.0804\n",
            "     14     \u001b[36m2149.4901\u001b[0m  0.0778\n",
            "     15      \u001b[36m642.8538\u001b[0m  0.0908\n",
            "     16      \u001b[36m118.2383\u001b[0m  0.0821\n",
            "     17      \u001b[36m107.0518\u001b[0m  0.0731\n",
            "     18       \u001b[36m96.8006\u001b[0m  0.0724\n",
            "     19       \u001b[36m87.7538\u001b[0m  0.0837\n",
            "     20       \u001b[36m77.5083\u001b[0m  0.0733\n",
            "     21       \u001b[36m69.4041\u001b[0m  0.1094\n",
            "     22       \u001b[36m64.9020\u001b[0m  0.1152\n",
            "     23       \u001b[36m58.1061\u001b[0m  0.1080\n",
            "     24       \u001b[36m51.6602\u001b[0m  0.0828\n",
            "     25       \u001b[36m47.0568\u001b[0m  0.0694\n",
            "     26       \u001b[36m38.7777\u001b[0m  0.0726\n",
            "     27       \u001b[36m36.0821\u001b[0m  0.0865\n",
            "     28       \u001b[36m32.8395\u001b[0m  0.0852\n",
            "     29       \u001b[36m29.8898\u001b[0m  0.0752\n",
            "     30       \u001b[36m28.6489\u001b[0m  0.0742\n",
            "     31       \u001b[36m27.5908\u001b[0m  0.0739\n",
            "     32       \u001b[36m26.4866\u001b[0m  0.0773\n",
            "     33       \u001b[36m23.9129\u001b[0m  0.0717\n",
            "     34       25.6945  0.0792\n",
            "     35       25.1563  0.0753\n",
            "     36       24.5102  0.0749\n",
            "     37       26.1337  0.0749\n",
            "     38       \u001b[36m23.8322\u001b[0m  0.0740\n",
            "     39       \u001b[36m23.5597\u001b[0m  0.0778\n",
            "     40       \u001b[36m20.8837\u001b[0m  0.0769\n",
            "     41       \u001b[36m19.9660\u001b[0m  0.0772\n",
            "     42       \u001b[36m19.8466\u001b[0m  0.0706\n",
            "     43       \u001b[36m19.4960\u001b[0m  0.1884\n",
            "     44       20.9124  0.1125\n",
            "     45       19.7228  0.1072\n",
            "     46       \u001b[36m18.8578\u001b[0m  0.1045\n",
            "     47       \u001b[36m18.0653\u001b[0m  0.1105\n",
            "     48       \u001b[36m17.0064\u001b[0m  0.1147\n",
            "     49       \u001b[36m16.4093\u001b[0m  0.1268\n",
            "     50       \u001b[36m15.3304\u001b[0m  0.1314\n",
            "     51       \u001b[36m15.2243\u001b[0m  0.1224\n",
            "     52       16.0265  0.1239\n",
            "     53       \u001b[36m15.1592\u001b[0m  0.1281\n",
            "     54       \u001b[36m14.8435\u001b[0m  0.1170\n",
            "     55       15.0959  0.1115\n",
            "     56       \u001b[36m13.7176\u001b[0m  0.1459\n",
            "     57       14.1029  0.1355\n",
            "     58       \u001b[36m13.0632\u001b[0m  0.1229\n",
            "     59       \u001b[36m12.6084\u001b[0m  0.1197\n",
            "     60       \u001b[36m12.2641\u001b[0m  0.1300\n",
            "     61       \u001b[36m10.3144\u001b[0m  0.1297\n",
            "     62        \u001b[36m9.2652\u001b[0m  0.1217\n",
            "     63        9.8017  0.1225\n",
            "     64        9.6422  0.1486\n",
            "     65        \u001b[36m8.4754\u001b[0m  0.1689\n",
            "     66        8.7457  0.1677\n",
            "     67        \u001b[36m8.0869\u001b[0m  0.1195\n",
            "     68        \u001b[36m6.9166\u001b[0m  0.1944\n",
            "     69        7.8375  0.1367\n",
            "     70        \u001b[36m6.4371\u001b[0m  0.1444\n",
            "     71        \u001b[36m5.9819\u001b[0m  0.1212\n",
            "     72        \u001b[36m5.6988\u001b[0m  0.1744\n",
            "     73        6.2394  0.1409\n",
            "     74        6.5690  0.1903\n",
            "     75        7.2724  0.1805\n",
            "     76       15.4184  0.1322\n",
            "     77        8.3427  0.1853\n",
            "     78        7.4134  0.1534\n",
            "     79        7.2841  0.2233\n",
            "     80        6.3368  0.1146\n",
            "     81        \u001b[36m4.4686\u001b[0m  0.1088\n",
            "     82        5.8147  0.1103\n",
            "     83        8.7155  0.1317\n",
            "     84        6.9278  0.2321\n",
            "     85        5.3143  0.3433\n",
            "     86        7.3853  0.6306\n",
            "     87        5.5485  0.1384\n",
            "     88        8.1504  0.3152\n",
            "     89        5.8792  0.3435\n",
            "     90        7.9424  0.2923\n",
            "     91        7.7504  0.2208\n",
            "     92        4.9783  0.2617\n",
            "     93        5.5336  0.2524\n",
            "     94        8.3677  0.2811\n",
            "     95        5.3208  0.2740\n",
            "     96        7.5146  0.3342\n",
            "     97        7.2048  0.2847\n",
            "     98        5.3521  0.2198\n",
            "     99        8.2899  0.3342\n",
            "    100        6.1513  0.2035\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m70436.5778\u001b[0m  0.2140\n",
            "      2    \u001b[36m53928.7795\u001b[0m  0.2186\n",
            "      3    \u001b[36m40268.3620\u001b[0m  0.1022\n",
            "      4    \u001b[36m29162.8260\u001b[0m  0.2204\n",
            "      5    \u001b[36m19990.4075\u001b[0m  0.2138\n",
            "      6    \u001b[36m12169.8116\u001b[0m  0.1421\n",
            "      7     \u001b[36m5111.0349\u001b[0m  0.1210\n",
            "      8      \u001b[36m445.7835\u001b[0m  0.1295\n",
            "      9      \u001b[36m218.2382\u001b[0m  0.1049\n",
            "     10      \u001b[36m182.2853\u001b[0m  0.1993\n",
            "     11      \u001b[36m166.1568\u001b[0m  0.1485\n",
            "     12      \u001b[36m149.6704\u001b[0m  0.1737\n",
            "     13      \u001b[36m123.0977\u001b[0m  0.1890\n",
            "     14      \u001b[36m105.3252\u001b[0m  0.1721\n",
            "     15       \u001b[36m92.2271\u001b[0m  0.1923\n",
            "     16       \u001b[36m74.8054\u001b[0m  0.1984\n",
            "     17       \u001b[36m65.3000\u001b[0m  0.1400\n",
            "     18       \u001b[36m61.6400\u001b[0m  0.1319\n",
            "     19       \u001b[36m57.0561\u001b[0m  0.1378\n",
            "     20       \u001b[36m52.4325\u001b[0m  0.1217\n",
            "     21       57.2774  0.1896\n",
            "     22       54.5452  0.2176\n",
            "     23       \u001b[36m43.2943\u001b[0m  0.1384\n",
            "     24       \u001b[36m32.6091\u001b[0m  0.1685\n",
            "     25       33.6517  0.1599\n",
            "     26       \u001b[36m25.1543\u001b[0m  0.1708\n",
            "     27       31.3240  0.1435\n",
            "     28       \u001b[36m20.1321\u001b[0m  0.1665\n",
            "     29       \u001b[36m18.7859\u001b[0m  0.1427\n",
            "     30       \u001b[36m16.9175\u001b[0m  0.1208\n",
            "     31       \u001b[36m16.2261\u001b[0m  0.1174\n",
            "     32       \u001b[36m12.8033\u001b[0m  0.1064\n",
            "     33       13.6943  0.1407\n",
            "     34       27.6043  0.1058\n",
            "     35       17.4263  0.1726\n",
            "     36       \u001b[36m11.6316\u001b[0m  0.2922\n",
            "     37        \u001b[36m8.4397\u001b[0m  0.1584\n",
            "     38       10.2501  0.1914\n",
            "     39        \u001b[36m7.8115\u001b[0m  0.1206\n",
            "     40       10.8469  0.1573\n",
            "     41        9.1654  0.1591\n",
            "     42       10.3854  0.1825\n",
            "     43        \u001b[36m7.3371\u001b[0m  0.1623\n",
            "     44       19.7981  0.2235\n",
            "     45        \u001b[36m4.9021\u001b[0m  0.1353\n",
            "     46        7.6257  0.1096\n",
            "     47        9.0074  0.1801\n",
            "     48        5.2262  0.2568\n",
            "     49        8.7665  0.2466\n",
            "     50        9.8350  0.1269\n",
            "     51        6.0474  0.1077\n",
            "     52        \u001b[36m3.1728\u001b[0m  0.3432\n",
            "     53        \u001b[36m2.5401\u001b[0m  0.1589\n",
            "     54        5.4887  0.1679\n",
            "     55        5.3827  0.1895\n",
            "     56       12.9819  0.1849\n",
            "     57       22.5579  0.1940\n",
            "     58        8.4598  0.2243\n",
            "     59        6.5355  0.5546\n",
            "     60        7.1926  0.4344\n",
            "     61        6.9796  0.4259\n",
            "     62        5.5187  0.4192\n",
            "     63        3.4592  0.5266\n",
            "     64        4.6015  0.3958\n",
            "     65        6.7616  0.5915\n",
            "     66        8.9083  0.3813\n",
            "     67        3.3575  0.4484\n",
            "     68        4.7883  0.3801\n",
            "     69        5.7593  0.2513\n",
            "     70        5.3309  0.1346\n",
            "     71        4.7313  0.1172\n",
            "     72        5.6864  0.1539\n",
            "     73        2.9881  0.1624\n",
            "     74        3.2291  0.2080\n",
            "     75        7.2269  0.1308\n",
            "     76        7.3840  0.2690\n",
            "     77        4.5549  0.1307\n",
            "     78        4.4394  0.1203\n",
            "     79       10.8868  0.1352\n",
            "     80        6.5639  0.2089\n",
            "     81        5.9049  0.3192\n",
            "     82        6.2612  0.2861\n",
            "     83        9.1853  0.1842\n",
            "     84        6.1605  0.0727\n",
            "     85        6.2187  0.0793\n",
            "     86       10.3857  0.0768\n",
            "     87        6.1616  0.0728\n",
            "     88        5.5442  0.0758\n",
            "     89        4.5838  0.0739\n",
            "     90        6.3117  0.0731\n",
            "     91        4.9328  0.0717\n",
            "     92        5.4927  0.0738\n",
            "     93        6.7207  0.0706\n",
            "     94        5.8485  0.0797\n",
            "     95        5.7147  0.0736\n",
            "     96        4.9251  0.0732\n",
            "     97        3.7979  0.0743\n",
            "     98        3.8718  0.0885\n",
            "     99        6.1365  0.0748\n",
            "    100        6.8790  0.0743\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1   \u001b[36m102060.9532\u001b[0m  0.0702\n",
            "      2    \u001b[36m81957.0039\u001b[0m  0.0789\n",
            "      3    \u001b[36m65008.2401\u001b[0m  0.0702\n",
            "      4    \u001b[36m51235.4979\u001b[0m  0.0753\n",
            "      5    \u001b[36m40120.0689\u001b[0m  0.0733\n",
            "      6    \u001b[36m31144.9706\u001b[0m  0.0757\n",
            "      7    \u001b[36m23866.0374\u001b[0m  0.0788\n",
            "      8    \u001b[36m17914.4480\u001b[0m  0.0774\n",
            "      9    \u001b[36m12985.8980\u001b[0m  0.0889\n",
            "     10     \u001b[36m8817.2845\u001b[0m  0.0717\n",
            "     11     \u001b[36m5168.8773\u001b[0m  0.0792\n",
            "     12     \u001b[36m1811.1137\u001b[0m  0.0719\n",
            "     13      \u001b[36m146.0911\u001b[0m  0.0775\n",
            "     14      \u001b[36m128.0937\u001b[0m  0.0700\n",
            "     15      \u001b[36m109.7427\u001b[0m  0.0738\n",
            "     16       \u001b[36m94.4517\u001b[0m  0.0805\n",
            "     17       \u001b[36m78.4928\u001b[0m  0.0711\n",
            "     18       \u001b[36m68.8711\u001b[0m  0.0723\n",
            "     19       \u001b[36m60.4823\u001b[0m  0.0723\n",
            "     20       \u001b[36m55.9405\u001b[0m  0.0735\n",
            "     21       \u001b[36m54.5786\u001b[0m  0.0762\n",
            "     22       \u001b[36m51.4576\u001b[0m  0.0737\n",
            "     23       \u001b[36m48.9418\u001b[0m  0.0725\n",
            "     24       \u001b[36m40.4177\u001b[0m  0.0838\n",
            "     25       43.8455  0.0744\n",
            "     26       \u001b[36m37.5322\u001b[0m  0.0730\n",
            "     27       \u001b[36m35.8311\u001b[0m  0.0764\n",
            "     28       \u001b[36m34.2573\u001b[0m  0.0753\n",
            "     29       \u001b[36m33.0912\u001b[0m  0.0725\n",
            "     30       \u001b[36m32.6280\u001b[0m  0.0722\n",
            "     31       32.6553  0.0719\n",
            "     32       \u001b[36m30.2556\u001b[0m  0.0725\n",
            "     33       31.0223  0.0747\n",
            "     34       30.7095  0.0716\n",
            "     35       32.3699  0.0777\n",
            "     36       \u001b[36m29.6700\u001b[0m  0.0741\n",
            "     37       \u001b[36m28.4210\u001b[0m  0.0760\n",
            "     38       \u001b[36m26.7323\u001b[0m  0.0733\n",
            "     39       27.0739  0.0791\n",
            "     40       30.6317  0.0714\n",
            "     41       29.9667  0.0732\n",
            "     42       29.9158  0.0712\n",
            "     43       \u001b[36m26.6193\u001b[0m  0.0802\n",
            "     44       27.0502  0.0714\n",
            "     45       29.0364  0.0714\n",
            "     46       29.7831  0.0746\n",
            "     47       28.3074  0.0732\n",
            "     48       29.5272  0.0797\n",
            "     49       26.6332  0.0728\n",
            "     50       26.7449  0.0714\n",
            "     51       28.7440  0.0793\n",
            "     52       \u001b[36m25.3196\u001b[0m  0.0737\n",
            "     53       28.2738  0.0756\n",
            "     54       \u001b[36m20.3687\u001b[0m  0.0763\n",
            "     55       \u001b[36m17.9929\u001b[0m  0.0750\n",
            "     56       21.0749  0.0709\n",
            "     57       20.9485  0.0751\n",
            "     58       \u001b[36m17.4723\u001b[0m  0.0772\n",
            "     59       \u001b[36m12.7891\u001b[0m  0.0741\n",
            "     60       13.4510  0.0759\n",
            "     61       13.5755  0.0787\n",
            "     62       14.0894  0.0751\n",
            "     63       14.2856  0.0718\n",
            "     64       \u001b[36m11.3588\u001b[0m  0.0844\n",
            "     65       12.7263  0.0772\n",
            "     66        \u001b[36m9.7235\u001b[0m  0.0779\n",
            "     67       12.2478  0.0732\n",
            "     68       16.4516  0.0720\n",
            "     69       16.2299  0.0726\n",
            "     70       12.6829  0.0778\n",
            "     71       14.8509  0.0710\n",
            "     72       11.2442  0.0816\n",
            "     73       12.2889  0.0739\n",
            "     74       14.7077  0.0745\n",
            "     75       14.1621  0.1033\n",
            "     76       12.3678  0.1048\n",
            "     77       13.3095  0.1055\n",
            "     78       13.5187  0.0969\n",
            "     79       13.7629  0.0958\n",
            "     80        \u001b[36m8.8834\u001b[0m  0.1006\n",
            "     81       12.7144  0.0972\n",
            "     82       11.2880  0.1051\n",
            "     83       16.2492  0.0958\n",
            "     84       10.1331  0.0970\n",
            "     85       15.5694  0.0980\n",
            "     86       10.1925  0.1013\n",
            "     87       13.1331  0.1176\n",
            "     88       11.1860  0.1106\n",
            "     89       18.1355  0.1056\n",
            "     90       13.0741  0.1052\n",
            "     91       17.9528  0.1041\n",
            "     92       12.0245  0.0994\n",
            "     93       13.7917  0.1036\n",
            "     94       19.2547  0.1005\n",
            "     95       18.2509  0.0980\n",
            "     96       18.6428  0.1104\n",
            "     97       16.0911  0.1189\n",
            "     98       18.8882  0.0996\n",
            "     99       22.1763  0.1070\n",
            "    100       16.1922  0.1053\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m89014.4593\u001b[0m  0.0977\n",
            "      2    \u001b[36m70505.6249\u001b[0m  0.1005\n",
            "      3    \u001b[36m55280.8039\u001b[0m  0.0987\n",
            "      4    \u001b[36m43151.3474\u001b[0m  0.0968\n",
            "      5    \u001b[36m33533.4863\u001b[0m  0.1007\n",
            "      6    \u001b[36m25909.0130\u001b[0m  0.0993\n",
            "      7    \u001b[36m19845.7809\u001b[0m  0.1088\n",
            "      8    \u001b[36m15013.0900\u001b[0m  0.1135\n",
            "      9    \u001b[36m11114.2149\u001b[0m  0.1015\n",
            "     10     \u001b[36m7884.2004\u001b[0m  0.1051\n",
            "     11     \u001b[36m5116.5940\u001b[0m  0.1135\n",
            "     12     \u001b[36m2684.2407\u001b[0m  0.1448\n",
            "     13      \u001b[36m685.4412\u001b[0m  0.0854\n",
            "     14      \u001b[36m281.0399\u001b[0m  0.0759\n",
            "     15      \u001b[36m265.7016\u001b[0m  0.0768\n",
            "     16      \u001b[36m245.7174\u001b[0m  0.0883\n",
            "     17      \u001b[36m227.6065\u001b[0m  0.0714\n",
            "     18      \u001b[36m208.6892\u001b[0m  0.0754\n",
            "     19      \u001b[36m191.6816\u001b[0m  0.0731\n",
            "     20      \u001b[36m176.4365\u001b[0m  0.0787\n",
            "     21      \u001b[36m163.0019\u001b[0m  0.0735\n",
            "     22      \u001b[36m152.4644\u001b[0m  0.0786\n",
            "     23      \u001b[36m143.1710\u001b[0m  0.0740\n",
            "     24      \u001b[36m135.6537\u001b[0m  0.0718\n",
            "     25      \u001b[36m126.5995\u001b[0m  0.0723\n",
            "     26      \u001b[36m118.3527\u001b[0m  0.0787\n",
            "     27      \u001b[36m111.5332\u001b[0m  0.0743\n",
            "     28      \u001b[36m104.4232\u001b[0m  0.0788\n",
            "     29       \u001b[36m92.2257\u001b[0m  0.0747\n",
            "     30       \u001b[36m87.0159\u001b[0m  0.0758\n",
            "     31       \u001b[36m82.0171\u001b[0m  0.0766\n",
            "     32       \u001b[36m78.6861\u001b[0m  0.0734\n",
            "     33       \u001b[36m75.8079\u001b[0m  0.0751\n",
            "     34       \u001b[36m75.4824\u001b[0m  0.0737\n",
            "     35       \u001b[36m67.8322\u001b[0m  0.0788\n",
            "     36       \u001b[36m63.9445\u001b[0m  0.0759\n",
            "     37       \u001b[36m60.2115\u001b[0m  0.0719\n",
            "     38       \u001b[36m57.4429\u001b[0m  0.0720\n",
            "     39       \u001b[36m55.6462\u001b[0m  0.0778\n",
            "     40       \u001b[36m50.5058\u001b[0m  0.0760\n",
            "     41       \u001b[36m48.9836\u001b[0m  0.0693\n",
            "     42       \u001b[36m46.3359\u001b[0m  0.0754\n",
            "     43       \u001b[36m43.1519\u001b[0m  0.0831\n",
            "     44       \u001b[36m41.1614\u001b[0m  0.0703\n",
            "     45       \u001b[36m39.4659\u001b[0m  0.0720\n",
            "     46       \u001b[36m37.9939\u001b[0m  0.0752\n",
            "     47       \u001b[36m35.6862\u001b[0m  0.0743\n",
            "     48       \u001b[36m33.8365\u001b[0m  0.0719\n",
            "     49       \u001b[36m32.6929\u001b[0m  0.0803\n",
            "     50       \u001b[36m31.1197\u001b[0m  0.0743\n",
            "     51       \u001b[36m29.9532\u001b[0m  0.0730\n",
            "     52       \u001b[36m28.9290\u001b[0m  0.0733\n",
            "     53       \u001b[36m26.0737\u001b[0m  0.0784\n",
            "     54       \u001b[36m24.3056\u001b[0m  0.0738\n",
            "     55       25.7328  0.0778\n",
            "     56       \u001b[36m23.2388\u001b[0m  0.0777\n",
            "     57       23.4783  0.0729\n",
            "     58       24.0397  0.0725\n",
            "     59       \u001b[36m21.5143\u001b[0m  0.0876\n",
            "     60       21.6296  0.0768\n",
            "     61       22.4988  0.0759\n",
            "     62       \u001b[36m19.9621\u001b[0m  0.0729\n",
            "     63       \u001b[36m19.5358\u001b[0m  0.0793\n",
            "     64       19.8345  0.0945\n",
            "     65       \u001b[36m19.1615\u001b[0m  0.1083\n",
            "     66       \u001b[36m19.0434\u001b[0m  0.0783\n",
            "     67       \u001b[36m18.8410\u001b[0m  0.0719\n",
            "     68       \u001b[36m18.6505\u001b[0m  0.0794\n",
            "     69       \u001b[36m18.0340\u001b[0m  0.0732\n",
            "     70       \u001b[36m16.1455\u001b[0m  0.0718\n",
            "     71       17.3643  0.0816\n",
            "     72       16.9415  0.0781\n",
            "     73       \u001b[36m15.7924\u001b[0m  0.0761\n",
            "     74       \u001b[36m15.5179\u001b[0m  0.0737\n",
            "     75       \u001b[36m14.8740\u001b[0m  0.0737\n",
            "     76       \u001b[36m13.2062\u001b[0m  0.0776\n",
            "     77       14.6805  0.0727\n",
            "     78       \u001b[36m12.7528\u001b[0m  0.0740\n",
            "     79       13.9124  0.0723\n",
            "     80       13.9449  0.0765\n",
            "     81       \u001b[36m12.1433\u001b[0m  0.0859\n",
            "     82       12.2704  0.0729\n",
            "     83       16.8874  0.0725\n",
            "     84       14.1004  0.0752\n",
            "     85       13.9763  0.0723\n",
            "     86       13.7492  0.0787\n",
            "     87       12.9840  0.0716\n",
            "     88       13.9746  0.0798\n",
            "     89       13.5667  0.0726\n",
            "     90       13.1480  0.0745\n",
            "     91       15.3201  0.0930\n",
            "     92       12.4106  0.0991\n",
            "     93       12.4933  0.0921\n",
            "     94       12.9305  0.1059\n",
            "     95       12.1769  0.0981\n",
            "     96       12.7577  0.0753\n",
            "     97       \u001b[36m11.2094\u001b[0m  0.0720\n",
            "     98       12.2015  0.0731\n",
            "     99        \u001b[36m7.9995\u001b[0m  0.0780\n",
            "    100       10.9475  0.0733\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m85133.0746\u001b[0m  0.0692\n",
            "      2    \u001b[36m66524.9755\u001b[0m  0.0733\n",
            "      3    \u001b[36m51466.1392\u001b[0m  0.0884\n",
            "      4    \u001b[36m39662.9737\u001b[0m  0.0720\n",
            "      5    \u001b[36m30470.7095\u001b[0m  0.0713\n",
            "      6    \u001b[36m23293.8670\u001b[0m  0.0813\n",
            "      7    \u001b[36m17650.7503\u001b[0m  0.0719\n",
            "      8    \u001b[36m13183.3019\u001b[0m  0.0794\n",
            "      9     \u001b[36m9598.2770\u001b[0m  0.0782\n",
            "     10     \u001b[36m6662.8725\u001b[0m  0.0800\n",
            "     11     \u001b[36m4208.2792\u001b[0m  0.0731\n",
            "     12     \u001b[36m2044.2846\u001b[0m  0.0718\n",
            "     13      \u001b[36m404.6365\u001b[0m  0.0717\n",
            "     14      \u001b[36m192.6884\u001b[0m  0.0744\n",
            "     15      \u001b[36m169.9164\u001b[0m  0.0717\n",
            "     16      \u001b[36m148.9236\u001b[0m  0.0726\n",
            "     17      \u001b[36m128.8418\u001b[0m  0.0709\n",
            "     18      \u001b[36m112.5607\u001b[0m  0.0808\n",
            "     19       \u001b[36m97.4945\u001b[0m  0.0797\n",
            "     20       \u001b[36m85.8213\u001b[0m  0.0736\n",
            "     21       \u001b[36m75.2083\u001b[0m  0.0746\n",
            "     22       \u001b[36m67.6125\u001b[0m  0.0742\n",
            "     23       \u001b[36m61.0147\u001b[0m  0.0756\n",
            "     24       \u001b[36m55.7276\u001b[0m  0.0712\n",
            "     25       \u001b[36m49.9775\u001b[0m  0.0826\n",
            "     26       \u001b[36m48.6133\u001b[0m  0.0726\n",
            "     27       \u001b[36m46.3012\u001b[0m  0.0733\n",
            "     28       \u001b[36m45.5498\u001b[0m  0.0734\n",
            "     29       \u001b[36m41.8533\u001b[0m  0.0949\n",
            "     30       \u001b[36m38.1700\u001b[0m  0.0759\n",
            "     31       \u001b[36m36.7399\u001b[0m  0.0734\n",
            "     32       \u001b[36m33.4964\u001b[0m  0.0800\n",
            "     33       \u001b[36m32.4417\u001b[0m  0.0775\n",
            "     34       \u001b[36m31.6915\u001b[0m  0.0754\n",
            "     35       \u001b[36m30.9118\u001b[0m  0.0741\n",
            "     36       \u001b[36m30.6552\u001b[0m  0.0844\n",
            "     37       \u001b[36m29.3438\u001b[0m  0.0721\n",
            "     38       \u001b[36m27.0672\u001b[0m  0.0710\n",
            "     39       \u001b[36m26.7494\u001b[0m  0.1094\n",
            "     40       \u001b[36m25.5847\u001b[0m  0.1096\n",
            "     41       \u001b[36m24.2540\u001b[0m  0.1051\n",
            "     42       \u001b[36m23.2503\u001b[0m  0.0974\n",
            "     43       \u001b[36m21.9450\u001b[0m  0.1034\n",
            "     44       \u001b[36m21.4976\u001b[0m  0.1036\n",
            "     45       \u001b[36m19.4886\u001b[0m  0.1000\n",
            "     46       \u001b[36m17.0025\u001b[0m  0.1031\n",
            "     47       \u001b[36m16.1460\u001b[0m  0.0995\n",
            "     48       \u001b[36m15.4588\u001b[0m  0.1019\n",
            "     49       \u001b[36m12.8828\u001b[0m  0.0984\n",
            "     50       13.4404  0.1000\n",
            "     51       \u001b[36m11.4750\u001b[0m  0.0993\n",
            "     52       11.4776  0.1231\n",
            "     53       \u001b[36m11.1993\u001b[0m  0.1105\n",
            "     54        \u001b[36m9.9255\u001b[0m  0.1046\n",
            "     55       10.2535  0.1045\n",
            "     56        \u001b[36m8.3178\u001b[0m  0.1337\n",
            "     57        \u001b[36m7.7781\u001b[0m  0.1038\n",
            "     58        8.8149  0.0969\n",
            "     59        8.9131  0.1003\n",
            "     60        7.8616  0.0993\n",
            "     61        \u001b[36m7.4792\u001b[0m  0.0948\n",
            "     62        \u001b[36m7.0778\u001b[0m  0.1008\n",
            "     63        8.0152  0.1174\n",
            "     64        9.7123  0.1049\n",
            "     65        \u001b[36m6.6001\u001b[0m  0.0994\n",
            "     66        8.7225  0.0979\n",
            "     67        8.1436  0.0959\n",
            "     68        6.9251  0.1063\n",
            "     69        \u001b[36m6.4447\u001b[0m  0.1073\n",
            "     70        8.4496  0.0981\n",
            "     71        6.7916  0.0981\n",
            "     72        \u001b[36m5.8722\u001b[0m  0.1029\n",
            "     73        7.3234  0.1121\n",
            "     74        7.6172  0.0977\n",
            "     75        6.8908  0.1301\n",
            "     76        7.2385  0.1021\n",
            "     77        7.0236  0.1083\n",
            "     78        5.9969  0.0906\n",
            "     79        \u001b[36m4.4144\u001b[0m  0.0745\n",
            "     80        5.3867  0.0731\n",
            "     81        7.8595  0.0740\n",
            "     82        6.3562  0.0759\n",
            "     83        5.6815  0.0731\n",
            "     84        5.4839  0.0847\n",
            "     85        5.7721  0.0812\n",
            "     86        4.5311  0.0727\n",
            "     87        \u001b[36m3.3935\u001b[0m  0.0727\n",
            "     88        4.4733  0.0721\n",
            "     89        4.4394  0.0747\n",
            "     90        3.9213  0.0724\n",
            "     91        5.0145  0.0846\n",
            "     92        4.4230  0.0760\n",
            "     93        6.0444  0.0737\n",
            "     94        4.3390  0.0714\n",
            "     95        3.8706  0.0785\n",
            "     96        \u001b[36m2.8341\u001b[0m  0.0764\n",
            "     97        2.8983  0.0857\n",
            "     98        \u001b[36m2.4433\u001b[0m  0.0726\n",
            "     99        2.6668  0.0733\n",
            "    100        \u001b[36m2.3901\u001b[0m  0.0713\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m61481.7771\u001b[0m  0.0721\n",
            "      2    \u001b[36m46902.6206\u001b[0m  0.0716\n",
            "      3    \u001b[36m35214.3084\u001b[0m  0.0769\n",
            "      4    \u001b[36m26085.8547\u001b[0m  0.0711\n",
            "      5    \u001b[36m18942.8795\u001b[0m  0.0713\n",
            "      6    \u001b[36m13276.0864\u001b[0m  0.0713\n",
            "      7     \u001b[36m8661.4743\u001b[0m  0.0750\n",
            "      8     \u001b[36m4736.8376\u001b[0m  0.0746\n",
            "      9     \u001b[36m1310.1625\u001b[0m  0.0789\n",
            "     10       \u001b[36m79.1316\u001b[0m  0.0824\n",
            "     11       \u001b[36m50.7204\u001b[0m  0.0819\n",
            "     12       \u001b[36m40.6086\u001b[0m  0.0926\n",
            "     13       \u001b[36m38.9437\u001b[0m  0.1008\n",
            "     14       \u001b[36m37.0806\u001b[0m  0.1017\n",
            "     15       37.4933  0.0948\n",
            "     16       \u001b[36m35.7007\u001b[0m  0.0938\n",
            "     17       \u001b[36m32.6021\u001b[0m  0.0945\n",
            "     18       34.0370  0.1009\n",
            "     19       33.3137  0.0763\n",
            "     20       33.8229  0.0825\n",
            "     21       \u001b[36m21.3148\u001b[0m  0.0825\n",
            "     22       \u001b[36m20.8578\u001b[0m  0.0704\n",
            "     23       \u001b[36m18.9289\u001b[0m  0.0830\n",
            "     24       20.1918  0.0731\n",
            "     25       \u001b[36m18.3565\u001b[0m  0.0752\n",
            "     26       \u001b[36m17.9221\u001b[0m  0.0715\n",
            "     27       \u001b[36m16.9204\u001b[0m  0.0733\n",
            "     28       \u001b[36m16.4783\u001b[0m  0.0764\n",
            "     29       19.3338  0.0731\n",
            "     30       21.3226  0.0730\n",
            "     31       20.1910  0.0792\n",
            "     32       20.1995  0.0703\n",
            "     33       20.3214  0.0734\n",
            "     34       20.2967  0.0815\n",
            "     35       20.6599  0.0715\n",
            "     36       20.0964  0.0715\n",
            "     37       18.9012  0.0709\n",
            "     38       \u001b[36m13.8873\u001b[0m  0.0788\n",
            "     39       \u001b[36m12.6680\u001b[0m  0.0748\n",
            "     40       13.7206  0.0766\n",
            "     41       13.4882  0.0702\n",
            "     42       13.7757  0.0710\n",
            "     43       14.9495  0.0718\n",
            "     44       \u001b[36m11.9334\u001b[0m  0.0737\n",
            "     45       15.8251  0.0698\n",
            "     46       13.7129  0.0940\n",
            "     47       14.7970  0.0811\n",
            "     48       16.0041  0.0743\n",
            "     49       \u001b[36m11.6198\u001b[0m  0.0712\n",
            "     50       \u001b[36m10.5639\u001b[0m  0.0764\n",
            "     51       13.4477  0.0781\n",
            "     52       15.7564  0.0707\n",
            "     53       18.8597  0.0740\n",
            "     54       14.0813  0.0716\n",
            "     55       \u001b[36m10.5215\u001b[0m  0.0699\n",
            "     56       \u001b[36m10.4816\u001b[0m  0.0719\n",
            "     57       10.8374  0.0760\n",
            "     58        \u001b[36m8.3709\u001b[0m  0.0712\n",
            "     59        9.2775  0.0788\n",
            "     60        8.3775  0.0761\n",
            "     61       14.2283  0.1016\n",
            "     62        9.4570  0.0702\n",
            "     63        9.0513  0.0773\n",
            "     64        8.7267  0.0723\n",
            "     65       14.0329  0.0727\n",
            "     66       14.3630  0.0814\n",
            "     67       13.3913  0.0759\n",
            "     68       17.2810  0.0791\n",
            "     69       16.4888  0.0793\n",
            "     70       10.5043  0.0768\n",
            "     71       14.8535  0.0797\n",
            "     72       10.5035  0.0825\n",
            "     73       12.4754  0.0813\n",
            "     74       11.9014  0.0739\n",
            "     75       10.1131  0.0746\n",
            "     76       16.1396  0.0770\n",
            "     77        9.7692  0.0721\n",
            "     78       13.1863  0.0772\n",
            "     79       10.5344  0.0716\n",
            "     80       14.9322  0.0733\n",
            "     81       10.0858  0.0716\n",
            "     82       12.1125  0.0775\n",
            "     83       18.4826  0.0707\n",
            "     84        9.3700  0.0810\n",
            "     85       13.6619  0.0730\n",
            "     86       12.9277  0.0700\n",
            "     87       14.1908  0.0792\n",
            "     88       12.0113  0.0751\n",
            "     89       10.8373  0.0734\n",
            "     90        9.5379  0.0843\n",
            "     91       13.3788  0.0720\n",
            "     92       10.2870  0.0757\n",
            "     93       10.2986  0.0722\n",
            "     94       10.4253  0.0751\n",
            "     95        9.0942  0.0731\n",
            "     96       10.7604  0.0791\n",
            "     97       21.8573  0.0774\n",
            "     98       22.4012  0.0736\n",
            "     99       22.0043  0.0743\n",
            "    100       18.5277  0.0817\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m71941.7316\u001b[0m  0.0726\n",
            "      2    \u001b[36m55699.4595\u001b[0m  0.0714\n",
            "      3    \u001b[36m42329.5109\u001b[0m  0.0711\n",
            "      4    \u001b[36m31569.7107\u001b[0m  0.1012\n",
            "      5    \u001b[36m22899.6725\u001b[0m  0.1048\n",
            "      6    \u001b[36m15829.0546\u001b[0m  0.1035\n",
            "      7     \u001b[36m9877.3644\u001b[0m  0.1027\n",
            "      8     \u001b[36m4568.9794\u001b[0m  0.1002\n",
            "      9      \u001b[36m594.5884\u001b[0m  0.1095\n",
            "     10      \u001b[36m131.2836\u001b[0m  0.1100\n",
            "     11      \u001b[36m101.3172\u001b[0m  0.1062\n",
            "     12       \u001b[36m88.6182\u001b[0m  0.0964\n",
            "     13       \u001b[36m76.6025\u001b[0m  0.1046\n",
            "     14       \u001b[36m69.7899\u001b[0m  0.0997\n",
            "     15       \u001b[36m65.9526\u001b[0m  0.1005\n",
            "     16       \u001b[36m63.7985\u001b[0m  0.1003\n",
            "     17       \u001b[36m60.0279\u001b[0m  0.1039\n",
            "     18       \u001b[36m56.8448\u001b[0m  0.1077\n",
            "     19       \u001b[36m48.7396\u001b[0m  0.1014\n",
            "     20       53.1857  0.1109\n",
            "     21       \u001b[36m46.8788\u001b[0m  0.1111\n",
            "     22       \u001b[36m44.5753\u001b[0m  0.0974\n",
            "     23       \u001b[36m41.2570\u001b[0m  0.1002\n",
            "     24       \u001b[36m36.2755\u001b[0m  0.1002\n",
            "     25       \u001b[36m35.5869\u001b[0m  0.1019\n",
            "     26       36.9149  0.0975\n",
            "     27       36.2462  0.0987\n",
            "     28       \u001b[36m32.9078\u001b[0m  0.1026\n",
            "     29       \u001b[36m26.8535\u001b[0m  0.1047\n",
            "     30       38.2203  0.1162\n",
            "     31       \u001b[36m25.5665\u001b[0m  0.0956\n",
            "     32       36.5570  0.0998\n",
            "     33       \u001b[36m21.4522\u001b[0m  0.0998\n",
            "     34       22.1187  0.0960\n",
            "     35       26.9114  0.0990\n",
            "     36       34.7667  0.0979\n",
            "     37       27.2124  0.1109\n",
            "     38       30.3390  0.1055\n",
            "     39       35.3045  0.1089\n",
            "     40       34.7457  0.1135\n",
            "     41       27.9587  0.1189\n",
            "     42       27.1841  0.0877\n",
            "     43       31.4487  0.0715\n",
            "     44       31.4748  0.0747\n",
            "     45       28.5117  0.0692\n",
            "     46       33.1897  0.0744\n",
            "     47       28.5067  0.0750\n",
            "     48       22.2084  0.0714\n",
            "     49       33.8785  0.0791\n",
            "     50       30.6642  0.0720\n",
            "     51       23.4812  0.0765\n",
            "     52       21.8693  0.0855\n",
            "     53       25.1413  0.0729\n",
            "     54       27.1449  0.0739\n",
            "     55       33.9083  0.0745\n",
            "     56       26.9344  0.0720\n",
            "     57       22.3955  0.0795\n",
            "     58       25.3578  0.0728\n",
            "     59       34.2750  0.0722\n",
            "     60       28.4464  0.0737\n",
            "     61       30.5144  0.0782\n",
            "     62       21.5911  0.0728\n",
            "     63       24.0446  0.0775\n",
            "     64       27.4571  0.0702\n",
            "     65       22.0058  0.0844\n",
            "     66       31.3473  0.0731\n",
            "     67       31.7196  0.0803\n",
            "     68       24.2132  0.0717\n",
            "     69       28.4541  0.0722\n",
            "     70       24.5790  0.0785\n",
            "     71       \u001b[36m18.8548\u001b[0m  0.0739\n",
            "     72       22.5102  0.0856\n",
            "     73       27.6774  0.0728\n",
            "     74       24.9258  0.0760\n",
            "     75       21.2995  0.0724\n",
            "     76       27.1007  0.0742\n",
            "     77       26.4672  0.0715\n",
            "     78       27.5169  0.0915\n",
            "     79       27.2517  0.0736\n",
            "     80       21.5586  0.0734\n",
            "     81       23.8705  0.0720\n",
            "     82       27.7429  0.0728\n",
            "     83       28.9385  0.0795\n",
            "     84       27.1012  0.0738\n",
            "     85       30.1449  0.0722\n",
            "     86       23.4216  0.0773\n",
            "     87       24.4808  0.0778\n",
            "     88       22.3823  0.0725\n",
            "     89       23.7496  0.0732\n",
            "     90       25.3947  0.0754\n",
            "     91       22.7109  0.0881\n",
            "     92       26.3259  0.0717\n",
            "     93       24.3729  0.0744\n",
            "     94       23.1070  0.0725\n",
            "     95       25.6216  0.0721\n",
            "     96       30.3169  0.0793\n",
            "     97       20.9539  0.0725\n",
            "     98       21.5791  0.0727\n",
            "     99       25.2381  0.0781\n",
            "    100       22.2919  0.0788\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m94214.2447\u001b[0m  0.0701\n",
            "      2    \u001b[36m75110.7144\u001b[0m  0.0706\n",
            "      3    \u001b[36m59087.7707\u001b[0m  0.0717\n",
            "      4    \u001b[36m45977.2135\u001b[0m  0.0825\n",
            "      5    \u001b[36m35257.8395\u001b[0m  0.0788\n",
            "      6    \u001b[36m26460.8018\u001b[0m  0.0734\n",
            "      7    \u001b[36m19176.6294\u001b[0m  0.0717\n",
            "      8    \u001b[36m13041.3694\u001b[0m  0.0728\n",
            "      9     \u001b[36m7728.1420\u001b[0m  0.0757\n",
            "     10     \u001b[36m2905.1860\u001b[0m  0.0732\n",
            "     11      \u001b[36m201.1573\u001b[0m  0.0781\n",
            "     12       \u001b[36m99.2712\u001b[0m  0.0729\n",
            "     13       \u001b[36m87.2596\u001b[0m  0.0797\n",
            "     14       \u001b[36m79.9066\u001b[0m  0.0714\n",
            "     15       \u001b[36m72.1592\u001b[0m  0.0692\n",
            "     16       \u001b[36m71.5544\u001b[0m  0.0717\n",
            "     17       \u001b[36m69.6381\u001b[0m  0.0750\n",
            "     18       \u001b[36m66.4638\u001b[0m  0.0828\n",
            "     19       \u001b[36m60.8272\u001b[0m  0.0708\n",
            "     20       \u001b[36m38.4389\u001b[0m  0.0719\n",
            "     21       \u001b[36m31.4263\u001b[0m  0.0751\n",
            "     22       \u001b[36m29.6061\u001b[0m  0.0729\n",
            "     23       \u001b[36m25.5871\u001b[0m  0.0789\n",
            "     24       \u001b[36m22.6436\u001b[0m  0.0731\n",
            "     25       23.0462  0.0715\n",
            "     26       \u001b[36m21.9632\u001b[0m  0.0705\n",
            "     27       \u001b[36m18.1512\u001b[0m  0.0751\n",
            "     28       22.7461  0.0739\n",
            "     29       20.9974  0.0787\n",
            "     30       22.3288  0.0729\n",
            "     31       23.2637  0.0827\n",
            "     32       28.0030  0.0746\n",
            "     33       24.1322  0.0732\n",
            "     34       22.5901  0.0767\n",
            "     35       23.7984  0.0749\n",
            "     36       19.1343  0.0716\n",
            "     37       \u001b[36m14.3410\u001b[0m  0.0709\n",
            "     38       \u001b[36m11.9420\u001b[0m  0.0759\n",
            "     39       13.8882  0.0713\n",
            "     40       13.9498  0.0766\n",
            "     41       18.3335  0.0709\n",
            "     42       25.5989  0.0708\n",
            "     43       23.4134  0.0752\n",
            "     44       13.2071  0.0816\n",
            "     45       \u001b[36m11.4781\u001b[0m  0.0773\n",
            "     46       11.5706  0.0707\n",
            "     47       12.0059  0.0724\n",
            "     48       13.8763  0.0742\n",
            "     49       12.9243  0.0722\n",
            "     50       \u001b[36m11.2836\u001b[0m  0.1277\n",
            "     51       \u001b[36m10.4376\u001b[0m  0.1352\n",
            "     52        \u001b[36m6.8516\u001b[0m  0.1100\n",
            "     53        9.8032  0.1286\n",
            "     54        8.4709  0.1398\n",
            "     55        9.3347  0.1483\n",
            "     56        7.1953  0.0718\n",
            "     57       11.7522  0.0705\n",
            "     58       13.3017  0.0719\n",
            "     59        \u001b[36m6.0644\u001b[0m  0.0730\n",
            "     60        9.1342  0.0714\n",
            "     61       10.9046  0.0741\n",
            "     62        6.6832  0.0718\n",
            "     63        6.9288  0.0829\n",
            "     64        6.9619  0.0737\n",
            "     65       12.3602  0.0720\n",
            "     66       12.4939  0.1073\n",
            "     67        7.1960  0.1053\n",
            "     68        \u001b[36m5.4672\u001b[0m  0.1064\n",
            "     69        8.5530  0.1081\n",
            "     70       13.2064  0.1091\n",
            "     71        6.5485  0.0988\n",
            "     72        7.7220  0.1158\n",
            "     73       12.8280  0.1045\n",
            "     74       13.1423  0.1005\n",
            "     75        6.0711  0.1163\n",
            "     76        6.6322  0.1043\n",
            "     77       13.0815  0.0996\n",
            "     78        7.3876  0.1198\n",
            "     79        9.3892  0.1110\n",
            "     80       15.0513  0.1033\n",
            "     81        6.4553  0.1311\n",
            "     82        7.1310  0.1463\n",
            "     83       10.5295  0.1317\n",
            "     84       12.1156  0.1087\n",
            "     85        7.3426  0.1031\n",
            "     86        6.6023  0.0996\n",
            "     87        7.1510  0.1024\n",
            "     88       14.4290  0.0990\n",
            "     89       13.5899  0.0976\n",
            "     90        5.7438  0.0988\n",
            "     91       12.8815  0.1018\n",
            "     92       12.9419  0.0966\n",
            "     93       12.1802  0.1197\n",
            "     94       11.0082  0.1130\n",
            "     95        6.3261  0.1028\n",
            "     96        6.9353  0.1024\n",
            "     97        8.6498  0.1076\n",
            "     98        7.8261  0.1139\n",
            "     99        9.3667  0.1051\n",
            "    100        8.1400  0.1009\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m61712.8315\u001b[0m  0.1103\n",
            "      2    \u001b[36m47505.1762\u001b[0m  0.1160\n",
            "      3    \u001b[36m36062.0725\u001b[0m  0.1111\n",
            "      4    \u001b[36m27002.1339\u001b[0m  0.0794\n",
            "      5    \u001b[36m19770.5901\u001b[0m  0.0819\n",
            "      6    \u001b[36m13898.7511\u001b[0m  0.0940\n",
            "      7     \u001b[36m8993.6533\u001b[0m  0.1020\n",
            "      8     \u001b[36m4688.5901\u001b[0m  0.1014\n",
            "      9      \u001b[36m961.2024\u001b[0m  0.0960\n",
            "     10       \u001b[36m94.9117\u001b[0m  0.0920\n",
            "     11       \u001b[36m59.1391\u001b[0m  0.0763\n",
            "     12       \u001b[36m52.5984\u001b[0m  0.0758\n",
            "     13       \u001b[36m45.7095\u001b[0m  0.0781\n",
            "     14       \u001b[36m36.4833\u001b[0m  0.0927\n",
            "     15       \u001b[36m19.2564\u001b[0m  0.0845\n",
            "     16       \u001b[36m13.7477\u001b[0m  0.0751\n",
            "     17       \u001b[36m11.6046\u001b[0m  0.0789\n",
            "     18       \u001b[36m11.3943\u001b[0m  0.0715\n",
            "     19        \u001b[36m9.9820\u001b[0m  0.0722\n",
            "     20        \u001b[36m9.5728\u001b[0m  0.0707\n",
            "     21        \u001b[36m9.2655\u001b[0m  0.0802\n",
            "     22        \u001b[36m8.4931\u001b[0m  0.0708\n",
            "     23        \u001b[36m7.8271\u001b[0m  0.0732\n",
            "     24        \u001b[36m7.7660\u001b[0m  0.0739\n",
            "     25        \u001b[36m7.3051\u001b[0m  0.0747\n",
            "     26        \u001b[36m6.0623\u001b[0m  0.0827\n",
            "     27        \u001b[36m6.0395\u001b[0m  0.0804\n",
            "     28        6.7115  0.0731\n",
            "     29        7.5625  0.0737\n",
            "     30        9.1865  0.0718\n",
            "     31       10.7123  0.0760\n",
            "     32        7.4374  0.0725\n",
            "     33       12.6440  0.0758\n",
            "     34        9.2492  0.0724\n",
            "     35       11.6282  0.0735\n",
            "     36       10.2683  0.0742\n",
            "     37        6.1190  0.0768\n",
            "     38       11.5625  0.0717\n",
            "     39        7.4936  0.0864\n",
            "     40        8.1230  0.0916\n",
            "     41       14.6869  0.0729\n",
            "     42        8.2611  0.0735\n",
            "     43        7.4020  0.0822\n",
            "     44        6.7555  0.0714\n",
            "     45       14.4152  0.0733\n",
            "     46        6.5052  0.0725\n",
            "     47        7.9159  0.0765\n",
            "     48        \u001b[36m5.7284\u001b[0m  0.0812\n",
            "     49        7.0599  0.0718\n",
            "     50        \u001b[36m5.4838\u001b[0m  0.0750\n",
            "     51        8.2836  0.0753\n",
            "     52        \u001b[36m4.4301\u001b[0m  0.0722\n",
            "     53        8.0099  0.0889\n",
            "     54        6.2044  0.0731\n",
            "     55        5.4808  0.0818\n",
            "     56        7.4309  0.0724\n",
            "     57        5.5760  0.0736\n",
            "     58        5.2225  0.0757\n",
            "     59        5.9363  0.0895\n",
            "     60        5.8760  0.0799\n",
            "     61        7.6245  0.0738\n",
            "     62        \u001b[36m4.3511\u001b[0m  0.0773\n",
            "     63        5.0055  0.0735\n",
            "     64        4.8691  0.0744\n",
            "     65        4.7464  0.0789\n",
            "     66        5.0653  0.0877\n",
            "     67        5.2659  0.0864\n",
            "     68        \u001b[36m3.5005\u001b[0m  0.0756\n",
            "     69        3.6397  0.0723\n",
            "     70        5.9089  0.0732\n",
            "     71        \u001b[36m3.1932\u001b[0m  0.0761\n",
            "     72        7.8197  0.0738\n",
            "     73        \u001b[36m2.7907\u001b[0m  0.0726\n",
            "     74        5.4611  0.0734\n",
            "     75        3.3177  0.0768\n",
            "     76        5.1900  0.0802\n",
            "     77        4.7251  0.0713\n",
            "     78        5.3611  0.0715\n",
            "     79        3.4760  0.0977\n",
            "     80        9.6087  0.0741\n",
            "     81        6.6302  0.0735\n",
            "     82        3.3746  0.0720\n",
            "     83        5.5767  0.0738\n",
            "     84        3.3632  0.0714\n",
            "     85        8.0696  0.0800\n",
            "     86        5.8967  0.0772\n",
            "     87       10.7813  0.0770\n",
            "     88        3.4837  0.0731\n",
            "     89       10.1564  0.0728\n",
            "     90        4.6980  0.0792\n",
            "     91        6.6470  0.0814\n",
            "     92        3.6903  0.0806\n",
            "     93        7.6352  0.0741\n",
            "     94        7.4602  0.0717\n",
            "     95        3.1332  0.0762\n",
            "     96        5.4852  0.0706\n",
            "     97        4.3439  0.0752\n",
            "     98       13.0248  0.0738\n",
            "     99        4.2787  0.0771\n",
            "    100       11.5322  0.0728\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m93168.4572\u001b[0m  0.0756\n",
            "      2    \u001b[36m74422.2330\u001b[0m  0.0792\n",
            "      3    \u001b[36m58950.9349\u001b[0m  0.0865\n",
            "      4    \u001b[36m46514.5195\u001b[0m  0.0734\n",
            "      5    \u001b[36m36572.2911\u001b[0m  0.0820\n",
            "      6    \u001b[36m28577.0301\u001b[0m  0.0745\n",
            "      7    \u001b[36m22083.9118\u001b[0m  0.1016\n",
            "      8    \u001b[36m16734.0763\u001b[0m  0.0952\n",
            "      9    \u001b[36m12176.0611\u001b[0m  0.0961\n",
            "     10     \u001b[36m8123.3709\u001b[0m  0.0941\n",
            "     11     \u001b[36m4326.1960\u001b[0m  0.0927\n",
            "     12      \u001b[36m896.8576\u001b[0m  0.1021\n",
            "     13      \u001b[36m146.8516\u001b[0m  0.0858\n",
            "     14       \u001b[36m91.3371\u001b[0m  0.0769\n",
            "     15       \u001b[36m80.0960\u001b[0m  0.0779\n",
            "     16       \u001b[36m67.4150\u001b[0m  0.0887\n",
            "     17       67.5165  0.0763\n",
            "     18       \u001b[36m64.8420\u001b[0m  0.0750\n",
            "     19       \u001b[36m63.5850\u001b[0m  0.0723\n",
            "     20       \u001b[36m63.2043\u001b[0m  0.0737\n",
            "     21       \u001b[36m59.2238\u001b[0m  0.0764\n",
            "     22       \u001b[36m58.8564\u001b[0m  0.0777\n",
            "     23       60.8903  0.0766\n",
            "     24       \u001b[36m58.0884\u001b[0m  0.0742\n",
            "     25       \u001b[36m52.1619\u001b[0m  0.0780\n",
            "     26       57.3550  0.0737\n",
            "     27       56.6411  0.0961\n",
            "     28       \u001b[36m48.9010\u001b[0m  0.1305\n",
            "     29       56.6009  0.1005\n",
            "     30       49.7178  0.0995\n",
            "     31       49.7128  0.1049\n",
            "     32       \u001b[36m45.6122\u001b[0m  0.1022\n",
            "     33       \u001b[36m45.1938\u001b[0m  0.0982\n",
            "     34       \u001b[36m43.7400\u001b[0m  0.1098\n",
            "     35       \u001b[36m43.0247\u001b[0m  0.1032\n",
            "     36       \u001b[36m40.4372\u001b[0m  0.1060\n",
            "     37       45.3963  0.1796\n",
            "     38       41.2262  0.1041\n",
            "     39       42.0448  0.1073\n",
            "     40       \u001b[36m34.5900\u001b[0m  0.1115\n",
            "     41       41.3296  0.1060\n",
            "     42       35.4020  0.1522\n",
            "     43       39.4645  0.1052\n",
            "     44       \u001b[36m33.2192\u001b[0m  0.1046\n",
            "     45       \u001b[36m31.4367\u001b[0m  0.1002\n",
            "     46       38.9996  0.1124\n",
            "     47       \u001b[36m29.2089\u001b[0m  0.1031\n",
            "     48       32.1845  0.1018\n",
            "     49       35.9389  0.0990\n",
            "     50       36.4580  0.1123\n",
            "     51       29.2672  0.1017\n",
            "     52       31.4561  0.1118\n",
            "     53       35.6313  0.1041\n",
            "     54       \u001b[36m26.5214\u001b[0m  0.1025\n",
            "     55       31.5273  0.1040\n",
            "     56       29.6585  0.1045\n",
            "     57       28.5569  0.1019\n",
            "     58       31.1555  0.1118\n",
            "     59       30.9334  0.1100\n",
            "     60       \u001b[36m24.3354\u001b[0m  0.1110\n",
            "     61       \u001b[36m24.1598\u001b[0m  0.1137\n",
            "     62       \u001b[36m23.8875\u001b[0m  0.1110\n",
            "     63       26.5889  0.0936\n",
            "     64       25.6032  0.0757\n",
            "     65       \u001b[36m23.5248\u001b[0m  0.0712\n",
            "     66       26.7715  0.0809\n",
            "     67       \u001b[36m21.7294\u001b[0m  0.0816\n",
            "     68       22.8798  0.0728\n",
            "     69       23.2505  0.0706\n",
            "     70       23.7019  0.0717\n",
            "     71       38.4528  0.0764\n",
            "     72       23.9698  0.0773\n",
            "     73       24.5965  0.0790\n",
            "     74       \u001b[36m21.2694\u001b[0m  0.0765\n",
            "     75       21.5546  0.0895\n",
            "     76       22.0107  0.0790\n",
            "     77       22.9097  0.0742\n",
            "     78       21.9368  0.0783\n",
            "     79       23.1473  0.0835\n",
            "     80       21.9871  0.0724\n",
            "     81       25.1079  0.0724\n",
            "     82       23.0638  0.0731\n",
            "     83       24.2039  0.0713\n",
            "     84       22.5910  0.0818\n",
            "     85       21.7344  0.0751\n",
            "     86       \u001b[36m20.5269\u001b[0m  0.0725\n",
            "     87       20.8690  0.0721\n",
            "     88       20.9554  0.0721\n",
            "     89       21.4754  0.0767\n",
            "     90       \u001b[36m19.3539\u001b[0m  0.0723\n",
            "     91       19.6578  0.0749\n",
            "     92       27.9815  0.0818\n",
            "     93       22.0502  0.0714\n",
            "     94       \u001b[36m18.9678\u001b[0m  0.0809\n",
            "     95       \u001b[36m17.6948\u001b[0m  0.0713\n",
            "     96       24.1394  0.0739\n",
            "     97       17.8268  0.0787\n",
            "     98       21.4169  0.0751\n",
            "     99       23.4030  0.0766\n",
            "    100       18.5879  0.0765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpZ7ew7-AKUg",
        "outputId": "ff22aa49-d686-45cd-94c6-9cda23084125"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AcurÃ¡cia de cada uma das 10 partiÃ§Ãµes da validaÃ§Ã£o cruzada:\n",
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BlQjdB7HIWH",
        "outputId": "6905ed13-c3e4-4449-da49-b6358a92b965"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.80701754, 0.78947368, 0.84210526, 0.9122807 , 0.8245614 ,\n",
              "       0.94736842, 0.84210526, 0.87719298, 0.50877193, 0.875     ])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media = resultados.mean()\n",
        "media"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVz_ztM1HNM8",
        "outputId": "7844d59a-bb95-4d37-84a7-d288a836c80e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8225877192982456"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desvio = resultados.std()\n",
        "desvio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAIviys7HaDG",
        "outputId": "952bf8f7-4733-492d-c1bd-8e9a17c1a6f1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11398636779767021"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WetUMNgmHjCd"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout\n",
        "\n",
        "##### Evita Overffiting"
      ],
      "metadata": {
        "id": "l0k0dlRDH1pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# O skorch exige que a rn seja passada como uma classe que herda do nn.Module:\n",
        "\n",
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Contruindo a rede: 30 -> 16 -> 16 -> 1\n",
        "\n",
        "    # 1) 30 -> 16:\n",
        "    self.dense0 = nn.Linear(30, 16)\n",
        "    torch.nn.init.uniform_(self.dense0.weight)\n",
        "    self.activation0 = nn.ReLU()\n",
        "    self.dropout0 = nn.Dropout(0.1)\n",
        "    # 2) 16 -> 16:\n",
        "    self.dense1 = nn.Linear(16, 16)\n",
        "    torch.nn.init.uniform_(self.dense1.weight)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.dropout1 = nn.Dropout(0.1)\n",
        "    # 3) 16 -> 1:\n",
        "    self.dense2 = nn.Linear(16, 1)\n",
        "    torch.nn.init.uniform_(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() ** ATUALIZAÃ‡ÃƒO (ver detalhes no texto acima) **\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dropout0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dropout1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) ** ATUALIZAÃ‡ÃƒO (ver detalhes no texto acima) **\n",
        "    return X"
      ],
      "metadata": {
        "id": "XcVBtv8hH3Lz"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  criterion=torch.nn.BCEWithLogitsLoss,\n",
        "                                                  optimizer=torch.optim.Adam,\n",
        "                                                  lr=0.001,\n",
        "                                                  optimizer__weight_decay=0.0001,\n",
        "                                                  max_epochs=100,\n",
        "                                                  batch_size=10,\n",
        "                                                  train_split=False) #False para que o split seja feita a validaÃ§Ã£o cruzada"
      ],
      "metadata": {
        "id": "hCBhXvLOKynC"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = cross_val_score(classificador_sklearn,previsores,classe,cv=10,scoring='accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgPcdhJfK3KA",
        "outputId": "2b518a89-2f3c-44bf-aa08-8c46c012e92e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m91270.4574\u001b[0m  0.1806\n",
            "      2    \u001b[36m74912.4777\u001b[0m  0.1576\n",
            "      3    \u001b[36m58526.1108\u001b[0m  0.1586\n",
            "      4    \u001b[36m46221.4592\u001b[0m  0.1816\n",
            "      5    \u001b[36m36319.4100\u001b[0m  0.1700\n",
            "      6    \u001b[36m28615.7540\u001b[0m  0.0780\n",
            "      7    \u001b[36m21928.5014\u001b[0m  0.1343\n",
            "      8    \u001b[36m17328.7621\u001b[0m  0.1253\n",
            "      9    \u001b[36m12672.3605\u001b[0m  0.2933\n",
            "     10     \u001b[36m8656.2915\u001b[0m  0.2420\n",
            "     11     \u001b[36m5516.5527\u001b[0m  0.1557\n",
            "     12     \u001b[36m2778.3078\u001b[0m  0.1220\n",
            "     13     \u001b[36m1341.5398\u001b[0m  0.1477\n",
            "     14     \u001b[36m1186.4450\u001b[0m  0.2121\n",
            "     15      \u001b[36m882.7500\u001b[0m  0.1900\n",
            "     16     1017.4347  0.2880\n",
            "     17      918.5328  0.4917\n",
            "     18      907.6660  0.5359\n",
            "     19      958.9967  0.3677\n",
            "     20      \u001b[36m856.3429\u001b[0m  0.3587\n",
            "     21      952.7959  0.4848\n",
            "     22      \u001b[36m828.2438\u001b[0m  0.4618\n",
            "     23      \u001b[36m812.4978\u001b[0m  0.3420\n",
            "     24      \u001b[36m798.8186\u001b[0m  0.4683\n",
            "     25      \u001b[36m619.5692\u001b[0m  0.4178\n",
            "     26      \u001b[36m598.8920\u001b[0m  0.5115\n",
            "     27      635.8735  0.2290\n",
            "     28      619.8163  0.2104\n",
            "     29      645.8997  0.1710\n",
            "     30      \u001b[36m556.4352\u001b[0m  0.3655\n",
            "     31      591.3395  0.3408\n",
            "     32      591.1129  0.1534\n",
            "     33      \u001b[36m551.5435\u001b[0m  0.0782\n",
            "     34      \u001b[36m535.3268\u001b[0m  0.0774\n",
            "     35      \u001b[36m403.8591\u001b[0m  0.0924\n",
            "     36      408.0290  0.0778\n",
            "     37      491.1877  0.0823\n",
            "     38      529.5406  0.0778\n",
            "     39      449.6497  0.0765\n",
            "     40      \u001b[36m345.5179\u001b[0m  0.0861\n",
            "     41      427.7293  0.0765\n",
            "     42      421.8809  0.0774\n",
            "     43      372.9418  0.0810\n",
            "     44      \u001b[36m291.9516\u001b[0m  0.0764\n",
            "     45      305.2133  0.0781\n",
            "     46      \u001b[36m245.1872\u001b[0m  0.0829\n",
            "     47      304.5848  0.0848\n",
            "     48      300.6392  0.0778\n",
            "     49      293.5779  0.0858\n",
            "     50      312.9324  0.0783\n",
            "     51      \u001b[36m229.2764\u001b[0m  0.0854\n",
            "     52      259.7676  0.0779\n",
            "     53      \u001b[36m226.8622\u001b[0m  0.0773\n",
            "     54      \u001b[36m219.9235\u001b[0m  0.0764\n",
            "     55      \u001b[36m212.4270\u001b[0m  0.0777\n",
            "     56      224.2456  0.0825\n",
            "     57      \u001b[36m185.9912\u001b[0m  0.0802\n",
            "     58      199.1738  0.0804\n",
            "     59      \u001b[36m164.9184\u001b[0m  0.0758\n",
            "     60      167.7595  0.0838\n",
            "     61      \u001b[36m128.9752\u001b[0m  0.0810\n",
            "     62      149.1521  0.0780\n",
            "     63      129.6221  0.0768\n",
            "     64      156.0120  0.0791\n",
            "     65      \u001b[36m119.5578\u001b[0m  0.0783\n",
            "     66      132.1708  0.0775\n",
            "     67      \u001b[36m104.9950\u001b[0m  0.0773\n",
            "     68      \u001b[36m104.9323\u001b[0m  0.0759\n",
            "     69      \u001b[36m104.5362\u001b[0m  0.0837\n",
            "     70       \u001b[36m87.7223\u001b[0m  0.0779\n",
            "     71       98.8204  0.0796\n",
            "     72       90.3943  0.0943\n",
            "     73       \u001b[36m79.6364\u001b[0m  0.0822\n",
            "     74       \u001b[36m75.5569\u001b[0m  0.0843\n",
            "     75       \u001b[36m74.1861\u001b[0m  0.0782\n",
            "     76       80.6063  0.0861\n",
            "     77       \u001b[36m61.0491\u001b[0m  0.0780\n",
            "     78       67.2093  0.0859\n",
            "     79       67.1822  0.0776\n",
            "     80       \u001b[36m55.7862\u001b[0m  0.0824\n",
            "     81       70.0262  0.0803\n",
            "     82       60.7491  0.0849\n",
            "     83       58.2817  0.0778\n",
            "     84       \u001b[36m52.5496\u001b[0m  0.0901\n",
            "     85       61.3351  0.0892\n",
            "     86       \u001b[36m47.9879\u001b[0m  0.0782\n",
            "     87       54.4684  0.0780\n",
            "     88       \u001b[36m39.6761\u001b[0m  0.0792\n",
            "     89       \u001b[36m39.4400\u001b[0m  0.0899\n",
            "     90       \u001b[36m35.0976\u001b[0m  0.0795\n",
            "     91       50.7363  0.0787\n",
            "     92       44.5146  0.0829\n",
            "     93       38.7133  0.0825\n",
            "     94       36.6441  0.0775\n",
            "     95       \u001b[36m34.9441\u001b[0m  0.0786\n",
            "     96       \u001b[36m31.5189\u001b[0m  0.0877\n",
            "     97       31.7708  0.0852\n",
            "     98       \u001b[36m29.2863\u001b[0m  0.0790\n",
            "     99       \u001b[36m26.6933\u001b[0m  0.0870\n",
            "    100       27.0697  0.0801\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m66245.9051\u001b[0m  0.0754\n",
            "      2    \u001b[36m51767.7765\u001b[0m  0.0924\n",
            "      3    \u001b[36m38510.7432\u001b[0m  0.0877\n",
            "      4    \u001b[36m28147.7510\u001b[0m  0.0776\n",
            "      5    \u001b[36m20197.8419\u001b[0m  0.0794\n",
            "      6    \u001b[36m14167.3206\u001b[0m  0.0809\n",
            "      7     \u001b[36m8642.7012\u001b[0m  0.0798\n",
            "      8     \u001b[36m3589.2563\u001b[0m  0.0949\n",
            "      9     \u001b[36m1600.3676\u001b[0m  0.0889\n",
            "     10     \u001b[36m1445.9634\u001b[0m  0.0794\n",
            "     11     \u001b[36m1229.0978\u001b[0m  0.0777\n",
            "     12     1525.8521  0.0793\n",
            "     13     1322.6658  0.0793\n",
            "     14     \u001b[36m1107.2081\u001b[0m  0.0835\n",
            "     15     1306.5289  0.0765\n",
            "     16     1129.1038  0.0766\n",
            "     17     \u001b[36m1052.0430\u001b[0m  0.0879\n",
            "     18     1105.6802  0.0793\n",
            "     19      \u001b[36m839.1007\u001b[0m  0.0781\n",
            "     20     1025.0946  0.0826\n",
            "     21      912.3480  0.0873\n",
            "     22      \u001b[36m828.0561\u001b[0m  0.0827\n",
            "     23      871.9358  0.0883\n",
            "     24      \u001b[36m793.6758\u001b[0m  0.0779\n",
            "     25      852.8546  0.0769\n",
            "     26      \u001b[36m749.9246\u001b[0m  0.0777\n",
            "     27      \u001b[36m738.2700\u001b[0m  0.0755\n",
            "     28      810.7803  0.0881\n",
            "     29      \u001b[36m686.7828\u001b[0m  0.0823\n",
            "     30      725.6519  0.0753\n",
            "     31      \u001b[36m646.0202\u001b[0m  0.0780\n",
            "     32      \u001b[36m618.5049\u001b[0m  0.0784\n",
            "     33      663.9556  0.0976\n",
            "     34      \u001b[36m608.6316\u001b[0m  0.1129\n",
            "     35      \u001b[36m562.5861\u001b[0m  0.1183\n",
            "     36      588.6573  0.1090\n",
            "     37      \u001b[36m436.3977\u001b[0m  0.1079\n",
            "     38      494.4506  0.1098\n",
            "     39      509.2052  0.1097\n",
            "     40      438.1581  0.1128\n",
            "     41      455.8054  0.1082\n",
            "     42      \u001b[36m407.2646\u001b[0m  0.1200\n",
            "     43      409.4121  0.1083\n",
            "     44      \u001b[36m338.2841\u001b[0m  0.1080\n",
            "     45      384.1008  0.1088\n",
            "     46      \u001b[36m304.4284\u001b[0m  0.1130\n",
            "     47      330.5267  0.1102\n",
            "     48      305.9171  0.1152\n",
            "     49      \u001b[36m304.3582\u001b[0m  0.1090\n",
            "     50      \u001b[36m261.0766\u001b[0m  0.1163\n",
            "     51      \u001b[36m234.8478\u001b[0m  0.1157\n",
            "     52      235.9528  0.1066\n",
            "     53      \u001b[36m209.4428\u001b[0m  0.1057\n",
            "     54      228.9252  0.1045\n",
            "     55      \u001b[36m199.4675\u001b[0m  0.1036\n",
            "     56      \u001b[36m192.9313\u001b[0m  0.1095\n",
            "     57      201.6302  0.1118\n",
            "     58      \u001b[36m176.1327\u001b[0m  0.1052\n",
            "     59      183.9342  0.1124\n",
            "     60      \u001b[36m153.3153\u001b[0m  0.1105\n",
            "     61      168.5933  0.1062\n",
            "     62      190.4029  0.1063\n",
            "     63      \u001b[36m136.5984\u001b[0m  0.1086\n",
            "     64      141.0394  0.1182\n",
            "     65      \u001b[36m114.7479\u001b[0m  0.1111\n",
            "     66      \u001b[36m110.4075\u001b[0m  0.1089\n",
            "     67      \u001b[36m105.7614\u001b[0m  0.1161\n",
            "     68      \u001b[36m102.0450\u001b[0m  0.1176\n",
            "     69       \u001b[36m95.8438\u001b[0m  0.1206\n",
            "     70       \u001b[36m95.0459\u001b[0m  0.0789\n",
            "     71       \u001b[36m81.3916\u001b[0m  0.0881\n",
            "     72      106.2622  0.0777\n",
            "     73       82.8318  0.0782\n",
            "     74       \u001b[36m71.6851\u001b[0m  0.0780\n",
            "     75       \u001b[36m64.2318\u001b[0m  0.0816\n",
            "     76       71.4254  0.0859\n",
            "     77       67.3875  0.0772\n",
            "     78       \u001b[36m56.8766\u001b[0m  0.0798\n",
            "     79       \u001b[36m51.1678\u001b[0m  0.0790\n",
            "     80       \u001b[36m42.5036\u001b[0m  0.0818\n",
            "     81       51.3198  0.0899\n",
            "     82       47.0256  0.0802\n",
            "     83       46.1882  0.0803\n",
            "     84       \u001b[36m41.9863\u001b[0m  0.0786\n",
            "     85       42.5948  0.0867\n",
            "     86       44.6050  0.0853\n",
            "     87       \u001b[36m33.3924\u001b[0m  0.0778\n",
            "     88       35.7945  0.0796\n",
            "     89       34.8685  0.0791\n",
            "     90       34.7244  0.0832\n",
            "     91       \u001b[36m25.3999\u001b[0m  0.0819\n",
            "     92       28.1265  0.0900\n",
            "     93       28.3668  0.0988\n",
            "     94       28.0159  0.1000\n",
            "     95       \u001b[36m23.0119\u001b[0m  0.1075\n",
            "     96       24.3497  0.1052\n",
            "     97       \u001b[36m22.2841\u001b[0m  0.1021\n",
            "     98       \u001b[36m21.3258\u001b[0m  0.0999\n",
            "     99       \u001b[36m18.4501\u001b[0m  0.1046\n",
            "    100       20.3597  0.1048\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m89958.0920\u001b[0m  0.0797\n",
            "      2    \u001b[36m72589.3745\u001b[0m  0.0787\n",
            "      3    \u001b[36m57352.6178\u001b[0m  0.0919\n",
            "      4    \u001b[36m46043.0015\u001b[0m  0.0945\n",
            "      5    \u001b[36m35808.8674\u001b[0m  0.0797\n",
            "      6    \u001b[36m28077.5018\u001b[0m  0.0781\n",
            "      7    \u001b[36m21901.0378\u001b[0m  0.0880\n",
            "      8    \u001b[36m16809.1590\u001b[0m  0.0782\n",
            "      9    \u001b[36m13104.0054\u001b[0m  0.0837\n",
            "     10     \u001b[36m9370.0818\u001b[0m  0.0793\n",
            "     11     \u001b[36m6555.7037\u001b[0m  0.0780\n",
            "     12     \u001b[36m3985.0536\u001b[0m  0.0814\n",
            "     13     \u001b[36m1583.4902\u001b[0m  0.0792\n",
            "     14     \u001b[36m1158.9545\u001b[0m  0.0841\n",
            "     15     \u001b[36m1056.6128\u001b[0m  0.0877\n",
            "     16      \u001b[36m799.3435\u001b[0m  0.0786\n",
            "     17      857.6100  0.0819\n",
            "     18      858.7294  0.0778\n",
            "     19      \u001b[36m725.8570\u001b[0m  0.0797\n",
            "     20      896.5875  0.0781\n",
            "     21      \u001b[36m603.4546\u001b[0m  0.0789\n",
            "     22      784.6196  0.0782\n",
            "     23      680.2836  0.0825\n",
            "     24      667.0667  0.0817\n",
            "     25      697.5825  0.0853\n",
            "     26      756.5488  0.0771\n",
            "     27      700.5944  0.0772\n",
            "     28      \u001b[36m501.0804\u001b[0m  0.0926\n",
            "     29      652.8187  0.0796\n",
            "     30      \u001b[36m458.2001\u001b[0m  0.0805\n",
            "     31      564.6818  0.0814\n",
            "     32      496.3794  0.0797\n",
            "     33      537.7458  0.0784\n",
            "     34      464.4284  0.0822\n",
            "     35      \u001b[36m404.2344\u001b[0m  0.0774\n",
            "     36      \u001b[36m387.2867\u001b[0m  0.0880\n",
            "     37      415.5766  0.0804\n",
            "     38      \u001b[36m384.0084\u001b[0m  0.0772\n",
            "     39      \u001b[36m378.3032\u001b[0m  0.0818\n",
            "     40      400.6997  0.0867\n",
            "     41      380.3390  0.0785\n",
            "     42      383.2574  0.0786\n",
            "     43      \u001b[36m336.9969\u001b[0m  0.0763\n",
            "     44      357.3786  0.0775\n",
            "     45      \u001b[36m276.9895\u001b[0m  0.0798\n",
            "     46      290.4812  0.0855\n",
            "     47      332.4312  0.0773\n",
            "     48      \u001b[36m247.3962\u001b[0m  0.0788\n",
            "     49      334.4310  0.0802\n",
            "     50      268.0538  0.0849\n",
            "     51      \u001b[36m231.3621\u001b[0m  0.1028\n",
            "     52      274.1690  0.1142\n",
            "     53      244.1730  0.1091\n",
            "     54      238.9279  0.1010\n",
            "     55      \u001b[36m216.2171\u001b[0m  0.0806\n",
            "     56      \u001b[36m206.7600\u001b[0m  0.0802\n",
            "     57      \u001b[36m186.3877\u001b[0m  0.0781\n",
            "     58      194.3358  0.0902\n",
            "     59      \u001b[36m181.7392\u001b[0m  0.0786\n",
            "     60      \u001b[36m158.0302\u001b[0m  0.0886\n",
            "     61      \u001b[36m144.0375\u001b[0m  0.0782\n",
            "     62      \u001b[36m137.0674\u001b[0m  0.0764\n",
            "     63      155.0022  0.0931\n",
            "     64      153.1163  0.0783\n",
            "     65      \u001b[36m108.5197\u001b[0m  0.0836\n",
            "     66      121.0431  0.0819\n",
            "     67      \u001b[36m102.0884\u001b[0m  0.0800\n",
            "     68       \u001b[36m85.1149\u001b[0m  0.0784\n",
            "     69      106.4754  0.0833\n",
            "     70      102.2499  0.0809\n",
            "     71       91.8803  0.0840\n",
            "     72       88.2139  0.0796\n",
            "     73       \u001b[36m78.8617\u001b[0m  0.0788\n",
            "     74       \u001b[36m74.6165\u001b[0m  0.0780\n",
            "     75       81.6327  0.0828\n",
            "     76       75.3290  0.0822\n",
            "     77       \u001b[36m70.2413\u001b[0m  0.0783\n",
            "     78       \u001b[36m55.4836\u001b[0m  0.0762\n",
            "     79       71.9903  0.0851\n",
            "     80       56.9042  0.0793\n",
            "     81       68.7686  0.0783\n",
            "     82       60.4832  0.0796\n",
            "     83       \u001b[36m55.1469\u001b[0m  0.0771\n",
            "     84       \u001b[36m52.5488\u001b[0m  0.0809\n",
            "     85       \u001b[36m48.7049\u001b[0m  0.0950\n",
            "     86       48.8438  0.1226\n",
            "     87       \u001b[36m36.5045\u001b[0m  0.1259\n",
            "     88       39.1427  0.1147\n",
            "     89       \u001b[36m29.6739\u001b[0m  0.1146\n",
            "     90       33.3181  0.1108\n",
            "     91       32.5594  0.1172\n",
            "     92       \u001b[36m28.3101\u001b[0m  0.1168\n",
            "     93       33.0960  0.1076\n",
            "     94       29.6712  0.1075\n",
            "     95       \u001b[36m27.2206\u001b[0m  0.1072\n",
            "     96       33.3401  0.1161\n",
            "     97       29.2527  0.1171\n",
            "     98       28.3204  0.1129\n",
            "     99       \u001b[36m20.2080\u001b[0m  0.1148\n",
            "    100       22.7341  0.1171\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m75837.1700\u001b[0m  0.1195\n",
            "      2    \u001b[36m60231.6015\u001b[0m  0.1124\n",
            "      3    \u001b[36m46340.8961\u001b[0m  0.1072\n",
            "      4    \u001b[36m35588.2163\u001b[0m  0.1085\n",
            "      5    \u001b[36m26540.5978\u001b[0m  0.1207\n",
            "      6    \u001b[36m20896.6521\u001b[0m  0.1158\n",
            "      7    \u001b[36m15113.1841\u001b[0m  0.1103\n",
            "      8    \u001b[36m10728.4904\u001b[0m  0.1190\n",
            "      9     \u001b[36m6845.5036\u001b[0m  0.1101\n",
            "     10     \u001b[36m3174.3497\u001b[0m  0.1097\n",
            "     11     \u001b[36m1016.5615\u001b[0m  0.1056\n",
            "     12      \u001b[36m820.9969\u001b[0m  0.1046\n",
            "     13     1074.5515  0.1048\n",
            "     14      \u001b[36m760.8442\u001b[0m  0.1392\n",
            "     15      765.8239  0.1209\n",
            "     16      \u001b[36m718.1003\u001b[0m  0.1134\n",
            "     17      \u001b[36m669.6326\u001b[0m  0.1155\n",
            "     18      \u001b[36m668.4723\u001b[0m  0.1305\n",
            "     19      \u001b[36m591.9155\u001b[0m  0.1176\n",
            "     20      616.9629  0.0832\n",
            "     21      601.1058  0.0832\n",
            "     22      \u001b[36m545.2987\u001b[0m  0.0833\n",
            "     23      551.3104  0.0794\n",
            "     24      \u001b[36m496.5782\u001b[0m  0.0831\n",
            "     25      \u001b[36m443.8451\u001b[0m  0.0794\n",
            "     26      484.2795  0.0769\n",
            "     27      \u001b[36m438.9380\u001b[0m  0.0790\n",
            "     28      \u001b[36m401.5366\u001b[0m  0.0783\n",
            "     29      \u001b[36m395.3606\u001b[0m  0.0799\n",
            "     30      535.3845  0.0770\n",
            "     31      423.6909  0.0744\n",
            "     32      420.0961  0.0813\n",
            "     33      \u001b[36m305.8603\u001b[0m  0.0781\n",
            "     34      378.2724  0.0787\n",
            "     35      365.1933  0.0777\n",
            "     36      312.0332  0.1020\n",
            "     37      348.0656  0.0796\n",
            "     38      369.5929  0.0764\n",
            "     39      \u001b[36m285.6178\u001b[0m  0.0804\n",
            "     40      \u001b[36m245.9954\u001b[0m  0.0779\n",
            "     41      273.7154  0.0846\n",
            "     42      \u001b[36m239.8486\u001b[0m  0.0773\n",
            "     43      263.2835  0.0872\n",
            "     44      262.6794  0.0762\n",
            "     45      265.2108  0.0763\n",
            "     46      \u001b[36m231.7393\u001b[0m  0.0764\n",
            "     47      264.0052  0.0870\n",
            "     48      \u001b[36m230.2134\u001b[0m  0.0829\n",
            "     49      \u001b[36m180.7471\u001b[0m  0.0783\n",
            "     50      210.2435  0.0876\n",
            "     51      206.2555  0.0884\n",
            "     52      217.8073  0.0833\n",
            "     53      202.3902  0.0799\n",
            "     54      \u001b[36m150.8084\u001b[0m  0.0822\n",
            "     55      166.6203  0.0825\n",
            "     56      179.6817  0.0783\n",
            "     57      168.9146  0.0764\n",
            "     58      \u001b[36m123.7065\u001b[0m  0.0856\n",
            "     59      134.4393  0.0809\n",
            "     60      161.1656  0.0811\n",
            "     61      137.4105  0.0795\n",
            "     62      130.1972  0.0769\n",
            "     63      \u001b[36m116.0753\u001b[0m  0.0824\n",
            "     64      \u001b[36m112.4014\u001b[0m  0.0777\n",
            "     65      \u001b[36m101.3467\u001b[0m  0.0782\n",
            "     66      121.8205  0.1093\n",
            "     67       \u001b[36m97.8032\u001b[0m  0.0814\n",
            "     68       \u001b[36m90.5067\u001b[0m  0.0821\n",
            "     69      101.6518  0.0839\n",
            "     70       91.7677  0.0768\n",
            "     71       \u001b[36m87.8177\u001b[0m  0.0785\n",
            "     72       \u001b[36m85.3379\u001b[0m  0.0838\n",
            "     73       \u001b[36m75.4892\u001b[0m  0.0845\n",
            "     74       \u001b[36m75.3403\u001b[0m  0.0820\n",
            "     75       82.5733  0.0789\n",
            "     76       \u001b[36m61.9276\u001b[0m  0.1016\n",
            "     77       69.2966  0.0839\n",
            "     78       72.5361  0.0791\n",
            "     79       62.8999  0.0799\n",
            "     80       \u001b[36m49.1376\u001b[0m  0.0821\n",
            "     81       53.9573  0.0763\n",
            "     82       60.8989  0.0768\n",
            "     83       61.1810  0.0818\n",
            "     84       \u001b[36m44.1394\u001b[0m  0.0869\n",
            "     85       51.1062  0.0767\n",
            "     86       \u001b[36m43.1867\u001b[0m  0.0802\n",
            "     87       48.9358  0.0782\n",
            "     88       \u001b[36m31.5409\u001b[0m  0.0871\n",
            "     89       35.4190  0.0772\n",
            "     90       33.7101  0.0758\n",
            "     91       32.8401  0.0825\n",
            "     92       34.3337  0.0793\n",
            "     93       \u001b[36m28.7657\u001b[0m  0.0819\n",
            "     94       31.7724  0.0793\n",
            "     95       \u001b[36m22.0206\u001b[0m  0.0835\n",
            "     96       22.3283  0.0779\n",
            "     97       \u001b[36m20.6114\u001b[0m  0.0894\n",
            "     98       \u001b[36m20.3504\u001b[0m  0.0855\n",
            "     99       \u001b[36m17.3393\u001b[0m  0.0817\n",
            "    100       \u001b[36m16.0448\u001b[0m  0.0819\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m97619.3714\u001b[0m  0.0750\n",
            "      2    \u001b[36m76430.1261\u001b[0m  0.0819\n",
            "      3    \u001b[36m60679.4380\u001b[0m  0.0785\n",
            "      4    \u001b[36m47316.8974\u001b[0m  0.0802\n",
            "      5    \u001b[36m37002.4794\u001b[0m  0.0768\n",
            "      6    \u001b[36m27900.2515\u001b[0m  0.0797\n",
            "      7    \u001b[36m21760.7163\u001b[0m  0.0786\n",
            "      8    \u001b[36m15863.7718\u001b[0m  0.0768\n",
            "      9    \u001b[36m11777.5227\u001b[0m  0.0859\n",
            "     10     \u001b[36m8833.4075\u001b[0m  0.0905\n",
            "     11     \u001b[36m5734.8702\u001b[0m  0.0799\n",
            "     12     \u001b[36m3399.7812\u001b[0m  0.0795\n",
            "     13     \u001b[36m1525.2722\u001b[0m  0.0811\n",
            "     14      \u001b[36m941.0937\u001b[0m  0.0801\n",
            "     15      974.9547  0.0792\n",
            "     16      \u001b[36m849.6752\u001b[0m  0.0764\n",
            "     17      \u001b[36m814.1226\u001b[0m  0.0868\n",
            "     18      881.7193  0.0801\n",
            "     19      \u001b[36m811.8878\u001b[0m  0.0812\n",
            "     20      \u001b[36m677.7387\u001b[0m  0.0820\n",
            "     21      750.2408  0.0876\n",
            "     22      680.7053  0.0881\n",
            "     23      \u001b[36m589.0938\u001b[0m  0.0826\n",
            "     24      701.6980  0.0885\n",
            "     25      \u001b[36m486.7070\u001b[0m  0.0810\n",
            "     26      545.0860  0.0773\n",
            "     27      592.5601  0.0841\n",
            "     28      564.3169  0.0798\n",
            "     29      \u001b[36m415.4717\u001b[0m  0.0835\n",
            "     30      433.6998  0.0784\n",
            "     31      496.4187  0.0784\n",
            "     32      464.5601  0.0783\n",
            "     33      424.9462  0.0907\n",
            "     34      \u001b[36m328.7685\u001b[0m  0.0870\n",
            "     35      345.3025  0.0760\n",
            "     36      342.9274  0.0785\n",
            "     37      388.2529  0.0770\n",
            "     38      382.1211  0.0869\n",
            "     39      \u001b[36m321.9624\u001b[0m  0.1174\n",
            "     40      \u001b[36m292.0044\u001b[0m  0.1085\n",
            "     41      322.9242  0.1081\n",
            "     42      308.9612  0.1219\n",
            "     43      \u001b[36m283.0990\u001b[0m  0.1339\n",
            "     44      302.3759  0.1190\n",
            "     45      \u001b[36m239.6287\u001b[0m  0.1278\n",
            "     46      240.9298  0.1081\n",
            "     47      \u001b[36m203.2763\u001b[0m  0.1079\n",
            "     48      223.7825  0.1066\n",
            "     49      210.6541  0.1114\n",
            "     50      222.4105  0.1160\n",
            "     51      \u001b[36m201.8638\u001b[0m  0.1167\n",
            "     52      \u001b[36m176.0490\u001b[0m  0.1264\n",
            "     53      \u001b[36m159.8375\u001b[0m  0.1215\n",
            "     54      189.8820  0.1134\n",
            "     55      \u001b[36m138.8255\u001b[0m  0.1067\n",
            "     56      177.7605  0.1097\n",
            "     57      170.1742  0.1087\n",
            "     58      163.6039  0.1053\n",
            "     59      152.6690  0.1063\n",
            "     60      \u001b[36m122.2174\u001b[0m  0.1125\n",
            "     61      152.6652  0.1387\n",
            "     62      129.0187  0.1142\n",
            "     63      138.0071  0.1077\n",
            "     64      126.7795  0.1079\n",
            "     65      \u001b[36m121.9593\u001b[0m  0.1158\n",
            "     66       \u001b[36m90.3833\u001b[0m  0.1079\n",
            "     67       95.2753  0.1093\n",
            "     68       \u001b[36m78.5862\u001b[0m  0.1260\n",
            "     69       90.5920  0.1108\n",
            "     70       82.3281  0.1271\n",
            "     71       \u001b[36m66.5394\u001b[0m  0.1259\n",
            "     72       84.7877  0.1216\n",
            "     73       66.6864  0.0919\n",
            "     74       70.6287  0.0781\n",
            "     75       67.8284  0.0809\n",
            "     76       78.3160  0.0827\n",
            "     77       \u001b[36m52.6878\u001b[0m  0.0929\n",
            "     78       59.6543  0.0904\n",
            "     79       60.4108  0.0784\n",
            "     80       \u001b[36m51.5819\u001b[0m  0.0872\n",
            "     81       62.3866  0.0852\n",
            "     82       54.5872  0.0786\n",
            "     83       \u001b[36m51.2398\u001b[0m  0.0770\n",
            "     84       \u001b[36m46.6023\u001b[0m  0.0819\n",
            "     85       47.0440  0.0770\n",
            "     86       \u001b[36m42.4816\u001b[0m  0.0857\n",
            "     87       \u001b[36m33.6113\u001b[0m  0.0783\n",
            "     88       39.5037  0.0772\n",
            "     89       34.8902  0.0787\n",
            "     90       \u001b[36m32.0159\u001b[0m  0.0840\n",
            "     91       33.7785  0.0786\n",
            "     92       32.1242  0.0856\n",
            "     93       \u001b[36m30.0465\u001b[0m  0.0924\n",
            "     94       34.9662  0.0766\n",
            "     95       \u001b[36m29.9019\u001b[0m  0.0785\n",
            "     96       \u001b[36m24.5523\u001b[0m  0.0845\n",
            "     97       27.9567  0.0806\n",
            "     98       \u001b[36m22.7038\u001b[0m  0.0788\n",
            "     99       24.3912  0.0867\n",
            "    100       \u001b[36m22.3267\u001b[0m  0.0799\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1   \u001b[36m104940.6931\u001b[0m  0.0774\n",
            "      2    \u001b[36m83857.7056\u001b[0m  0.0791\n",
            "      3    \u001b[36m66641.5288\u001b[0m  0.0771\n",
            "      4    \u001b[36m53432.6647\u001b[0m  0.0825\n",
            "      5    \u001b[36m42391.9052\u001b[0m  0.0894\n",
            "      6    \u001b[36m32224.3689\u001b[0m  0.0763\n",
            "      7    \u001b[36m25079.4914\u001b[0m  0.0842\n",
            "      8    \u001b[36m18116.1974\u001b[0m  0.0775\n",
            "      9    \u001b[36m13256.1766\u001b[0m  0.0774\n",
            "     10     \u001b[36m8163.2192\u001b[0m  0.0775\n",
            "     11     \u001b[36m3948.0641\u001b[0m  0.0880\n",
            "     12     \u001b[36m1754.2390\u001b[0m  0.0793\n",
            "     13     \u001b[36m1472.0328\u001b[0m  0.0797\n",
            "     14     1550.6976  0.0832\n",
            "     15     \u001b[36m1018.3699\u001b[0m  0.0797\n",
            "     16     1447.3948  0.1091\n",
            "     17     1267.4510  0.1083\n",
            "     18     1436.2195  0.0789\n",
            "     19     1060.7334  0.0785\n",
            "     20     1261.1531  0.0764\n",
            "     21      \u001b[36m985.0079\u001b[0m  0.0880\n",
            "     22     1113.3513  0.0804\n",
            "     23      \u001b[36m979.4492\u001b[0m  0.0760\n",
            "     24     1020.3308  0.0782\n",
            "     25      \u001b[36m924.2349\u001b[0m  0.0822\n",
            "     26     1061.9768  0.0827\n",
            "     27      \u001b[36m839.1420\u001b[0m  0.0781\n",
            "     28      882.6945  0.0807\n",
            "     29      \u001b[36m752.1079\u001b[0m  0.0944\n",
            "     30      \u001b[36m694.1321\u001b[0m  0.0888\n",
            "     31      773.7933  0.0822\n",
            "     32      \u001b[36m635.5621\u001b[0m  0.0845\n",
            "     33      904.4919  0.0788\n",
            "     34      722.2618  0.0783\n",
            "     35      \u001b[36m598.4376\u001b[0m  0.0817\n",
            "     36      639.7197  0.0791\n",
            "     37      637.6592  0.0912\n",
            "     38      \u001b[36m536.0330\u001b[0m  0.0786\n",
            "     39      \u001b[36m449.9584\u001b[0m  0.0792\n",
            "     40      536.5810  0.0865\n",
            "     41      554.2558  0.0882\n",
            "     42      452.4725  0.0792\n",
            "     43      476.3283  0.0805\n",
            "     44      450.6130  0.0815\n",
            "     45      494.4855  0.0834\n",
            "     46      495.8225  0.0831\n",
            "     47      \u001b[36m415.0703\u001b[0m  0.0790\n",
            "     48      \u001b[36m369.2591\u001b[0m  0.0761\n",
            "     49      \u001b[36m362.8198\u001b[0m  0.0824\n",
            "     50      384.0076  0.0802\n",
            "     51      370.2514  0.0795\n",
            "     52      \u001b[36m298.2614\u001b[0m  0.0814\n",
            "     53      319.3828  0.0919\n",
            "     54      318.9427  0.0783\n",
            "     55      360.8644  0.0754\n",
            "     56      \u001b[36m288.6212\u001b[0m  0.0825\n",
            "     57      \u001b[36m271.9554\u001b[0m  0.0839\n",
            "     58      \u001b[36m255.1379\u001b[0m  0.0783\n",
            "     59      \u001b[36m208.3533\u001b[0m  0.0782\n",
            "     60      244.6305  0.0773\n",
            "     61      233.2945  0.0868\n",
            "     62      245.3143  0.1000\n",
            "     63      238.9245  0.0993\n",
            "     64      \u001b[36m204.2920\u001b[0m  0.0804\n",
            "     65      205.5965  0.0853\n",
            "     66      \u001b[36m201.5626\u001b[0m  0.0849\n",
            "     67      \u001b[36m176.4152\u001b[0m  0.0835\n",
            "     68      \u001b[36m160.7815\u001b[0m  0.0762\n",
            "     69      168.4642  0.0766\n",
            "     70      \u001b[36m152.1539\u001b[0m  0.0772\n",
            "     71      \u001b[36m142.2136\u001b[0m  0.0801\n",
            "     72      \u001b[36m139.8927\u001b[0m  0.0773\n",
            "     73      \u001b[36m124.4193\u001b[0m  0.0777\n",
            "     74      \u001b[36m107.8953\u001b[0m  0.0783\n",
            "     75      124.2566  0.0811\n",
            "     76      127.6914  0.0810\n",
            "     77      124.0339  0.0869\n",
            "     78      126.6026  0.0787\n",
            "     79      118.3472  0.0813\n",
            "     80      108.1115  0.0781\n",
            "     81      \u001b[36m103.3846\u001b[0m  0.0780\n",
            "     82      107.3214  0.0839\n",
            "     83       \u001b[36m92.7494\u001b[0m  0.0794\n",
            "     84       97.4828  0.0790\n",
            "     85       95.8245  0.0793\n",
            "     86       \u001b[36m71.3010\u001b[0m  0.0874\n",
            "     87       84.2054  0.0786\n",
            "     88       91.1260  0.0806\n",
            "     89       \u001b[36m65.1420\u001b[0m  0.0827\n",
            "     90       76.5471  0.0831\n",
            "     91       81.4564  0.1005\n",
            "     92       67.0916  0.1195\n",
            "     93       71.3493  0.1087\n",
            "     94       \u001b[36m56.3686\u001b[0m  0.1098\n",
            "     95       66.0163  0.1092\n",
            "     96       \u001b[36m53.5503\u001b[0m  0.1063\n",
            "     97       58.2846  0.1132\n",
            "     98       53.5529  0.1112\n",
            "     99       60.1098  0.1201\n",
            "    100       \u001b[36m49.3663\u001b[0m  0.1145\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m60346.3795\u001b[0m  0.1069\n",
            "      2    \u001b[36m46512.7276\u001b[0m  0.1153\n",
            "      3    \u001b[36m35401.4216\u001b[0m  0.1214\n",
            "      4    \u001b[36m26411.3776\u001b[0m  0.1128\n",
            "      5    \u001b[36m19100.1578\u001b[0m  0.1093\n",
            "      6    \u001b[36m13553.6573\u001b[0m  0.1125\n",
            "      7     \u001b[36m8259.6672\u001b[0m  0.1169\n",
            "      8     \u001b[36m3872.6816\u001b[0m  0.1118\n",
            "      9     \u001b[36m1722.1920\u001b[0m  0.1067\n",
            "     10     \u001b[36m1440.9780\u001b[0m  0.1172\n",
            "     11     \u001b[36m1303.8849\u001b[0m  0.1108\n",
            "     12     \u001b[36m1195.9895\u001b[0m  0.1075\n",
            "     13     1407.4569  0.1048\n",
            "     14     1287.1264  0.1133\n",
            "     15     \u001b[36m1097.5778\u001b[0m  0.1063\n",
            "     16     1134.3913  0.1068\n",
            "     17     1162.9435  0.1112\n",
            "     18     1107.6326  0.1093\n",
            "     19     \u001b[36m1061.5510\u001b[0m  0.1097\n",
            "     20     \u001b[36m1017.4770\u001b[0m  0.1109\n",
            "     21      \u001b[36m939.3809\u001b[0m  0.1106\n",
            "     22      \u001b[36m881.6590\u001b[0m  0.1156\n",
            "     23      995.4671  0.1111\n",
            "     24      \u001b[36m704.7081\u001b[0m  0.1089\n",
            "     25      716.1033  0.1155\n",
            "     26      748.6586  0.1215\n",
            "     27      \u001b[36m641.4065\u001b[0m  0.0765\n",
            "     28      \u001b[36m616.4156\u001b[0m  0.0797\n",
            "     29      \u001b[36m608.6345\u001b[0m  0.0793\n",
            "     30      668.5008  0.0808\n",
            "     31      \u001b[36m532.2341\u001b[0m  0.0846\n",
            "     32      \u001b[36m530.1898\u001b[0m  0.0820\n",
            "     33      \u001b[36m521.1868\u001b[0m  0.0782\n",
            "     34      535.3704  0.0790\n",
            "     35      \u001b[36m507.1072\u001b[0m  0.0819\n",
            "     36      \u001b[36m497.4355\u001b[0m  0.0774\n",
            "     37      \u001b[36m468.8617\u001b[0m  0.0832\n",
            "     38      524.5548  0.0854\n",
            "     39      485.2985  0.0826\n",
            "     40      \u001b[36m378.5018\u001b[0m  0.0801\n",
            "     41      430.5916  0.0795\n",
            "     42      \u001b[36m374.6196\u001b[0m  0.2217\n",
            "     43      \u001b[36m335.8973\u001b[0m  0.3513\n",
            "     44      383.4100  0.1963\n",
            "     45      \u001b[36m305.4204\u001b[0m  0.0798\n",
            "     46      309.5924  0.1022\n",
            "     47      \u001b[36m294.0387\u001b[0m  0.0932\n",
            "     48      \u001b[36m262.6052\u001b[0m  0.0792\n",
            "     49      \u001b[36m226.2382\u001b[0m  0.1702\n",
            "     50      271.4151  0.4590\n",
            "     51      233.9038  0.1315\n",
            "     52      240.6748  0.0815\n",
            "     53      \u001b[36m202.4480\u001b[0m  0.0805\n",
            "     54      \u001b[36m190.3653\u001b[0m  0.0831\n",
            "     55      \u001b[36m189.2629\u001b[0m  0.0802\n",
            "     56      \u001b[36m167.0895\u001b[0m  0.0783\n",
            "     57      176.3250  0.2809\n",
            "     58      187.0638  0.4184\n",
            "     59      174.5307  0.0802\n",
            "     60      \u001b[36m163.6136\u001b[0m  0.0787\n",
            "     61      \u001b[36m158.3527\u001b[0m  0.0779\n",
            "     62      \u001b[36m137.0448\u001b[0m  0.0854\n",
            "     63      \u001b[36m130.3480\u001b[0m  0.0777\n",
            "     64      \u001b[36m110.6437\u001b[0m  0.0776\n",
            "     65      113.8117  0.0772\n",
            "     66      \u001b[36m109.9857\u001b[0m  0.0829\n",
            "     67       \u001b[36m92.3892\u001b[0m  0.0913\n",
            "     68      105.3868  0.0851\n",
            "     69       94.4053  0.0801\n",
            "     70       \u001b[36m88.5279\u001b[0m  0.0799\n",
            "     71       93.9811  0.0776\n",
            "     72       \u001b[36m81.1988\u001b[0m  0.0783\n",
            "     73       94.7290  0.0766\n",
            "     74       \u001b[36m71.1535\u001b[0m  0.0870\n",
            "     75       \u001b[36m65.1062\u001b[0m  0.0819\n",
            "     76       \u001b[36m64.9628\u001b[0m  0.0754\n",
            "     77       66.1070  0.0799\n",
            "     78       \u001b[36m64.7263\u001b[0m  0.0829\n",
            "     79       \u001b[36m50.6616\u001b[0m  0.0766\n",
            "     80       61.0240  0.0856\n",
            "     81       51.1824  0.0774\n",
            "     82       \u001b[36m47.2827\u001b[0m  0.0855\n",
            "     83       47.9462  0.0787\n",
            "     84       52.7628  0.0765\n",
            "     85       55.4270  0.0773\n",
            "     86       47.6362  0.0794\n",
            "     87       \u001b[36m45.1821\u001b[0m  0.0856\n",
            "     88       \u001b[36m40.9461\u001b[0m  0.0816\n",
            "     89       45.0972  0.0799\n",
            "     90       \u001b[36m33.2213\u001b[0m  0.0781\n",
            "     91       41.0158  0.0804\n",
            "     92       33.8341  0.0860\n",
            "     93       \u001b[36m25.0096\u001b[0m  0.0815\n",
            "     94       25.7706  0.0866\n",
            "     95       28.3138  0.0800\n",
            "     96       36.9891  0.0868\n",
            "     97       29.0547  0.0775\n",
            "     98       25.5010  0.0840\n",
            "     99       \u001b[36m21.4066\u001b[0m  0.0794\n",
            "    100       23.4919  0.0773\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m88296.4859\u001b[0m  0.0742\n",
            "      2    \u001b[36m70162.3169\u001b[0m  0.0839\n",
            "      3    \u001b[36m55338.9027\u001b[0m  0.0824\n",
            "      4    \u001b[36m42920.8622\u001b[0m  0.0778\n",
            "      5    \u001b[36m31954.3062\u001b[0m  0.0867\n",
            "      6    \u001b[36m23913.2152\u001b[0m  0.0788\n",
            "      7    \u001b[36m16225.3211\u001b[0m  0.0819\n",
            "      8     \u001b[36m9116.2104\u001b[0m  0.0777\n",
            "      9     \u001b[36m3772.8302\u001b[0m  0.0851\n",
            "     10     \u001b[36m2131.5478\u001b[0m  0.0837\n",
            "     11     2138.2522  0.0828\n",
            "     12     2317.3114  0.0763\n",
            "     13     \u001b[36m1968.9067\u001b[0m  0.0850\n",
            "     14     \u001b[36m1950.0131\u001b[0m  0.0790\n",
            "     15     \u001b[36m1899.6623\u001b[0m  0.0809\n",
            "     16     \u001b[36m1511.7767\u001b[0m  0.0820\n",
            "     17     1515.7737  0.1030\n",
            "     18     1616.8061  0.0827\n",
            "     19     1533.1944  0.0784\n",
            "     20     1690.8680  0.0906\n",
            "     21     \u001b[36m1417.8465\u001b[0m  0.0779\n",
            "     22     \u001b[36m1335.6100\u001b[0m  0.0807\n",
            "     23     1431.1788  0.0794\n",
            "     24     \u001b[36m1297.4011\u001b[0m  0.0821\n",
            "     25     \u001b[36m1129.7506\u001b[0m  0.0806\n",
            "     26     1315.9595  0.0958\n",
            "     27     1188.8767  0.1171\n",
            "     28     \u001b[36m1058.4741\u001b[0m  0.1290\n",
            "     29     \u001b[36m1032.4835\u001b[0m  0.1153\n",
            "     30     1094.4847  0.1104\n",
            "     31      \u001b[36m874.6598\u001b[0m  0.1044\n",
            "     32      \u001b[36m874.0065\u001b[0m  0.1072\n",
            "     33      876.9229  0.1103\n",
            "     34      984.6183  0.1041\n",
            "     35      978.1087  0.1118\n",
            "     36      \u001b[36m806.8026\u001b[0m  0.1061\n",
            "     37      \u001b[36m687.8762\u001b[0m  0.1204\n",
            "     38      762.5640  0.1079\n",
            "     39      721.3190  0.1159\n",
            "     40      \u001b[36m660.9460\u001b[0m  0.1154\n",
            "     41      \u001b[36m511.2825\u001b[0m  0.1131\n",
            "     42      582.3393  0.1141\n",
            "     43      616.8628  0.1159\n",
            "     44      571.1197  0.1088\n",
            "     45      522.0438  0.1096\n",
            "     46      601.2734  0.1127\n",
            "     47      577.3954  0.1080\n",
            "     48      546.0667  0.1071\n",
            "     49      \u001b[36m471.1764\u001b[0m  0.1086\n",
            "     50      474.4134  0.1259\n",
            "     51      \u001b[36m419.3065\u001b[0m  0.1066\n",
            "     52      \u001b[36m365.3968\u001b[0m  0.1097\n",
            "     53      \u001b[36m344.9000\u001b[0m  0.1094\n",
            "     54      \u001b[36m334.1400\u001b[0m  0.1217\n",
            "     55      394.2010  0.1164\n",
            "     56      \u001b[36m313.5256\u001b[0m  0.1072\n",
            "     57      349.4687  0.1077\n",
            "     58      \u001b[36m310.4926\u001b[0m  0.1133\n",
            "     59      \u001b[36m278.4110\u001b[0m  0.1051\n",
            "     60      291.0144  0.1105\n",
            "     61      301.8630  0.1159\n",
            "     62      \u001b[36m236.6669\u001b[0m  0.1158\n",
            "     63      260.1844  0.0912\n",
            "     64      256.7350  0.0823\n",
            "     65      \u001b[36m212.3149\u001b[0m  0.0833\n",
            "     66      240.4381  0.0836\n",
            "     67      215.3051  0.0822\n",
            "     68      \u001b[36m177.9579\u001b[0m  0.0818\n",
            "     69      212.0572  0.0788\n",
            "     70      219.1314  0.0869\n",
            "     71      \u001b[36m172.3854\u001b[0m  0.0789\n",
            "     72      186.3015  0.0825\n",
            "     73      174.0004  0.0834\n",
            "     74      \u001b[36m151.9373\u001b[0m  0.0844\n",
            "     75      \u001b[36m144.3835\u001b[0m  0.0848\n",
            "     76      \u001b[36m131.3679\u001b[0m  0.0777\n",
            "     77      \u001b[36m123.1819\u001b[0m  0.0878\n",
            "     78      149.6202  0.0859\n",
            "     79      127.3494  0.0779\n",
            "     80      \u001b[36m114.7626\u001b[0m  0.0813\n",
            "     81      \u001b[36m109.5859\u001b[0m  0.0836\n",
            "     82      \u001b[36m101.7346\u001b[0m  0.0798\n",
            "     83       \u001b[36m95.1815\u001b[0m  0.0799\n",
            "     84       \u001b[36m91.5768\u001b[0m  0.0821\n",
            "     85       \u001b[36m90.2803\u001b[0m  0.0770\n",
            "     86      103.6374  0.0877\n",
            "     87       95.5627  0.0962\n",
            "     88       \u001b[36m88.6974\u001b[0m  0.0791\n",
            "     89       89.3113  0.0867\n",
            "     90       \u001b[36m86.5291\u001b[0m  0.0895\n",
            "     91       \u001b[36m81.9946\u001b[0m  0.0871\n",
            "     92       \u001b[36m72.2924\u001b[0m  0.0772\n",
            "     93       \u001b[36m67.8449\u001b[0m  0.0775\n",
            "     94       \u001b[36m64.0241\u001b[0m  0.0822\n",
            "     95       64.6515  0.0843\n",
            "     96       65.2471  0.0784\n",
            "     97       \u001b[36m60.3931\u001b[0m  0.0791\n",
            "     98       \u001b[36m59.9321\u001b[0m  0.0834\n",
            "     99       \u001b[36m57.2678\u001b[0m  0.0820\n",
            "    100       \u001b[36m56.1942\u001b[0m  0.0781\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1   \u001b[36m110057.0750\u001b[0m  0.0934\n",
            "      2    \u001b[36m89415.9643\u001b[0m  0.0769\n",
            "      3    \u001b[36m73797.6807\u001b[0m  0.0796\n",
            "      4    \u001b[36m57506.0078\u001b[0m  0.0754\n",
            "      5    \u001b[36m46046.3993\u001b[0m  0.0763\n",
            "      6    \u001b[36m36758.4413\u001b[0m  0.0892\n",
            "      7    \u001b[36m29026.6067\u001b[0m  0.0816\n",
            "      8    \u001b[36m22717.4974\u001b[0m  0.0781\n",
            "      9    \u001b[36m17063.6622\u001b[0m  0.0810\n",
            "     10    \u001b[36m13167.6055\u001b[0m  0.0803\n",
            "     11     \u001b[36m9311.3973\u001b[0m  0.0859\n",
            "     12     \u001b[36m6218.4926\u001b[0m  0.0803\n",
            "     13     \u001b[36m3462.9859\u001b[0m  0.0907\n",
            "     14     \u001b[36m1533.7426\u001b[0m  0.0818\n",
            "     15     \u001b[36m1183.1971\u001b[0m  0.0861\n",
            "     16      \u001b[36m975.1280\u001b[0m  0.0846\n",
            "     17      \u001b[36m840.1354\u001b[0m  0.0805\n",
            "     18     1160.2378  0.0774\n",
            "     19     1002.6420  0.0773\n",
            "     20      908.2388  0.0799\n",
            "     21      882.2159  0.0831\n",
            "     22      877.4667  0.0782\n",
            "     23      \u001b[36m818.4647\u001b[0m  0.0791\n",
            "     24      \u001b[36m726.2117\u001b[0m  0.0828\n",
            "     25      761.2182  0.0949\n",
            "     26      \u001b[36m693.7817\u001b[0m  0.0814\n",
            "     27      756.8733  0.0795\n",
            "     28      719.6339  0.0857\n",
            "     29      \u001b[36m622.9490\u001b[0m  0.0967\n",
            "     30      \u001b[36m525.4027\u001b[0m  0.0824\n",
            "     31      557.3873  0.0872\n",
            "     32      \u001b[36m520.0944\u001b[0m  0.0805\n",
            "     33      613.6003  0.0809\n",
            "     34      \u001b[36m483.0906\u001b[0m  0.0783\n",
            "     35      534.2974  0.0814\n",
            "     36      485.2853  0.0793\n",
            "     37      523.1315  0.0880\n",
            "     38      510.0197  0.0809\n",
            "     39      501.6699  0.1099\n",
            "     40      485.5423  0.0792\n",
            "     41      \u001b[36m461.2094\u001b[0m  0.0827\n",
            "     42      \u001b[36m370.8508\u001b[0m  0.0799\n",
            "     43      390.0190  0.0786\n",
            "     44      376.8692  0.0944\n",
            "     45      400.6000  0.0871\n",
            "     46      \u001b[36m328.4426\u001b[0m  0.0919\n",
            "     47      \u001b[36m308.0066\u001b[0m  0.0798\n",
            "     48      318.7539  0.0882\n",
            "     49      \u001b[36m281.4788\u001b[0m  0.0897\n",
            "     50      \u001b[36m248.3289\u001b[0m  0.0826\n",
            "     51      \u001b[36m223.6833\u001b[0m  0.0881\n",
            "     52      282.6949  0.0794\n",
            "     53      319.7466  0.0805\n",
            "     54      323.5464  0.0847\n",
            "     55      224.6640  0.0809\n",
            "     56      230.8539  0.0922\n",
            "     57      \u001b[36m210.7488\u001b[0m  0.0807\n",
            "     58      239.2404  0.0785\n",
            "     59      286.2525  0.0788\n",
            "     60      \u001b[36m202.1704\u001b[0m  0.0884\n",
            "     61      221.6890  0.0842\n",
            "     62      \u001b[36m170.3159\u001b[0m  0.0788\n",
            "     63      172.8844  0.0776\n",
            "     64      \u001b[36m157.2397\u001b[0m  0.0818\n",
            "     65      200.6464  0.0857\n",
            "     66      185.3952  0.0806\n",
            "     67      \u001b[36m156.4969\u001b[0m  0.0860\n",
            "     68      \u001b[36m124.7163\u001b[0m  0.0814\n",
            "     69      \u001b[36m113.8002\u001b[0m  0.0854\n",
            "     70      129.6820  0.0767\n",
            "     71      118.7034  0.0879\n",
            "     72      \u001b[36m110.8754\u001b[0m  0.0814\n",
            "     73      \u001b[36m109.5303\u001b[0m  0.0879\n",
            "     74      121.5550  0.0783\n",
            "     75      \u001b[36m101.8149\u001b[0m  0.0857\n",
            "     76      108.3676  0.0840\n",
            "     77       \u001b[36m84.8927\u001b[0m  0.0804\n",
            "     78      103.3981  0.0816\n",
            "     79       \u001b[36m76.5517\u001b[0m  0.0869\n",
            "     80       87.4113  0.1168\n",
            "     81       79.1281  0.1114\n",
            "     82       83.2190  0.1065\n",
            "     83       \u001b[36m75.0200\u001b[0m  0.1173\n",
            "     84       \u001b[36m62.4128\u001b[0m  0.1158\n",
            "     85       \u001b[36m60.2591\u001b[0m  0.1093\n",
            "     86       65.8306  0.1141\n",
            "     87       73.0002  0.1080\n",
            "     88       \u001b[36m48.7136\u001b[0m  0.1145\n",
            "     89       60.5876  0.1079\n",
            "     90       58.5949  0.1122\n",
            "     91       52.1705  0.1086\n",
            "     92       54.2006  0.1241\n",
            "     93       \u001b[36m42.5888\u001b[0m  0.1175\n",
            "     94       \u001b[36m40.0290\u001b[0m  0.1191\n",
            "     95       41.9428  0.1315\n",
            "     96       \u001b[36m38.2160\u001b[0m  0.1210\n",
            "     97       38.7712  0.1208\n",
            "     98       47.0835  0.1082\n",
            "     99       39.9943  0.1095\n",
            "    100       \u001b[36m35.2570\u001b[0m  0.1079\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m63544.0862\u001b[0m  0.1220\n",
            "      2    \u001b[36m48587.1487\u001b[0m  0.1119\n",
            "      3    \u001b[36m37357.3829\u001b[0m  0.1145\n",
            "      4    \u001b[36m28372.7904\u001b[0m  0.1094\n",
            "      5    \u001b[36m20310.3689\u001b[0m  0.1073\n",
            "      6    \u001b[36m14607.5680\u001b[0m  0.1126\n",
            "      7    \u001b[36m10164.7881\u001b[0m  0.1080\n",
            "      8     \u001b[36m6123.7439\u001b[0m  0.1055\n",
            "      9     \u001b[36m3096.0591\u001b[0m  0.1101\n",
            "     10     \u001b[36m1410.4843\u001b[0m  0.1225\n",
            "     11     \u001b[36m1213.6655\u001b[0m  0.1079\n",
            "     12     1279.5721  0.1142\n",
            "     13     \u001b[36m1176.2845\u001b[0m  0.1179\n",
            "     14     \u001b[36m1113.8437\u001b[0m  0.1135\n",
            "     15     \u001b[36m1018.0597\u001b[0m  0.1144\n",
            "     16     1098.2126  0.0785\n",
            "     17      \u001b[36m826.0092\u001b[0m  0.0789\n",
            "     18     1010.2166  0.0856\n",
            "     19      \u001b[36m823.1915\u001b[0m  0.0856\n",
            "     20      888.7577  0.0822\n",
            "     21      892.5904  0.0785\n",
            "     22      \u001b[36m744.2753\u001b[0m  0.0872\n",
            "     23      \u001b[36m681.9664\u001b[0m  0.1017\n",
            "     24      \u001b[36m589.0884\u001b[0m  0.0905\n",
            "     25      669.5113  0.0811\n",
            "     26      608.7264  0.0865\n",
            "     27      647.5646  0.0817\n",
            "     28      670.7421  0.0864\n",
            "     29      \u001b[36m560.1571\u001b[0m  0.0813\n",
            "     30      \u001b[36m464.0125\u001b[0m  0.0820\n",
            "     31      519.1388  0.0984\n",
            "     32      473.2422  0.0799\n",
            "     33      \u001b[36m436.6025\u001b[0m  0.0796\n",
            "     34      \u001b[36m416.2595\u001b[0m  0.0800\n",
            "     35      496.4606  0.0859\n",
            "     36      \u001b[36m362.3110\u001b[0m  0.0872\n",
            "     37      384.9366  0.0803\n",
            "     38      \u001b[36m349.0456\u001b[0m  0.0853\n",
            "     39      398.4090  0.0797\n",
            "     40      \u001b[36m323.8631\u001b[0m  0.0776\n",
            "     41      \u001b[36m297.9111\u001b[0m  0.0756\n",
            "     42      \u001b[36m283.1407\u001b[0m  0.1129\n",
            "     43      \u001b[36m276.0520\u001b[0m  0.1093\n",
            "     44      \u001b[36m262.4986\u001b[0m  0.1012\n",
            "     45      \u001b[36m251.5308\u001b[0m  0.1048\n",
            "     46      260.4891  0.0935\n",
            "     47      \u001b[36m245.9686\u001b[0m  0.0777\n",
            "     48      \u001b[36m233.4378\u001b[0m  0.0850\n",
            "     49      \u001b[36m212.4412\u001b[0m  0.0822\n",
            "     50      \u001b[36m179.4797\u001b[0m  0.0780\n",
            "     51      \u001b[36m161.9926\u001b[0m  0.0782\n",
            "     52      177.1738  0.0886\n",
            "     53      \u001b[36m158.5800\u001b[0m  0.0787\n",
            "     54      \u001b[36m157.4945\u001b[0m  0.0853\n",
            "     55      \u001b[36m114.3685\u001b[0m  0.0808\n",
            "     56      118.5213  0.0792\n",
            "     57      132.0249  0.0844\n",
            "     58      \u001b[36m105.0208\u001b[0m  0.0761\n",
            "     59      113.1145  0.0842\n",
            "     60      110.8790  0.0806\n",
            "     61      128.6270  0.0791\n",
            "     62      106.7940  0.0813\n",
            "     63      107.8654  0.0905\n",
            "     64       \u001b[36m95.6446\u001b[0m  0.0827\n",
            "     65       \u001b[36m89.8171\u001b[0m  0.0791\n",
            "     66       95.2843  0.0957\n",
            "     67       \u001b[36m74.9631\u001b[0m  0.0858\n",
            "     68       \u001b[36m74.2863\u001b[0m  0.0801\n",
            "     69       75.9751  0.0827\n",
            "     70       \u001b[36m58.9534\u001b[0m  0.0814\n",
            "     71       69.8051  0.0892\n",
            "     72       66.0610  0.0829\n",
            "     73       \u001b[36m54.7968\u001b[0m  0.0827\n",
            "     74       68.8851  0.0849\n",
            "     75       \u001b[36m45.3734\u001b[0m  0.0804\n",
            "     76       65.6428  0.0836\n",
            "     77       \u001b[36m43.3737\u001b[0m  0.0819\n",
            "     78       49.7297  0.0902\n",
            "     79       \u001b[36m41.0894\u001b[0m  0.0782\n",
            "     80       47.8367  0.0821\n",
            "     81       43.0807  0.0824\n",
            "     82       \u001b[36m35.5610\u001b[0m  0.1011\n",
            "     83       39.1929  0.0800\n",
            "     84       \u001b[36m33.4410\u001b[0m  0.0807\n",
            "     85       \u001b[36m31.7965\u001b[0m  0.0860\n",
            "     86       32.6274  0.0807\n",
            "     87       34.0131  0.0904\n",
            "     88       \u001b[36m29.4402\u001b[0m  0.0801\n",
            "     89       \u001b[36m24.3749\u001b[0m  0.0804\n",
            "     90       \u001b[36m23.4420\u001b[0m  0.0909\n",
            "     91       \u001b[36m21.8863\u001b[0m  0.0828\n",
            "     92       25.8342  0.0826\n",
            "     93       \u001b[36m20.3895\u001b[0m  0.0873\n",
            "     94       \u001b[36m16.4217\u001b[0m  0.0784\n",
            "     95       \u001b[36m16.1847\u001b[0m  0.0793\n",
            "     96       18.1960  0.0821\n",
            "     97       20.4080  0.0836\n",
            "     98       \u001b[36m15.3129\u001b[0m  0.0769\n",
            "     99       \u001b[36m12.7662\u001b[0m  0.0793\n",
            "    100       \u001b[36m10.7622\u001b[0m  0.0771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media = resultados.mean()\n",
        "desvio = resultados.std()\n",
        "media, desvio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shVAaEIvK8ZO",
        "outputId": "6e775c73-a455-4a60-e367-2f9c8563f796"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7997807017543859, 0.05905641086717138)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh8v-mQbLY6_",
        "outputId": "de957c17-4d1a-4774-eb15-3df24f8a99c5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.77192982, 0.85964912, 0.80701754, 0.68421053, 0.78947368,\n",
              "       0.73684211, 0.8245614 , 0.87719298, 0.77192982, 0.875     ])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3AYxayNLfL7"
      },
      "execution_count": 64,
      "outputs": []
    }
  ]
}